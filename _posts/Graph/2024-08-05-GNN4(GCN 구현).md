---
title: "[그래프 이론]GCN 구현하기 with PyTorch"
categories: 
  - Graph
  
toc: true
toc_sticky: true

date: 2024-08-05
last_modified_at: 2024-08-05
---

# GCN 구현하기
## 1. 패키지 설치
```python
# Install required packages.
!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html
!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html
!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git
```

## 2. Visualization을 위한 함수 정의
이 코드는 그래프와 임베딩을 시각화하는 두 가지 함수를 정의한 것이다. 각 함수의 목적은 다음과 같다:

1. **`visualizeGraph(G, color)` 함수**:
   - 그래프 `G`와 노드의 색상을 지정하는 `color` 매개변수를 입력으로 받는다.
   - `nx.spring_layout`을 사용하여 그래프의 레이아웃을 계산하고, `nx.draw_networkx`를 사용하여 그래프를 시각화한다.
   - 시각화된 그래프는 노드의 레이블을 표시하지 않으며, 노드의 색상은 `color` 매개변수를 기반으로 지정된 컬러맵(`Set2`)을 사용한다.

2. **`visualizeEmbedding(h, color, epoch=None, loss=None)` 함수**:
   - 임베딩 텐서 `h`, 색상을 지정하는 `color` 매개변수, 선택적인 `epoch` 및 `loss` 값을 입력으로 받는다.
   - 임베딩 텐서 `h`를 NumPy 배열로 변환하고, `plt.scatter`를 사용하여 2D 평면에 점으로 시각화한다.
   - `epoch`와 `loss` 값이 제공되면, 플롯의 x축 레이블에 해당 정보를 표시한다.
   - 시각화된 임베딩은 지정된 `Set2` 컬러맵을 사용하여 노드의 색상을 표시한다.

이 코드는 주로 그래프 데이터를 시각화하고, 신경망의 임베딩 결과를 시각화하는 데 사용된다. 시각화를 통해 그래프의 구조와 임베딩의 분포를 쉽게 이해할 수 있다.

```python
import torch
import networkx as nx
import matplotlib.pyplot as plt

def visualizeGraph(G, color):
  plt.figure(figsize=(7,7))
  plt.xticks([])
  plt.yticks([])
  nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,
                   node_color=color, cmap="Set2")
  plt.show()

def visualizeEmbedding(h, color, epoch=None, loss=None):
  plt.figure(figsize=(7, 7))
  plt.xticks([])
  plt.yticks([])
  h = h.detach().cpu().numpy()
  plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap="Set2")
  if epoch is not None and loss is not None:
    plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)
  plt.show()

```

## 3. Data Load
PyTorch Geometric을 사용하여 Karate Club 데이터셋을 로드하고 데이터셋 및 그래프에 대한 다양한 통계를 출력한다.

1. **데이터셋 로드**:
   - `KarateClub` 데이터셋을 로드하여 `dataset` 변수에 할당한다.
   - 데이터셋에 대한 기본 정보(그래프 수, 특징 수, 클래스 수)를 출력한다.

2. **데이터셋 통계 출력**:
   - 데이터셋 내 그래프의 수.
   - 데이터셋의 노드당 특징 수.
   - 데이터셋 내 클래스 수.

3. **그래프 데이터 출력**:
   - 데이터셋의 첫 번째 그래프 데이터를 출력한다.

4. **그래프 통계 수집 및 출력**:
   - 그래프의 노드 수.
   - 그래프의 엣지 수.
   - 평균 노드 차수(엣지 수를 노드 수로 나눈 값).
   - 학습 노드 수.
   - 학습 노드 라벨 비율(전체 노드 수 대비 학습 노드의 비율).
   - 그래프에 고립된 노드가 있는지 여부.
   - 그래프에 자기 루프가 있는지 여부.
   - 그래프가 무방향인지 여부.

```python
from torch_geometric.datasets import KarateClub
dataset = KarateClub()
print(f'Dataset: {dataset}:')
print('======================')
print(f'Number of graphs: {len(dataset)}')
print(f'Number of features: {dataset.num_features}')
print(f'Number of classes: {dataset.num_classes}')


data = dataset[0]
print(data)
print('==============================================================')

# Gather some statistics about the graph.
print(f'Number of nodes: {data.num_nodes}')
print(f'Number of edges: {data.num_edges}')
print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')
print(f'Number of training nodes: {data.train_mask.sum()}')
print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')
print(f'Has isolated nodes: {data.has_isolated_nodes()}')
print(f'Has self-loops: {data.has_self_loops()}')
print(f'Is undirected: {data.is_undirected()}')
```

```bash
Dataset: KarateClub():
======================
Number of graphs: 1
Number of features: 34
Number of classes: 4
Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])
==============================================================
Number of nodes: 34
Number of edges: 156
Average node degree: 4.59
Number of training nodes: 4
Training node label rate: 0.12
Has isolated nodes: False
Has self-loops: False
Is undirected: True
```

`NetworkX` 라이브러리는 그래프 분석을 위한 여러가지 함수를 제공한다. 그 중 그래프를 시각화할 수 있는 함수 또한 존재한다.
```python
from torch_geometric.utils import to_networkx

G = to_networkx(data, to_undirected=True)
visualizeGraph(G, color=data.y)
```

<p align="center">
<img width="400" alt="1" src="https://github.com/user-attachments/assets/edb7cbc8-aeba-476d-a9a7-58c2765dfe73">
</p>

## 5. GCN 정의하기
PyTorch 및 PyTorch Geometric을 사용하여 그래프 컨볼루션 네트워크(GCN) 모델을 정의한 것이다. 코드에 대한 설명은 다음과 같다:

1. **임포트**:
   - PyTorch의 주요 라이브러리인 `torch`.
   - 선형 계층을 위한 `torch.nn`의 `Linear`.
   - 그래프 컨볼루션 계층을 위한 `torch_geometric.nn`의 `GCNConv`.

2. **GCN 클래스 정의**:
   - `GCN` 클래스는 `torch.nn.Module`을 상속한다.
   - `__init__` 메서드는 모델을 초기화한다:
     - 재현성을 위해 시드를 수동으로 설정한다.
     - 세 개의 그래프 컨볼루션 계층(`conv1`, `conv2`, `conv3`)을 정의하고, 입력 및 출력 차원을 지정한다:
       - `conv1`: 데이터셋의 특징 수에서 4로 변환.
       - `conv2`: 4에서 4로 변환.
       - `conv3`: 4에서 2로 변환.
     - 2차원 입력을 데이터셋의 클래스 수로 매핑하는 선형 분류기 계층(`classifier`)을 정의한다.
   - `forward` 메서드는 모델의 순전파를 정의한다:
     - 첫 번째 그래프 컨볼루션 계층을 적용하고 `tanh` 활성화 함수를 적용한다.
     - 두 번째 그래프 컨볼루션 계층을 적용하고 `tanh` 활성화 함수를 적용한다.
     - 세 번째 그래프 컨볼루션 계층을 적용하고 `tanh` 활성화 함수를 적용한다.
     - 세 번째 그래프 컨볼루션 계층의 출력에 선형 분류기를 적용한다.

3. **모델 초기화**:
   - `GCN` 클래스의 인스턴스를 생성하고 출력한다.

```python
import torch
from torch.nn import Linear
from torch_geometric.nn import GCNConv

class GCN(torch.nn.Module):
  def __init__(self):
    super().__init__()
    torch.manual_seed(1234)
    self.conv1 = GCNConv(dataset.num_features, 4)
    self.conv2 = GCNConv(4, 4)
    self.conv3 = GCNConv(4, 2)
    self.classifier = Linear(2, dataset.num_classes)

  def forward(self, x, edge_index):
    h = self.conv1(x, edge_index)
    h = h.tanh()
    h = self.conv2(h, edge_index)
    h = h.tanh()
    h = self.conv3(h, edge_index)
    h = h.tanh()

    out = self.classifier(h)
    return out, h

model = GCN()
print(model)

_, h = model(data.x, data.edge_index)
print(f'Embedding shape: {list(h.shape)}')
visualizeEmbedding(h, color=data.y)
```

```bash
GCN(
  (conv1): GCNConv(34, 4)
  (conv2): GCNConv(4, 4)
  (conv3): GCNConv(4, 2)
  (classifier): Linear(in_features=2, out_features=4, bias=True)
)

Embedding shape: [34, 2]
```

<p align="center">
<img width="400" alt="1" src="https://github.com/user-attachments/assets/63749506-be60-4d97-9e2f-f1eaf30abc6a">
</p>


# Reference
[Graph Convolutional Networks: Introduction to GNNs](https://mlabonne.github.io/blog/posts/2022-02-20-Graph_Convolution_Network.html)
