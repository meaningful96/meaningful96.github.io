---
title: Chapter 2 Graph Laplacian & Graph Fourier Transform

categories: 
  - Graph
  
tags:
  - [GNN,Graph]
  
toc: true
toc_sticky: true

date: 2023-01-25
last_modified_at: 2023-01-25
---

<span style = "font-size:110%">**Contents**</span>

- Graph Laplacian

- Eigen-decomposition of Laplacian Matrix

- Graph Fourier Transform

- Spectral Graph Filtering

  

<span style = "font-size:110%">**Goal**</span>

Graph Neural Network이론의 기본적인  Background 인 Graph Fourier Transform을 공부한다.1 


## 1. Graph Laplacian

### 1) Graph Feature 표현

<p align="center">
<img width="400" alt="1" src="https://greeksharifa.github.io/public/img/Machine_Learning/2021-08-14-GFT/graph.PNG">
</p>

위와 같은 Graph $$\mathscr{G}$$가 있을 때,  node $$v$$는  feature를 갖고 있다.  

각각의 node가 갖고 있는 feature를 그 node의 **signal**이라고 할 때, node $$v_1$$ 의 signal은 $$f_1$$이라는 함수에 의해 정의된다.



node의 집합 $$\mathscr{V}$$ = [$$v_1, v_2, v_3, v_4$$] 에 대한 **node feature  matrix**는 $$(4,d)$$ 형태의 2차원 행렬이다. 
$$
\mathscr{V} \rightarrow 
\begin{bmatrix}
f_1\\
f_2\\
f_3\\
f_4\\
\end{bmatrix} = f
$$

### 2) Laplacian Matrix   정의

그리고 이 Graph의 인접 행렬(Adjacency Matrix)를 표현하면 다음과 같다.

$$
A = 
\begin{bmatrix}
0&1&1&0\\
0&0&1&0\\
0&1&1&0\\
0&0&1&0\\
\end{bmatrix}
$$

그리고 Graph의 Degree Matrix는 $$D$$이며 이 두 행렬을 이용하여 <span style = "color:aqua">**Laplacian Matrix**</span>를 정의한다.

$$
L = D\;-\;A
$$

cf) Degree Matrix

Given Graph $$G = (V,E)$$  with  $$|V| = n$$, the **degree matrix $$D$$** for **G** is a $$n \times n$$ diagonal matrix defined as
$$
D_{i,j} =
\begin{cases}
deg(v_i) \;\;\;\; if\;\; i = j\\
0	\;\;\;\;\;\;\;\;\;\;\;\; otherwise
\end{cases}
$$

where the degree $$deg(v_i)$$ of a vertex counts the number of times an edge terminates at that vertex. In an undirected graph, this means that each loop increases the degree of a vertex by two. In a directed graph the term *degree* may refer either to indegree (the number of incoming edges at each vertex) or outdegree(the number of outgoing edges at each vertex).

<p align="center">
<img width="300" alt="1" src="https://user-images.githubusercontent.com/111734605/214490586-c016d961-d30b-4378-ae54-784412402ff7.png">
</p>

### 3) Laplacian Matrix를 Difference Operator로 활용 

<p align="center">
<img width="500" alt="1" src="https://user-images.githubusercontent.com/111734605/214491999-6781798b-fb2a-40f9-9ef6-765168cec521.png">
</p>

위에서 $$h$$는 벡터이고, $$h_i$$는 Scalar이다. 여기서 Degree Matrix의 일반적인 특징을 적용해서 $$h_i$$의 식을 정의할 수 있다. 한가지 예시를 들어보면 다음과 같다.

(**Ex1**) $$h_2 = 2f_2 \; - \; f_1 \; - \; f_3$$    

(**일반화**)$$h_i = \displaystyle\sum_{j \in N_i}(f_i \; - \; f_j)$$


## Reference

[Graph Fourier Transform 설명](https://greeksharifa.github.io/machine_learning/2021/08/14/GFT/)

