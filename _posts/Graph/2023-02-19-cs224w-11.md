---
title: (cs224w) Chapter 11. Reasoning in Knowledge Graphs

categories: 
  - Graph
  
tags:
  - [Graph, KG, cs224w]
  
toc: true
toc_sticky: true

date: 2023-02-11
last_modified_at: 2023-02-11
---

cs224w 11주차

- 11.1 Reasoning over Knowledge Graphs
- 11.2 Answering Predictive Queries on Knowledge Graphs
- 11.3 Query2Box: Reasoning over Knowledge Graphs Box Embedding



## 1. Reasoning over Knowledge Graphs

### 1)  Recap of Knowledge Graph Completion

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220048265-9bb0051f-7453-4eb2-8349-2d7495944899.png">
</p>

 Knowledge Graph에 대해 간단하게 복습을 하자면, Head Entity와 Relation이 주어졌을 때(Given <$$h,r$$>) 그 관계성에 알맞는 Tail Entity를 찾는 것이 바로 Knowledge Graph Completion이다.

Link Prediction과 Knowledge Graph Completion은 비슷하지만 조금은 다르다. Link Prediction은 주어진 정보 없이 유실된 relation edge를 찾는 것을 목표로 하는  task를 말한다.

이 KG Completion의 경우는 다르게 말하면 one-hop Reasoning이라고 할 수 있다. head와 relation의 바로 상응하는 tail을 찾는것이기 때문이다. 
그러면 이걸 Multi-hop으로 확장한 것을 수행할 수 있는가에 대한 질문이 나오게 되고 이 질문에 해당하는 것을 바로 Reasoning이라고 한다. 





### 2) Predictive Queries on KG

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220049674-8f1c5dcb-a510-4f9e-a709-c3d1b68c30bd.png">
</p>

<span style = "color:aqua">Reasoning은 다시 말해서 **n-hop**으로 예측 범위를 확대</span>>한 것이다. Reasoning의 예로는 'One-hop Queries', 'Path Queries', 'Conjunctive Queries'있다.

먼저 **One-hop queries**의 경우 Knowledge Graph Completion과는 약간의 뉘앙스 차이가 있다. 
KG Completion은 "head와 relation, tail의 링크가 Knowledge Graph안에 있니?"를 물어보는 것이라면, 
one-hop queries의 경우 "head, relation을 query로 할 때, 이 query에 대한 정답이 tail이니?"를 물어보는 것이다.

두번째로 **Path-queries**이다. 이때부터 Multi-hop에 해당하고, 여기서 시작지점의 Entity를 Anchor entity라고 한다. 
Anchor Entity로부터 N개의 relation을 거쳐서 정답을 찾는 것을 Path queries라고 한다. 예를 들어 'Fulvastrant' 노드를 Anchor entity 주고, 
relation들을 causes(<span style = "color:red">빨간선</span>)와 Associate(<span style = "color:green">초록선</span>) 이 둘을 합쳐서 Query라 했을 때, 
그에 대한 Answer Entity는 두통[Headache], 뇌출혈[Brain Bleeding], 신장 감염[Kidney Infection], 과호흡[Short of Breath] 등의 초록색 네모 Entity들이다.

마지막으로 **Conjunctive Queries**는 앞의 Path queries와는 다르게 Relation이 여러개를 거치는 것이 아닌, 
다수의 head relation쌍이 query러 주어지고 그에 걸맞는 공통된 tail을 예측하는 방법이다.


## 2. Answering Predictive Queries on Knowledge Graphs

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220056489-8c494b7f-a38e-4303-8aeb-793a528a4a03.png">
</p>

Predictive Queries의 경우 일밙넉으로 Knowledge Base Question Answering과 형태가 비슷하고 이 경우에 이제 query에 해당하는 relation들을 따라가 정답을 찾는 것인데, 
만약에 Knowledge Graph가 불완전해서 유실된 엣지가 있을 경우 정답을 못찾는 경우가 발생할 수 있다.

그림에서 보여지는 것이 그 예시로 Headache로 relation을 따라갈 경우 정답을 찾지 못한다. 이 경우 KG Completion을 통해서 완전한 Knowledge Graph를 만들어주고, 
탐색하면 되는데, 문제는 이 경우 시간 복잡도가 너무 커진다.

이를 보완하기 위해 나온 것이 바로 **'Predictive Quereis'**이다. Predictive Queries는 <span style = "color:aqua">불완전한 그래프 상에서 query에 대해,누락된 정보를 내재적으로 연산하여 정답을 예측하는 방법</span>이다. 다르게 말해 강의에 나온 말을 그대로 직역하자면, 누락된 정보를 암시적으로 귀속시키면서 임의 쿼리에 응답하는 방법이다.



### 1) Traversing KG in Vector Space
<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220057879-06732ec7-4a7d-4c2b-a5b8-4e4854ea30fd.png">
</p>

Predictive Querie를 어떤 방식으로 수행할 수 있는지가 관건인데, 그 답은 TransE 모델에서 찾을 수 있다. TransE 모델을 활용하면 임베딩을 통해 합성 관계를 표현할 수 있다. TransE 모델을 사용하기에 적합한  Connectivity Pattern을 잠시 되짚어보면 다음 표와 같다.

<p align="center">
<img width="600" alt="1" src="https://user-images.githubusercontent.com/111734605/220058427-6b0af3a4-c985-492b-b6db-2e0b1dc4f8bd.png">
</p>

Connectivity Pattern 중 Compositional relation pattern이 있는데, 이는 여러 relation을 거쳐서 찾은 tail Entity를 한 번에 연결하는 또 다를 relation이 있을 경우 참이되는 pattern이다.  query가 Anchor entity로부터 relation vector와의 선형 결합으로 이루어진 것으로 표현한다.

이 때, n-hop을 거친 후의 벡터와 가장 가까운 entity 임베딩 벡터를 prediction value, 예측값으로 삼는 것이다. 그림으로 살펴보면 'Fulvestrant' entity에서 <span style = "color:red">Causes</span> relation을 거쳐 <span style = "color:green">Assoiciate</span> relation을 가면 tail entity인 **q**가 된다.  이 때 tail Entity인 q와 가장 가까운 임베딩인 CASP8이나 BIRC2나 PIM1이 정답이 되는 것이다.

- Predictive Queries는 Path-queries를 기반으로 하는 모델

### 2) Conjunctive Queries

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220061247-4af723f2-fa86-4f5f-ad4b-fe502a6c4681.png">
</p>

앞서 Reasoning의 예시로 든 것 중 마지막인 Conjunctive Queries는 Path Queries와는 다른 관계성을 보여준다. 

Path Queries는 relation이 여러 개인 경우를 말한다면, Conjunctive Queries에서는 Anchor Entity가 여러 개인 경우를 말한다. 따라서, Anchor가 다수이므로 각각의 Anchor들과 relation을 따라갔을 때 공통으로 나오는 Entity를 정답, Tail Entity로 삼는 것이다.

예시를 보면 왼쪽은 조금 단순화해서 나타낸 것으로, ESR2는 Associate와 Treated By relation을 따라가면 정답이 나오는 것을 이미지화 해 놓은 그림이다.

이를 진짜 Knowledge Graph에서 본 경우가 오른쪽이고, ESR2가 두 relation을 따라간 결과 총 3개의 Entity가 나온다. 마찬가지로 Short of Breath도 relation을 따라가면 3개의 Entity가 보인다. 이 각각의 3개에서 공통으로 들어가 있는 Entity는 Paclitaxel과 Fulvestrant이므로 두  Entity가 정답 Entity가 되는 것이다.

무조건 두 Entity가 정답이 되는 것은 아니고, 모델에 따라서 Scoring function을 이용해 더 높은 점수가 나온 것을 Answer Entity로 정하기도 한다.



<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220061350-c921a684-6b0b-4274-bde5-f5f30cbd0002.png">
</p>

하지만, 이 Conjunctive Queries의 경우 만약 Knowledge Graph가 불완전하면 ESR2와 Breast Cancer를 연결하는 엣지가 없을 수도 있으며 이럴경우에은 Fulvestrant를 예측하지 못하게 된다.

이 때, Breast Cancer를 보시면 BRCA1을 거쳐 ESR2와 연결되어 있기 때문에 <span style = "color:aqua">둘의 연결관계를 모델이 내재적으로 인지</span>할 수 있어야 한다. 다시 말해, Fulvestrant를 정답으로 이 예측하랴먄, BRCA1을 거치는 Path에 대한 정보가 원래의 정보와 유사하다는 것을 모델에 학습시켜야 한다.



## 3. Query2Box: Reasoning over KGs Box Embeddings

### 1) Box Embedding

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220064419-c442228d-b145-474b-97b2-f250054a4609.png">
</p>

Conjunctive Queries의 단점을 보완하고자 나온 모델이 바로 Query2Box이다. 이 모델의 Key Idea는 Box Embedding을 이용하는 것이다. Query는 entity와 relation으로 이루어져 있고, 이를 임베딩 공간에서 박스로 표현할 수 있다. 일종의 Subgraph 개념이다.

이 때, <span style = "color:aqua">query의 tail entity는 box안에 존재하고, $q = (Center(q), Offset(q))$로 표현할 수 있다. 여기서 Center는 박스의 중심을, Offset은 박스의 크기</span>이다. 박스를 활용할 경우 Conjunctive Queries의 정답을 두 anchor로부터 나오는 예측 tail set들의 교집합으로 쉽게 표현할 수 있다.

Entity 임베딩은 크기가 0인 박스로 취급하며 파라미터 수는 d|V|이다. d는 outdegree이고, |V|는 entity(Vertex)의 수를 의미한다. Relation embedding의 파라미터 수는 2d|R|이며, R은 relations의 수를 의미한다. f는 두개 혹은 여러 개의 박스를 받아 교집합 박스를 output으로 내어주는 함수이다.

### 2) Projection Operator

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220066259-eb334a2a-0fb7-4d9f-ae2b-f27dcc1aeb65.png">
</p>

- Projection Operator P
    - Input: Box & Relation
    - Output: Box의 Center와 Offset을 변형해서 리턴

이를 수식으로 표현하면, 기존 박스에 대한 벡터 q와 relation 벡터를 선형결합한 꼴로 표현할 수 있다.



### 3) Embed with Box Embedding

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220067139-541210e8-1d6d-4285-b323-0468bb22ef57.png">
</p>

'What is the drug that causes short of Breath and treats disease associated with protein ESR2?' 라는 질문에 대한 해답을 찾기 위해서 먼저 Query를 만들어내야 한다.

Knowledge Graph에 의해 Conjunctive Queries를 만들 수 있다. 즉, 정답으로 가능한 Entity relation set이 두 개가 있는 것이고 다음과 같다.

이 관계성들을 Projection Operator를 이용해 표현하면 먼저, ESR2이라는 Entity와 Associate라는 relation으로 이루어진 query를 표현하는 것이다. 여기서 $$q = p(ESR2, Assoc)$$을 통해 tail에 해당하는 노드 집을 담는 center와 offset을 갖는 박스 임베딩이 형성된다.

또다른  Anchor인 'Short of Breath'에서 시작하는 tail에 대한 박스 임베딩도 만들어주고 이 q와 relation인 TreatedBy를 통해 새로운 박스 임베딩 q prime을 만들어 준다.

최종적으로 <span style = "color:aqua">만들어진 초록 박스와 노랑 박스의 **교집합**을 구하는 것이 박스 임베딩</span>의 과정이다.

### 4) Intersection Operator - 1. Center

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220069034-b6ab7b7d-3f7b-4f9f-ac3c-3d60a0d20216.png">
</p>

다음으로는 이를 앞의 Intersection Box를 구하는 것을 수식화 해야한다. 먼저 Center를 정의한다.

Intersection Box, 교집합 박스의 중심은 직관적으로 input box들의 중심과 가까워야 한다. 그래야 박스들이 겹치는 공간이 더 넓어질 수 있기 때문이다. 또한 직관적으로 또 다른 것은 Output 박스인 교집합 박스는 항상 Input 박스들보다 작아야 한다.

이를 이용한다면, 각 박스의 벡터를 함수 $$f_{cen}$$을 통과한 후 softmax를 취해 가중치 벡터 $$w_i$$를 구할 수 있다. $$w_i$$는 neural network를 통해 학습할 수 있는 Trainable한 weight이다.

이 과정을 통해 잘 생각해보면, <span style = "color:aqua">query를 함수에 집어넣고 softmax를 취해 준 것은 **self-attention**과 비슷하기 때문에 각각의 input 박스의 센터에 대한 self-attention score라고 표현</span>>할 수 있다.

$$w_{i}$$를 구한 후 이를  $$Cen(q_i)$$와 Element-Wise Product, 즉 Hadamard Product를 한 후 이를 $$\sum$$를 취해 Summation해 주면 교집합 박스의 중심이 된다.

### 5) Intersection Operator - 2. Offset

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220071250-87cfcb21-040d-46a8-bb33-b1cfede4754f.png">
</p>

다음으로는 offset을 수식화 해야 한다. 직관적으로 offset은 center부분에서 언급했듯이, Input Box들의 size가 교집합 박스의 사이즈보다 항상 크다는 것이다.

바꿔말하면, <span style = "color:aqua">교집합 박스는 항상 Input 박스보다 작다. 교집합 박스는 Input 박스보다 작다.</span> 따라서, 교집합 박스를 구할 때, 그 사이즈는 Input 박스들 중 가장 작은 박스보다도 작기 때문에, Input 박스로 연산을 해 줄 때, 가장 작은 박스의 offset을 이용하는 것이 현명하다.

따라서, Input 박스의 minimum offset을 추출해주고 그 값이 수식상에서 $$min(off(q_1),\cdots,off(q_n))$$이다.

다음으로는  $$f_{off}$$를 이용해서 Input 박스들의 representation을 추출하는데, $$f_{off}$$는 하나의 neural network고 이는 학습 가능하다. $$f_{off}$$를 통해서 Input의 표현을 좀 더 다양화 시키는 역할을 한다.

이를 Sigmoid 함수에 넣어서 일종의 Self-Attention Score를 구해주고 이 값을 핲서 구한 Input 박스의 minimum offset vector와 Hadamard Product를 하면 최종적으로 교집합 박스의 offset이 구해진다.

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220072925-06f99d46-38dd-4339-a49d-1314f8f25db3.png">
</p>

최종 임베딩을 보면 오른쪽의 회색으로 밑줄 친 부분이 된다.

### 6)  Entity-to-Box Distance

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220073084-af07f5b6-888a-4c04-b248-9476e0bd2ed4.png">
</p>

이렇게 임베딩을 최종적으로 했으면, 제대로 된 tail을 찾는 건지 평가할 지표가 필요하다. 따라서, Scoring function을 정해주어야 하는데, Query2Box의 Scoring function은 Negative distsance이다.

즉, head Entity n에서 정답인 q로 이루어지는 거리의 -값을 붙인 것이다. 이 거리는 $$d_{out}$$과 $$d_{in}$$의 선형 결합으로 표현한다.



### 7) And-Or Query

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220073895-c628a869-5061-4ed2-926c-7a77455ba8f9.png">
</p>

그러면 Query가 좀 더 복잡해졌을 때 이걸 임베딩 할 수 있는가? 라는 질문이 나올 수 있다. 예를 들어, 'What drug can treat Breast cancer <span style = "color:aqua">or</span> lung cancer?'라는 질문이 있을 때, or 연산을 할 수 있느냐는 것이다.

옆의 그림을 보면, 낮은 차원의 임베딩 space에서 $$v_1$$과 $$v_2$$는 박스로 묶기 쉽다. 하지만, 만약 $$v_2$$ 와 $$v_4$$를 임베딩한다고 했을 때, $$v_3$$를 포함하지 않고 박스를 만들기는 불가능하다.

즉, m개의 Query에 대해 수행하기 위해서는 m+1차원의 공간이 필요하나 그래프에서 노드의 갸수는 굉장히 많기 때문에 현실적으로 임베딩 차원을 그렇게까지 늘릴 수는 없다.

이를 해결하려면 <span style = "color:aqua">연산의 우선순위(Priority)</span>를 정하면 된다.

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220075056-73fdd118-4d73-4e8b-9cf6-656c241f46d6.png">
</p>

만약 and와 or 연산이 함께 있는 경우에는 and 연산을 우선으로 하여 해결할 수 있다.

- and: 교집합
- or: 합집합

식을 전개해서 Or 연산을 제일 마지막으로 미룬다. 하지만 실제로는 이 Or 연산은 수행하지 않는데, 모든 q에 대해서 각 query와 노드 v의 거리 중 최소 거리를 연산하면 되기 때문이다.

### 8) How to Train?

<p align="center">
<img width="900" alt="1" src="https://user-images.githubusercontent.com/111734605/220075737-d2976314-a2f1-4195-b783-75f39a15d64b.png">
</p>
