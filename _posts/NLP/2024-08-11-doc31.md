---
title: "[NLP]언어 모델을 위한 평가지표 3. 혼잡도(Perplexity)"
categories: 
  - NLP
  
toc: true
toc_sticky: true

date: 2024-08-11
last_modified_at: 2024-08-11
---

# Perplexity란?
<span style="color:gold">**Peplexity(혼잡도, PPL)**</span>는 언어 모델의 성능을 평가할 때 사용하는 지표이다. 즉, **언어 모델이 다음 단어나 문장을 얼마나 잘 예측**하는지를 정량화한 값이다.

- **낮은 Perplexity ($$\downarrow$$)**: 모델이 예측을 더 잘함 (더 정확한 언어 모델, $$\uparrow$$)
- **높은 Perplexity ($$\uparrow$$)**: 모델이 예측을 잘 못함 (성능이 낮은 언어 모델, $$\downarrow$$) 

<center>$$\text{Perplexity}(W) = \exp\!\left(-\frac{1}{N}\sum_{i=1}^{N}\log P(w_i \mid w_{<i})\right)= \left(\prod_{i=1}^{N}\frac{1}{P(w_i \mid w_{<i})}\right)^{\!1/N} = P(w_1,\dots,w_N)^{-\frac{1}{N}}$$</center>

**[시퀀스 전체의 PPL]** Perplexity는 문장의 길이로 정규화된 문장 확률의 역수이다. 문장의 길이를 $$W$$, 길이가 $$N$$이라고 하였을 때, PPL의 수식은 위와 같다. 이는 **시퀀스 전체에 대한 PPL**로, 문장 전체의 평균 예측 난이도를 기하평균의 역수로서, <span style="color:gold">**문장 전체를 평균적으로 얼마나 어렵계 예측**</span>했는지를 측정한다. 음의 log-likelihood의 산술평균을 지수화한 값이며, 크로스 엔트로피의 지수화와 동일합니다. 값이 낮을수록 모델이 문장 전체를 잘 예측했다는 뜻이다.

**[특정 시점 한 토큰에 대한 PPL]**
