---
title: "[NLP]언어 모델을 위한 평가지표 2. BLEU와 ROUGE"
categories: 
  - NLP
  
toc: true
toc_sticky: true

date: 2024-08-11
last_modified_at: 2024-08-11
---

BLEU와 ROUGE는 최근 활발히 연구가 진행되는 **Natural Language Generation(NLG) 모델들을 위한 평가 방법**이다. 즉, Generated Sentence를 평가하는 방식이다. Generative Model은 주로 Supervised Learning 방식으로 정답이 되는 Reference Sentence가 있다. 모델로부터 생성되는 문장을 Generated Sentence 그리고 비교하는 정답을 Reference Sentence라고 한다. 이렇게 생성된 문장을 평가하는 두 방식이 바로 BLEU와 ROUGE인 것이다.

- **BLEU**: Reference Setence의 단어가 Generated Sentence에 포함되는 정도.
- **ROUGE**: Generated Sentence의 단어가 Reference Sentence에 포함되는 정도.


# BLEU 란?

BLEU는 기계 번역의 품질을 평가하는 지표로, 주어진 <span style="color:red">**기계 번역 결과(Generated Sentence)와 하나 이상의 레퍼런스(Reference Sentence) 번역 간의 유사성을 측정**</span>한다. BLEU 점수는 **n-gram 매칭**을 기반으로 하며, **정답과의 일치 비율을 계산**한다. BLEU는 정답과 비교할 때 번역된 문장 내에서 n-gram이 얼마나 잘 매칭되는지를 파악하고, 일반적으로 `Precision`을 측정하여 점수를 계산한다.

BLEU의 핵심 개념 중 하나는 '**Brevity Penalty(길이 패널티)**'이다. 기계 번역이 너무 짧을 경우, 일치하는 n-gram의 비율이 높아져 높은 `Precision`을 얻을 수 있지만, 번역 결과가 의미적으로 부정확해질 수 있다. 이를 방지하기 위해 BLEU는 Brevity Penalty를 도입하여 너무 짧은 번역에 페널티를 부여한다. BLEU 점수는 다음 수식에 의해 계산된다.

<center>$$\text{BLEU} = BP \cdot \exp \left( \sum_{n=1}^{N} w_n \log p_n \right)$$</center>

여기서 $$BP$$가 Brevity Penalty로 정의되며, 이는 다음과 같이 계산된다.

<center>$$BP = \begin{cases} 1 & \text{if } c > r \\
\exp(1 - \frac{r}{c}) & \text{if } c \leq r 
\end{cases}$$</center>

<br/>
<br/>


# ROUGE 란?

ㅓㅗ

<br/>
<br/>
