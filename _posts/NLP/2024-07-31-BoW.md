---
title: "[NLP]Bag of Words(BoW)"
categories: 
  - NLP
  
toc: true
toc_sticky: true

date: 2024-07-31
last_modified_at: 2024-07-31
---

# 단어 표현(Word Representation)

<p align="center">
<img width="600" alt="1" src="https://github.com/user-attachments/assets/21b43297-440c-4c30-affd-023460e90c87">
</p>

컴퓨터는 이진화된 값, 즉 0과 1로 구성된 데이터를 이해하지만, 텍스트를 이러한 방식으로 변환하는 것은 자연어 처리(NLP)에서 여러 가지 문제가 있다. 단순히 컴퓨터가 이해하기 위해 만들어진 **이진값은 언어적 특성을 전혀 반영하지 않기 때문**이다. 자연어 처리의 궁극적인 목표는 컴퓨터가 인간이 만들어낸 고차원적인 언어를 이해하도록 하는 것이다. 이를 위해서는 언어의 특성을 최대한 반영하는 방식으로 자연어를 처리해야 한다.

이 과정에서 중요한 해결책 중 하나가 바로 **"단어 표현(Word Representation)"**이다. 이는 단어의 언어적 특성을 반영하여 수치화하거나 벡터화하는 방법을 찾는 것을 의미한다. 이러한 표현 방식은 "단어 임베딩(Word Embedding)" 또는 "단어 벡터(Word Vector)"라고도 불린다. 단어 임베딩은 단어를 고차원 벡터 공간에 매핑하여 단어 간의 유사성과 의미적 관계를 유지하면서 컴퓨터가 처리할 수 있는 형태로 변환한다.

예를 들어, 단어 임베딩 기법 중 하나인 Word2Vec은 단어를 벡터로 표현하며, 이 벡터들 간의 유사도를 계산할 수 있도록 한다. 이러한 벡터화 방식은 단어의 의미적 유사성을 유지하면서도 연산이 가능하게 한다. 이를 통해 컴퓨터는 단순히 단어를 기계적으로 처리하는 것이 아니라, 단어 간의 관계와 문맥을 이해할 수 있게 한다.


# Reference
[WikiDocs - Bow](https://wikidocs.net/22650)  
