---
title: "[NLP]Word2Vec: CBOW와 Skip-gram"
categories: 
  - NLP
  
toc: true
toc_sticky: true

date: 2024-08-15
last_modified_at: 2024-08-15
---
# Word2Vec에 관하여

<figure style="text-align: center; margin: auto;">
  <img width="1000" alt="1" src="https://github.com/user-attachments/assets/77c76d70-12c4-43d5-b916-60ec2a3aabca" style="display: block; margin: auto;">
  <figcaption style="font-size:70%; text-align: center; width: 100%; margin-top: 0px;">
    <em>Word2vec은 CBOW와 Skip-gram 두 종류로 나눠진다.</em>
  </figcaption>
</figure>

**Word2Vec**는 자연어 처리 분야에서 **단어를 벡터화하는 모델** 중 하나이다. 2013년 구글의 토마스 미콜로프(Thomas Mikolov)와 그의 팀이 개발한 이 모델은 **단어 간의 의미적 유사성을 반영하는 벡터 표현을 생성**하는 것이 주요 목표이다. Word2Vec는 기본적으로 <span style="color:red">**단어를 일정한 크기의 벡터 공간에 임베딩하여 단어 간의 관계를 수치적으로 표현**</span>할 수 있게 한다.

Word2Vec 모델은 크게 두 가지 아케턱처로 나뉜다.

- **CBOW(Continuous Bag of Words)**
- **Skip-gram**

## Architecture 1) CBOW
**CBOW** 모델은 <span style="color:red">**문맥 단어들(문장에서 특정 단어의 주변 단어들, Context Words)을 사용하여 중심 단어(Center Words)를 예측**</span>하는 방식이다. 예를 들어, "The cat sits on the mat"이라는 문장이 있을 때, "cat"이라는 단어를 예측하기 위해 "The", "sits", "on", "the", "mat"과 같은 문맥 단어들이 사용된다. CBOW는 다수의 주변 단어로부터 중심 단어를 예측하기 때문에 빠르고 효과적이다.

<p align="center">
<img width="800" alt="1" src="https://github.com/user-attachments/assets/3fa36b57-6570-4f99-bc85-0d0aea8ccf1e">
</p>

중심 단어를 예측하기 위해서는 앞, 뒤로 몇 개의 단어를 고려할지 정해야 한다. 이를 **윈도우 크기(Window size)**라고 한다. 위의 그림을 예시로 들면, 윈도우 크기가 2인 것이다. 중심 단어를 기준으로 앞 뒤로 최대 두 개의 단어를 고려하기 때문이다. 정해진 윈도우 크기를 바탕으로, 문장 내 위치를 이동하며 중심 단어-주변 단어 쌍을 여러 개 만들어야 한다. 중심 단어를 하나씩 이동하면서 중심-주변 단어 쌍을 만들고, 이를 학습을 위한 데이터셋으로 삼을 수 있다. 이 방법을 슬라이싱 윈도우(Slicing window)라고 한다.


## Architecture 2) Skip-gram
Skip-gram 모델은 CBOW와 반대로, 주어진 중심 단어로부터 주변 단어들을 예측하는 방식이다. 예를 들어, "cat"이라는 단어가 주어졌을 때, 이 단어를 기반으로 "The", "sits", "on", "the", "mat"과 같은 문맥 단어들을 예측한다. Skip-gram은 낮은 빈도의 단어와 문맥 간의 관계를 잘 학습하는 데 유리하다.

# Reference
\[1\] Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean. 2013. Efficient estimation of word representations in vector space. 
\[2\] Blog: [Word2Vec: (2) CBOW 개념 및 원리](https://heytech.tistory.com/352)
