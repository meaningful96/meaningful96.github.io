---
title: "[NLP]Skip-gram 이란?"
categories: 
  - NLP
  
toc: true
toc_sticky: true

date: 2024-08-10
last_modified_at: 2024-08-10
---

# Skip-gram의 개념
**Skip-gram**은 단어의 분산 표현(distributed representation)을 학습하기 위해 사용하는 모델 중 하나이다. 이 모델은 주어진 중심 단어로부터 주변 단어를 예측하는 방식으로 단어 벡터를 학습한다. 이는 Word2Vec 모델의 한 가지 방식으로, <span style="color:red">**중심 단어와 주변 단어 간의 관계를 잘 반영하는 벡터를 학습**</span>하는 것이다.

<figure style="text-align: center; margin: auto;">
  <img width="1000" alt="1" src="https://github.com/user-attachments/assets/c6db86de-60f5-440c-a1c3-3b60c0aaf248" style="display: block; margin: auto;">
  <figcaption style="font-size:70%; text-align: center; width: 100%; margin-top: 0px;">
    <em><a href="#reference" style="text-decoration:none;">[1] ref) Efficient Estimation of Word Representations in Vector Space</a></em>
  </figcaption>
</figure>

# Reference
\[1\] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. [Efficient estimation of word representations in vector space](https://arxiv.org/abs/1301.3781).
