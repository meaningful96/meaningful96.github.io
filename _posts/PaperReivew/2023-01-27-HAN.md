---
title: Heterogeneous Graph Attention Network

categories: 
  - PaperReview
  
tags:
  - [GNN,Graph]
  
toc: true
toc_sticky: true

date: 2023-01-27
last_modified_at: 2023-01-27
---

<span style = "font-size:120%">Paper: Heterogeneous Graph Attention Network</span>

Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Peng Cui, P. Yu, Yanfang Ye (2019, WWW)

## 1. Problem Statement

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/215000073-d1317816-6f8d-434c-904e-a34e3f1828bf.png">
</p>

<span style = "font-size:110%">1) GNN 모델들에 "Attention Mechanism"이 적용된 적이 없다.</span>

Attention Mechanism은 특히 Transformer기반 모델들을 이용하는 자연어 처리 분야나 딥러닝 분야에서는 많이 사용되고 있다. 하지만, GNN 기반의 모델들에는 적용하려는 시도 자체도 적었고, 
특히 Heterogeneous Graph 를 이용하는 분야에는 적용 사례가 없었다.

실제로 세상에 있는 많은 그래프는 Heterogeneous Graph이기 때문에 이 분야에 대한 모델 개선의 필요성이 증가하고 있다. 


<span style = "font-size:110%">2) 전통적인 GNN은 Heterogeneous Graph를 처리하는데 부적합하다.</span>

Heterogeneous Graph의 복잡성 때문에 기존의 전통적인 GNN 기반의 모델들은 직접적인 적용이 어렵다.

## 2. Related Work
- Node Embedding
- GNN
- GAN
- Attetnion Mechanism
- Heterogeneity of Graph

## 3. Method
### Overview

<p align="center">
<img width="700" alt="1" src="https://user-images.githubusercontent.com/111734605/215003117-4b1a43f0-e9b9-44aa-a2dc-a6f7c048e577.png">
</p>
<center><span style = "font-size:80%">Overview of HAN Structure</span></center>

Heterogeneous Graph Attention Network(HAN) 모델의 전체적인 구조를 보면 위와 같다. HAN은 크게 두 가지 Step으로 구성되어 있다.

- Node-Level Attention
- Semantic-Level Attention

Node-Level Attention은 Heterogeneous graph의 노드들의 타입이 여러개이고 이들의 feature의 차원수가 다를 수 있으므로 차원수를 맞춰주기 위해  선형 변환을 해주고, 그런다음 노드들의 정보를 Meta-path 별로 aggregation한다.

Semantic-Level Attention은 앞서 Meta-path 별로 취합 된 정보들을 다시 하나로 aggregation. 이렇게 나온 최종 임베딩 출력값으로 Loss를 Cross-entropy로 하여 MLP를 수행하여 Prediction을 한다.

### Background - Heterogeneous Graph

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/215005601-12367cbf-30e3-4c5b-b3f3-19ca79d6b458.png ">
</p>

Heterogeneous Graph는 왼쪽 그림을 보면 이해하기 쉽다. 노드들이 총 8개로 구성된 그래프인데, 노드들의 Type이 Actor, Movie, Director로 여러 개인 것을 볼 수 있다. 이처럼  <span style = "color:aqua">**노드 타입이 여러개인 그래프**</span>를 **Heterogeneous Graph**이다. 노드의 타입이 여러 개이면 노드와 노드의 <u>관계의 다양성이 증가</u>한다. 다시 말해, 노드마다 타입이 다르기 때문에 모든 엣지들이 같은 유형의 정보만을 표현하지 않는다.

Ex)  
오른쪽 그래프에서 A와 B는 사람 타입의 노드이고, 학회1과 학회2는 학회 이름 타입의 노드이며 NLP는 연구 주제의 노드 타입이다. 즉, 총 3가지의 노드 타입으로 이루어진 그래프이다. A와 B가 무슨 연구 주제를 연구하는지 맞추는 문제를 푼다고 할 때, 만약 NLP라는 노드가 없는 타입 종류가 2개일 때  다른 사람 노드들이 학회1과 학회2에 동시에 투고하는 논문 수가 많아질수록 학습이 잘 되어 'A와 B의 연구주제가 같다' 또는 ''학회1과 학회2는 비슷한 주제를 다룬다''라고 판단한다.(**기존의 방식**)

하지만 NLP라는 노드가 있는 상태에서는 학회1과 학회2가 같은 연구 주제를 다룬다는 정보가 이미 있는 것이다. 즉 학회에 다른 정보가 반영되어 있는 것이기 때문에 A와 B의 유사함을 판단하게 된다.(**Meta-path방식**)

### Background - Meta-Path

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/215018392-d34d744e-77d4-40b5-8fb0-27a5520c8a88.png">
</p>

**Meta-Path**라는 건 Heterogeneous에서 노드 타입별로 일종의 Path를 정의하는 것이다. (d)번을 보면 그 의미를 쉽게 파악할 수 있다.

- Movie - Actor - Movie
- Movie - Director - Movie

이처럼 노드 타입별로 유의미한 정보를 이끌어 낼 수 있는 Path이다. 관계를 가지고 다른 유형의 정보를 추출하는데 용이하게 해준다. 이를 이해하기 쉽게 설명하자면, 영화배우 '드웨인 존슨'을 Actor라는 노드에 그가 출연한 영화들을 각각 Movie 노드에 할당해준다. 이 때 우리는 '드웨인 존슨'이라는 배우가 어떤 영화에 출연했었는지를 안다면, 그가 출연한 영화들 중 내가 모르는 영화가 있더라고 "액션"적 요소가 많이 있는 영화라고 추측할 수 있다.  다른 유형의 정보를 추출하는데 이처럼 Meta-Path는 유용하다.

### Structure - Step1. Node-Level Attention

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/215020477-33ff1cac-ee31-44bd-ab3f-6046e2d0d402.png">
</p>

먼저 Node-Level Attention이다.  먼저 빨간색 부분에 집중해서 보면 $$h_i$$ 는 노드들의 feature이다. 이 feature들은 노드 타입별로 그 사이즈가 다를수도 있다. 즉, 타입별로 Input node feature의 차원 수가 다를 수 있다. 따라서, 선형 변환을 통해 feature들의 크기를 맞춰줘야 한다.

이 선형 변환을 할 때 변환되는 **Weight 같은 경우 노드별로 공유되지 않고** 각각의 노드 타입별로 다르다.  즉, 노드 타입에 따라서 다른 가중치를 부여하지만, 같은 공간으로 임베딩을 시키려고 Projection하는 것이다.

> Due to the heterogeneity of nodes, different types of nodes have different feature spaces. Therefore, for each type of nodes (e.g.,node with type $$\phi_i$$ ), we design the type-specific transformation matrix $$M_{\phi_i}$$ to project the features of different types of nodes into the same feature space. Unlike [13], the type-specific transformation matrix is based on node-type rather than edge-type. 
