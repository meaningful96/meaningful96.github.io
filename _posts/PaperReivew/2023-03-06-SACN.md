---
title: "[논문리뷰]End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion"

categories: 
  - PaperReview
  
tags:
  - [KG Completion]
  
toc: true
toc_sticky: true

published: true

date: 2023-03-06
last_modified_at: 2023-03-06
---

Shang, C. (2018, November 11). End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion. *arXiv present: 1811.04441*  
[Paper]("https://arxiv.org/abs/1811.04441")

# Problem Statement

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/228893474-6f84c0fa-6024-46c6-91fb-ee2fcb72068a.png">
</p>

Knowledge Graph는 현 시점에서 <u>많은 수의 엔티티(Entity, Node)와 릴레이션(Relation, Edge)를 가지고 있다. 또한 그 정보 역시 다양한 Heterogeneous Graph</u>이다. 하지만 기존의 존재하던 Knowledge Base Model들은 모두 Large-Graph에 부적합하다. Graph Embedding모델중에서는 PinSage 모델을 제외하고는 기존 모델들은 모두 Large Scale Graph에 부적합하다. 따라서 새로운  Graph Embedding 모델의 필요하다.

1. Knowledge Graph는 이미 수백만의 Triple을 포함한다.
  - 실제 데이터가 계속해서 추가되기 때문에 그 수가 기하급수적으로 늘어난다.
  - 따라서 KG Completion Task를 푸는 것이 점점 더 중요해진다.
<br/>
2. 기존의 임베딩 모델들은 Large Scale Graph에 부적합하며, ConvE역시 마찬가지이다.
  - ConvE는 Triple의 임베딩 연산이 TransE와는 다르게 translation property가 존재하지 않는다. 
  - TransE의 임베딩 연산은 <span style = "color:aqua">$$e_s + e_r = e_o$$</span>이다. 즉, Subject(head)와 relation의 임베딩의 합이 Object(tail)임베딩과 같다.
  - ConvE는 임베딩 공간에서 KG의 연결성을 설명하는데 부적합하다.  

<br/> 
<br/> 


# Relation Work

- Knowledge Graph Embedding
- TransE, TransR, TransD, TransH
- DistMult, ComplEx
- convKB, convE
- GCN

# Method
## 1. Overview
<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229112137-e06272cc-b40b-4ff4-b475-e8e0f961fa1c.png">
</p>

모델의 아키텍쳐는 크게 두 부분으로 나누어지며, Encoder-Decoder 모델이다. Encoder는 <span style = "color:aqua">**WGCN**</span>으로 기존의 GCN에 Weight(가중치)를 추가하여 수정한 구조이다. 그리고 디코더는 <span style = "color:aqua">**SACN**</span>이라고 불리며 이는 Structure-Aware Convolution Network이다.

이 모델의 전체적인 구조를 단 한 줄로 설명하자면 <span style = "color:gold">**ConvE의 prediction performance에 TransE의 Translation Property를 병합**</span>시킨 모델이다.

## 2. Encoder: WGCN

### 1) GCN vs WGCN

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229114946-de11cdb5-9fd9-4541-b6bd-017effeafb38.png">
</p>

Encoder는 GCN모델의 성능을 향상시켜만든 모델이다. **Weighted GCN**의 약자이며, 이름 그대로 가중치에 대한 정보를 GCN에 추가한 것이다. 그림을 보면 빨간색 노드가 중심노드가 된다. GCN은 Graph Embedding 모델의 한 종류이다. 즉, 하나의 노드를 기준으로 이웃 노드들의 대한 정보를 Aggregation한다.

마찬가지로 WGCN도 이웃 노드들의 정보를 Aggregation한다. 기존의 GCN과 다른점은 WGCN은 <span style = "color:gold">**중심 노드를 기준으로 이웃 정보를 취합할 때 Relation Type마다 이웃 노드들에 가중치(Weight)를 부여**</span>한다. 이로서 어떤 이웃노드들이 중심노드에 더욱 더 큰 영향력을 행사하는지 파악할 수 있다. 가중치는 Learning parameter이다.

그림에서 예시를 들면, 빨간색 노드가 중심노드이고, 중심 노드에대해 이웃들의 relation은 총 3가지 종류가 있으며 각각이 <span style = "color:blue">Blue</span>, <span style = "color:green">Green</span>, <span style = "color:orange">Orange</span> 노드로 표현되어 있다. 

```
WGCN (Weighted Graph Convolutional Network) determines how much weight to assign to each subgraph 
when combining the GCN (Graph Convolutional Network) embeddings for a node. This approach enhances 
the learning capabilities of the model by emphasizing important subgraphs and their relationships 
within the network, ultimately improving the overall performance in tasks such as node classification, 
link prediction, or graph clustering.
```

<br/>

### 2) Mechanism of WGCN

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229121357-e318a6b9-199e-4154-a03e-7898687ca682.png">
</p>

WGCN은 여거래의 Layer가 쌓여져있는 형태이다. 먼저 하나의 노드에서 Aggregation되는 과정을 살펴보면, $$l^{th}$$ 레이어의 입력은 이전 레이어에서 나온 크기가 $$F^l$$인 벡터가 된다. 그렇게 들어온 입력이 WGCN을 거치면 $$F^{l+1}$$ 번째의 성분이 입력 벡터에 추가된다. 다시 말해, 레이어를 하나씩 거칠때마다 출력 벡터의 성분 개수가 하나씩 늘어난다.

$$v_i$$노드에 대한 임베딩을 수식으로 나타내면 다음과 같다. $$\alpha_t^l$$은 새롭게 추가된 parameter인 **가중치(weight)** 이다. $$t$$는 edge type의 개수로 총 $$T$$개가 있다. GCN과 마찬가지로 기본적인 Operation은 <u>1)Weighted Sum을 하고 2)Nonlinearity를 먹이는 모양</u>이다. 식의 의미를 해석하자면, **$$i$$노드를 중심으로 모든 이웃 노드의 정보를 가중치를 부여해 취합하고, Nonlinearity를 먹여 신경망의 표현 능력을 향상**시킬 수 있는 출력값을 만들어 내는것이다.

<p align="center">
<img width="400" alt="1" src="https://user-images.githubusercontent.com/111734605/229144812-d0184cdc-a24b-4a97-baaa-2226f83af125.png">
</p>

이 식을 보면 한 가지 문제점이 발생한다. 바로 중심 노드가 이웃 노드들의 정보만 취합하고, 자기 자신에 대한 정보를 취합하지 못했다는 것이다. 따라서, 중심 노드의 정보를 담을
수 있는 term을 추가해 줘야 하고 이를 <span style = "color:aqua">Self-Loop</span>라고 한다.

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229153105-427d88fc-d409-4788-84df-e836eb33d312.png">
</p>

최종적으로 위의 식처럼 이웃 노드들의 정보를 가진 term과 $$v_i$$자신에 대한 정보를 가진 term으로 표현된다. $$A_t$$는 노드들의 연결 정보가 담겨져 있는 인접행렬(Adjacency matrix)이다. 이때, Self-Loop에 대한 정보까지 담아 둔 행렬을 $$A_l$$라 하고, 정리하면 오른쪽 위의 식처럼된다. 이를 $$h_i^l$$에 대입해서 정리한 후, 하나의 노드에 대해서가 아닌 레이어 전체 연산으로 바꾸어 행렬식으로 나타내면 최종 임베딩 식이 나온다. 수식을 다시 한 번 정리하면 다음과 같다.

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/229178421-e0044236-539a-4692-a7f7-f54858cf0d10.png">
</p>

이를 좀 더 직관적으로 이해하기 위해서 행렬식으로 정리하는 과정을 그림으로 나타내면 다음과 같다. $$N \times N$$ 의 크기를 가지는 Self-loop가 포함된 인접행렬에 크기가 $$N \times F^l$$인 $$H^l$$을 곱하고 거기에 크기가 $$F^l \times F^{l+1}$$인 $$W^l$$을 곱하고 각 요소마다 Nonlinearity를 먹이면 인코더의 최종 임베딩인 $$H^{l+1}$$이 나온다.

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229179346-17f47d6d-64af-4d3d-8211-b1679226b780.png">
</p>

<br/>

### 3) Node Attribute

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229181786-4d2c8bfc-a78c-480d-b320-b13879f154af.png">
</p>

Knowledge Graph에서 노드들은 종종 ($$entity(subject), relation, attribute(object)$$)형태 여러 속성과 연결된다. 예를 들어, (s = Tom, r = people.person.gender, o = male)
이다. 이를 해석하면, <u>'Subject인 Tom과 Object인 male은 성별이라는 관계가 있다.'</u>로 해석할 수 있다. 

만약에 **Node Attribute**가 Node 정보를 나타내는 **Vector Representation**가 같으면 2가지 문제가 발생한다. 먼저 <u>각 노드의 Node Attribute의 수 일반적으로 매우 적으며, 각 노드마다 다르다</u>는 것이다. 이러한 이유로 Attribute Vector는 매우 Sparse하다.

두번째로 <u>Attribute Vector에서 성분이 0이면 그 의미가 매우 모호해진다</u>는 것이다. 예를 들어 그 값이 0일 경우 노드가 구체적인 Attribute가 없는것이거나 또는 attribute에 대한 값을 노드가 유실한 것 둘 모두로 해석될 수 있다.

이 논문에서는 Knowledge Graph의 node attribute가 다른 node set으로 표현되고 그걸 'attribute node'라고 표현한다. Attribute nodes는 연관된 엔티티들과 연결을 해주는 일종의 **다리(bridge)** 역할을 한다.

```
Because these attributes exhibit in triplets, we represent the attributes 
similarly to the representation of the entity o in relation triplets. Note 
that each type of attribute corresponds to a node.
```

왜냐하면 이 attribute들이 triple로 표현되며, triple에 관련하여 object의 표현과 유사한 속성을 나타낸다. 예를 들어, 'male'과 'female'은 두 개의 노드가 아닌 단일 노드로 표시된다. 이러한 방식으로 <span style ="color:gold">**WGCN은 그래프의 Connectivity structure를 이용할 뿐만 아니라 note attribute를 효과적으로 사용**</span>한다. 이렇기 때문에 WGCN이 **Structure-Aware Convolution network**라고 불리는 것이다.

## 3. Decoder: Conv-TransE
### 1) Model Concept

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229191669-2d5bab03-bb53-4120-8f85-9358bf171fb7.png">
</p>

디코더는 **Conv-TransE**라는 아키텍쳐를 사용한다. 이 모델은 기존에 존재하던 Graph Embedding 모델인 ConvE에 기반해서 만들어졌다. 거기에 TransE모델의 장점인 Translation Property를 가져와 사용하는 모델이다. 즉, Conv-TransE는 <span style = "color:gold">**ConvE모델의 장점과 TransE모델의 장점을 모두 취한 새로운 아키텍쳐**</span>라고 할 수 있다. ConvE모델과 다른 점은 트리플을 임베딩해서 나온 임베딩 벡터 $$e_s$$와  $$e_r$$을 stacking한 후에 reshape을 할 필요가 없다는 것이다.

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229192567-ce01aa66-289a-4ee6-a44d-40cdaf729c8a.png">
</p>

디코더는 총 두 개의 입력을 받는다. 첫 번째 입력은 WGCN의 결과로 나운 임베딩 행렬(Embedding Matrix)이다. 임베딩 행렬의 크기는 각각의 노드가 $$F^l$$ 차원의 임베딩을 가지고 총 N개의 노드가 있는 것이므로 $$\mathbb{R}^{N \times F^L}$$이다. 두 번째 입력은 릴레이션 임베딩 행렬(Relation Embedding Matrix)이다. <u>Mini-batch stochastic train algorithm을 사용하기 때문에 릴레이션 임베딩 행렬도 학습된다.</u> 

디코더의 첫 번째 단계는 미니 배치에 있는 Triplet들의 $$e_s$$와 $$e_r$$을 찾기위해 임베딩 행렬을 참조하는 Look-up 연산을 수행한다. 더 정확하게는 서로 다른 $$C$$개의 커널(Kernel)이 있고, $$c$$ 번째 커널은  $$w_c$$로 파라미터(Parameterized)로 정의된다고하면 다음의 위의 식을 따른다. $$K$$는 커널의 폭이고, $$n$$은 출력 벡터의 항목을 인뎅싱한다. 

- $$K$$ = Kernel Width. 논문에서는  $$2 \times k$$의 Kernel size를 정의하고, $$k$$는 1,3,5 세 가지로 실험을 진행했다.
- $$n$$ = Indexing the entries of output vector, $$n \in [0, F^L - 1]$$ 이다.
- $$w_c$$는 학습 가능하다. 
- $$\hat{e_s}$$ 


<br/> 
<br/> 

# Experiment & Result

as

<br/> 
<br/> 

# Contribution

as

<br/> 
<br/> 

