---
title: "[논문리뷰]End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion"

categories: 
  - PaperReview
  
tags:
  - [KG Completion]
  
toc: true
toc_sticky: true

published: true

date: 2023-03-06
last_modified_at: 2023-03-06
---

Shang, C. (2018, November 11). End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion. *arXiv present: 1811.04441*  
[Paper]("https://arxiv.org/abs/1811.04441")

# Problem Statement

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/228893474-6f84c0fa-6024-46c6-91fb-ee2fcb72068a.png">
</p>

Knowledge Graph는 현 시점에서 <u>많은 수의 엔티티(Entity, Node)와 릴레이션(Relation, Edge)를 가지고 있다. 또한 그 정보 역시 다양한 Heterogeneous Graph</u>이다. 하지만 기존의 존재하던 Knowledge Base Model들은 모두 Large-Graph에 부적합하다. Graph Embedding모델중에서는 PinSage 모델을 제외하고는 기존 모델들은 모두 Large Scale Graph에 부적합하다. 따라서 새로운  Graph Embedding 모델의 필요하다.

1. Knowledge Graph는 이미 수백만의 Triple을 포함한다.
  - 실제 데이터가 계속해서 추가되기 때문에 그 수가 기하급수적으로 늘어난다.
  - 따라서 KG Completion Task를 푸는 것이 점점 더 중요해진다.
<br/>
2. 기존의 임베딩 모델들은 Large Scale Graph에 부적합하며, ConvE역시 마찬가지이다.
  - ConvE는 Triple의 임베딩 연산이 TransE와는 다르게 translation property가 존재하지 않는다. 
  - TransE의 임베딩 연산은 <span style = "color:aqua">$$e_s + e_r = e_o$$</span>이다. 즉, Subject(head)와 relation의 임베딩의 합이 Object(tail)임베딩과 같다.
  - ConvE는 임베딩 공간에서 KG의 연결성을 설명하는데 부적합하다.  

<br/> 
<br/> 


# Relation Work

- Knowledge Graph Embedding
- TransE, TransR, TransD, TransH
- DistMult, ComplEx
- convKB, convE
- GCN

# Method
## 1. Overview
<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229112137-e06272cc-b40b-4ff4-b475-e8e0f961fa1c.png">
</p>

모델의 아키텍쳐는 크게 두 부분으로 나누어지며, Encoder-Decoder 모델이다. Encoder는 <span style = "color:aqua">**WGCN**</span>으로 기존의 GCN에 Weight(가중치)를 추가하여 수정한 구조이다. 그리고 디코더는 <span style = "color:aqua">**SACN**</span>이라고 불리며 이는 Structure-Aware Convolution Network이다.

이 모델의 전체적인 구조를 단 한 줄로 설명하자면 <span style = "color:gold">**ConvE의 prediction performance에 TransE의 Translation Property를 병합**</span>시킨 모델이다.

## 2. Encoder: WGCN

### 1) GCN vs WGCN

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229114946-de11cdb5-9fd9-4541-b6bd-017effeafb38.png">
</p>

Encoder는 GCN모델의 성능을 향상시켜만든 모델이다. **Weighted GCN**의 약자이며, 이름 그대로 가중치에 대한 정보를 GCN에 추가한 것이다. 그림을 보면 빨간색 노드가 중심노드가 된다. GCN은 Graph Embedding 모델의 한 종류이다. 즉, 하나의 노드를 기준으로 이웃 노드들의 대한 정보를 Aggregation한다. 마찬가지로 WGCN도 이웃 노드들의 정보를 Aggregation한다. 기존의 GCN과 다른점은 WGCN은 <span style = "color:gold">**중심 노드를 기준으로 이웃 정보를 취합할 때 Relation Type마다 이웃 노드들에 가중치(Weight)를 부여**</span>한다. 이로서 어떤 이웃노드들이 중심노드에 더욱 더 큰 영향력을 행사하는지 파악할 수 있다. 가중치는 Learning parameter이다.

그림에서 예시를 들면, 빨간색 노드가 중심노드이고, 중심 노드에대해 이웃들의 relation은 총 3가지 종류가 있으며 각각이 <span style = "color:blue">Blue</span>, <span style = "color:green">Green</span>, <span style = "color:orange">Orange</span> 노드로 표현되어 있다. 


- WGCN determines how much weights to give to each subgraph when combining the GCN embeddings for a node.

<br/>

### 2) Mechanism of WGCN

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/229121357-e318a6b9-199e-4154-a03e-7898687ca682.png">
</p>


<br/> 
<br/> 

# Experiment & Result

as

<br/> 
<br/> 

# Contribution

as

<br/> 
<br/> 

