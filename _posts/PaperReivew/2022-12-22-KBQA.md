---
title: (논문 리뷰)Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals 

categories: 
  - PaperReview
  
tags:
  - [KBQA]
  
toc: true
toc_sticky: true

date: 2022-12-22
last_modified_at: 2022-12-22 
---

## 1. 논문을 들어가기 앞서 알면 좋은 Basic Knowledge
- [Graph의 개념](https://meaningful96.github.io/datastructure/2-Graph/)
- [Cross Entropy, Jensen-Sharnnon Divergence](https://drive.google.com/file/d/18qhdvC_2B9LG7paPdAONARqj3DWxxa8h/view?usp=sharing)
- Knowledge Based Learning
- Reward Shaping
- Action Dropout
- [BFS, DFS](https://meaningful96.github.io/datastructure/2-BFSDFS/)
- [Bidirectional Search in Graph](https://meaningful96.github.io/datastructure/3-Bidirectionalsearch/)
- GNN
- Various Types of Supervision in Machine Learning

<span style = "font-size:120%">**Graph**</span>

<p align="center">
<img width="500" alt="1" src="https://user-images.githubusercontent.com/111734605/208984702-642c1b33-0940-4469-a731-91dca6bfdad8.png">
</p>
```
그래프는 연결할 객체를 나타내는 정점(Vertex, Node)와 객체를 연결하는 간선(Edge)의 집합으로 구성된다.
그래프 G를 다음과 같이 정의한다.
```
$$G = G(V,E) $$  
여기서 V는 정점의 집합(Vertex Set)이고, E는 간선들의 집합(Edge Set)이다.

**용어 정리**
- **노드(node)**: 정점(vertice)라고도 불리며, 일반적으로 노드에는 데이터가 저장됨
- **간선(edge)**: 링크, arcs라고도 불리며, 노드간의 관계를 나타냄
- **인접 정점(adjacent vertex)**: 간선에 의해 연결된 정점.
- **단순 경로(simple-path)**: 경로 중 반복되는 정점이 없는것, 같은 간선을 자나가지 않는 경로
- **차수(degree)**: 무방향 그래프에서 하나의 정점에 인접한 정점의 수. 위 그래프에서 A의 차수는 3이다.
- **진출차수(out-degree)/진입차수(in-degree)**: 방향그래프에서 사용되는 용어
  - 진출 차수 는 한 노드에서 외부로 향하는 간선의 수,
  - 진입차수 는 외부 노드에서 들어오는 간선의 수

**그래프의 특징**
- 그래프는 <span style = "color:aqua">**네트워크 모델**</span> 즉, 객체와 이에 대한 관계를 나타내는 유연한 방식으로 이해할 수 있다.   
- 그래프의 순회는 DFS(깊이 우선 탐색), BFS(너비 우선 탐색)으로 할 수 있다.  
- 그래프에는 루트 노드, 부모-자식의 개념은 존재하지 않는다.
- 트리는 그래프의 한 종류이다.

<span style = "font-size:120%">Cross Entropy</span>

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/209002976-5b2ac8df-418f-498f-8950-cbd269693985.png">
</p>

이 때, KL divergence의 문제점은 symmetric하지 않기 때문에, 유사도를 이야기할 때 **거리**라고 표현하지 않는다.  
이 거리 개념 <span style = "color:aqua">Distance Metric으로 쓸 수 있는 방법</span>으로 나온 것이 **Jensen-Shannon Divergence**이다.

<center><span style="font-size:120%"> $$JSD(P,Q) = \frac{1}{2} D(P||M) + \frac{1}{2} D(Q||M)$$ </span></center>  
<center><span style="font-size:120%"> $$where M = \frac{1}{2} (P+Q)$$ </span></center>  

수식에서 보여지듯이, P와 Q의 평균값을 뜻하는 M과 KL-divergence를 함으로써 Symmetric해지는 성질을 확인 할 수 있다.

<center><span style="font-size:120%"> $$JSD(P,Q) = JSD(Q,P)$$ </span></center>  
이를 통해 <span style = "color:aqua">**두 확률 분포 사이의 거리(Distance)**를 유사도 척도로 활용</span>할 수 있다.

<span style = "font-size:120%">Knowledge Based Learning</span>

지식 기반 시스템(KBS)은 의사 결정을 지원하기 위해 인간 전문가의 지식을 포착하는 것을 목표로 하는 인공지능(AI)의 한 형태이다.

지식 기반 시스템의 예로는 전문가 시스템이 있는데, 이는 인간의 전문 지식에 대한 의존 때문에 소위 말하는 것이다.

문제 해결 방법을 알려주는 지식 기반 시스템의 전형적인 아키텍처는 지식 기반과 추론 엔진을 포함한다.
첫 번째 "지식 베이스"의 경우 세계에 관한 사실을 표현한다. 
두 번째 "추론 엔진"의 경우 새로운 지식을 추론할 수 있게 한다.

전문가 시스템: 보통은 전문 지식이 필요한 것으로 간주되는 복잡한 작업에 대해 인간 전문가를 돕거나 대체할 목적으로 시스템이 지원을 시도하는 태스크의 종류를 가리킨다.

지식 기반 시스템: 절차적 코드가 아닌, 분명하게 지식을 표현하는 시스템의 구조를 가리킨다.

<span style = "font-size:120%">Reward Shaping</span>
Reward shaping is an efficient way to incorporate domain knowledge into a reinforcement learning agent.
보상 형성은 도메인 지식을 강화 학습 에이전트에 통합하는 효율적인 방법이다.

In order to enrich the reward function, we develop a novel reward shaping approach to provide informative reward signal for the reinforcement learning agent.
보상 기능을 풍부하게 하기 위해 우리는 강화 학습 에이전트에 유익한 보상 신호를 제공하는 새로운 보상 형성 접근 방식을 개발한다.

## 2. Abstract
Multi-hop Knowledge Base Question Answering (KBQA) Problem의 목표는 지식 기반의 Question의 entity에서 여러 hop(홉)만큼 떨어져 있는 answer entity를 찾는 것이다.  

```Major Challenge: Lack of Supervision signals at intermediate steps.```

이 문제점 때문에, mulit-hop KBQA 알고리즘은 마지막 final answer로부터만 feedback 을 받을 수 있다는 것이고, 이는 학습에 비효율적이고 불안정하게 만든다.




