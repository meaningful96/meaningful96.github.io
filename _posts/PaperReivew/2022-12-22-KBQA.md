---
title: (논문 리뷰)Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals 

categories: 
  - PaperReview
  
tags:
  - [KBQA]
  
toc: true
toc_sticky: true

date: 2022-12-22
last_modified_at: 2022-12-22 
---

## 1. 논문을 들어가기 앞서 알면 좋은 Basic Knowledge
- [Graph의 개념](https://meaningful96.github.io/datastructure/2-Graph/)
- [Cross Entropy, Jensen-Sharnnon Divergence](https://drive.google.com/file/d/18qhdvC_2B9LG7paPdAONARqj3DWxxa8h/view?usp=sharing)
- [Knowledge Based Learning](https://meaningful96.github.io/etc/KB/)
- [Reward Shaping](https://meaningful96.github.io/etc/rewardshaping/#4-linear-q-function-update)
- [Action Dropout](https://meaningful96.github.io/deeplearning/dropout/#4-test%EC%8B%9C-drop-out)
- [GloVe]()
- [BFS, DFS](https://meaningful96.github.io/datastructure/2-BFSDFS/)
- [Bidirectional Search in Graph](https://meaningful96.github.io/datastructure/3-Bidirectionalsearch/)
- [GNN]()
- [Various Types of Supervision in Machine Learning]()
- [End-to-end deep neural network](https://meaningful96.github.io/deeplearning/1-ETE/)
- [NSM(Neural State Machine)]()



<span style = "font-size:120%">**Graph**</span>

<p align="center">
<img width="500" alt="1" src="https://user-images.githubusercontent.com/111734605/208984702-642c1b33-0940-4469-a731-91dca6bfdad8.png">
</p>
```
그래프는 연결할 객체를 나타내는 정점(Vertex, Node)와 객체를 연결하는 간선(Edge)의 집합으로 구성된다.
그래프 G를 다음과 같이 정의한다.
```
<center>$$G = G(V,E) $$</center>  

여기서 V는 정점의 집합(Vertex Set)이고, E는 간선들의 집합(Edge Set)이다.

**용어 정리**
- **노드(node)**: 정점(vertice)라고도 불리며, 일반적으로 노드에는 데이터가 저장됨
- **간선(edge)**: 링크, arcs라고도 불리며, 노드간의 관계를 나타냄
- **인접 정점(adjacent vertex)**: 간선에 의해 연결된 정점.
- **단순 경로(simple-path)**: 경로 중 반복되는 정점이 없는것, 같은 간선을 자나가지 않는 경로
- **차수(degree)**: 무방향 그래프에서 하나의 정점에 인접한 정점의 수. 위 그래프에서 A의 차수는 3이다.
- **진출차수(out-degree)/진입차수(in-degree)**: 방향그래프에서 사용되는 용어
  - 진출 차수 는 한 노드에서 외부로 향하는 간선의 수,
  - 진입차수 는 외부 노드에서 들어오는 간선의 수

**그래프의 특징**
- 그래프는 <span style = "color:aqua">**네트워크 모델**</span> 즉, 객체와 이에 대한 관계를 나타내는 유연한 방식으로 이해할 수 있다.   
- 그래프의 순회는 DFS(깊이 우선 탐색), BFS(너비 우선 탐색)으로 할 수 있다.  
- 그래프에는 루트 노드, 부모-자식의 개념은 존재하지 않는다.
- 트리는 그래프의 한 종류이다.



<span style = "font-size:120%">**Cross Entropy**</span>

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/209002976-5b2ac8df-418f-498f-8950-cbd269693985.png">
</p>

이 때, KL divergence의 문제점은 symmetric하지 않기 때문에, 유사도를 이야기할 때 **거리**라고 표현하지 않는다.  
이 거리 개념 <span style = "color:aqua">Distance Metric으로 쓸 수 있는 방법</span>으로 나온 것이 **Jensen-Shannon Divergence**이다.

<center><span style="font-size:120%"> $$JSD(P,Q) = \frac{1}{2} D(P||M) + \frac{1}{2} D(Q||M)$$ </span></center>  
<center><span style="font-size:120%"> $$where \,M = \frac{1}{2} (P+Q)$$ </span></center>  

수식에서 보여지듯이, P와 Q의 평균값을 뜻하는 M과 KL-divergence를 함으로써 Symmetric해지는 성질을 확인 할 수 있다.

<center><span style="font-size:120%"> $$JSD(P,Q) = JSD(Q,P)$$ </span></center>  
이를 통해 <span style = "color:aqua">**두 확률 분포 사이의 거리(Distance)**를 유사도 척도로 활용</span>할 수 있다.



<span style = "font-size:120%">**Knowledge Based Learning**</span>  
의사 결정을 지원하기 위해 인간 전문가의 지식을 포착하는 것을 목표로 하는 인공지능(AI)의 한 형태이다. 지식 기반 시스템의 예로는 전문가 시스템이 있는데, 이는 인간의 전문 
지식에 대한 의존 때문에 소위 말하는 것이다.

문제 해결 방법을 알려주는 지식 기반 시스템의 전형적인 아키텍처는 지식 기반과 추론 엔진을 포함한다.
첫 번째 "지식 베이스"의 경우 세계에 관한 사실을 표현한다. 
두 번째 "추론 엔진"의 경우 새로운 지식을 추론할 수 있게 한다.

전문가 시스템: 보통은 전문 지식이 필요한 것으로 간주되는 복잡한 작업에 대해 인간 전문가를 돕거나 대체할 목적으로 시스템이 지원을 시도하는 태스크의 종류를 가리킨다.
지식 기반 시스템: 절차적 코드가 아닌, 분명하게 지식을 표현하는 시스템의 구조를 가리킨다.



<span style = "font-size:120%">**Reward Shaping**</span>  
Reward shaping is an efficient way to incorporate domain knowledge into a reinforcement learning agent.
보상 형성은 도메인 지식을 강화 학습 에이전트에 통합하는 효율적인 방법이다.

In order to enrich the reward function, we develop a novel reward shaping approach to provide informative reward signal for the reinforcement learning agent.
보상 기능을 풍부하게 하기 위해 우리는 강화 학습 에이전트에 유익한 보상 신호를 제공하는 새로운 보상 형성 접근 방식을 개발한다.

## 2. Abstract
Multi-hop Knowledge Base Question Answering (KBQA) Problem의 목표는 지식 기반의 Question의 entity에서 여러 hop(홉)만큼 떨어져 있는 answer entity를 찾는 것이다.  

```Major Challenge: Lack of Supervision signals at intermediate steps.```

이 문제점 때문에, mulit-hop KBQA 알고리즘은 마지막 final answer로부터만 feedback 을 받을 수 있다는 것이고, 이는 학습에 **비효율적이고 불안정**하게 만든다.

**Suggested Solution**
- Novel teacher-student approach for the multi-hop KBQA task
- Student network는 query(질의)에 관한 정확한 답을 찾는 것을 목표로한다.
- <span style = "color:aqua">Teatch network</span>는 동시에 중간 단계의(Intermediate) student network의 추론 능력을 향상시키기 위해 supervision signal을 학습한다.
- Major novelty는 teacher network에 있다.
- Bidirectional reasoning을 통해 그 효율을 증대시킨다.

### Keyword
**Knowledge Base Question Answering**, **Teacher-student Network**, **Intermediate Supervision Signals**

## 3. Introduction

<p align="center">
<img width="600" alt="1" src="https://user-images.githubusercontent.com/111734605/209012402-dc7d7449-e253-439a-8b5e-e6ea6b919b6f.png">
</p>

최근에, End-to-end deep neural network(종단간 심층 신경망)은 Multi-hop KBQA 문제에 대해서 paramter를 자동으로 학습하기에 각광받고 있다.

Multi-hop KBQA라고 불리는 **멀티홉 추론 절차를 필요로 하는 복잡한 문제를 해결하는 것**에 대한 관심이 증가하고 있다. 최종 답변 외에도, 멀티홉 KBQA 알고리즘이 
**답변 엔티티로 이어지는 합리적인 관계 경로를 식별**할 수 있는 것도 중요하다. 경우에 따라서 정답이 올바르게 발견된 경우에도 그 경로는 거짓일 수 있다.  
```In some cases, even if the answer was correctly found, the relation path might be spurious. ```  

- Ex) Figure 1 pic
  1. 문제: In some cases, even if the answer was correctly found, the relation path might be spurious. 
  2. 정답: 빨간색 경로
  3. 오답: 파란색 경로, 회색 경로
 
➜ 그것은 주로 <span style = "color:aqua">**중간 추론 단계(Intermediate reasoning steps)에서 supervision signals가 부족**</span>하기 때문이다.

- Multi-hop KBQA task의 경우 훈련 데이터는 일반적으로 이상적인 대신 ⟨ $$question, answer$$ ⟩ 의 형태이다.
- 따라서 멀티홉 추론 알고리듬은 이러한 데이터 세트를 사용하여 최종 답변에서만 피드백을 받을 수 있다.

이러한 문제점들을 해결하기 위해서 다양한 연구에서 다양한 방법이 제시되었지만, 여전히 중간 단계에서 효과적인 supervision signal이 부족했다. 따라서 본 논문에서는
다음과 같은 방향을 잡고 연구를 진행하였다.

- 메인 모델은 쿼리에 대한 올바른 답을 찾는 것을 목표로 하고, 보조 모델은 메인 모델의 추론 능력을 향상시키기 위해 중간 감독 신호를 학습하려고 한다.
- 구체적으로, 보조 모델은 중간 단계의 어떤 엔티티가 질문과 더 관련이 있는지를 추론하며, 이러한 엔티티는 중간 감독 신호로 간주된다.
  1. 이 아이디어는 attractive 하지만, training을 위한 레이블이 지정된 데이터가 없기 때문에 효과적인 보조 모델을 배우는 것은 어렵다.
  2. Key idea from `양방향 탐색(Bidirectional Search)`
  3. Topic Entity(Query Entity) ➜ Answer Entity : <span style = "color:aqua">전진 추론</span>
  4. Answering Entity ➜ Topic Entity : <span style = "color:aqua">후진 추론</span>

### Idea
- Student Network: NSM(Neural State Machine)을 적용
  - 학생 네트워크는 교사 네트워크에서 학습된 중간 엔티티 분포에 따라 자체를 개선할 수 있다.

## 4. Mechanism
### 1) Overview
- Multi-hop KBQA 과제 자체에 집중하는 학생 네트워크를 훈련한다 
- 다른 교사 네트워크는 학생 네트워크를 개선하기 위한 중간 추론 단계에서 Supervision signal(즉, 우리의 과제에서 추론된 엔티티 분포)를 제공하도록 훈련한다.
  1. Knoledge Base를 그래프로 간주하여 Multi-hop KBQA 작업에 적용
  2. Multi-hop 추론 과정에서 엔티티에 대해 점진적으로 학습된 엔티티 분포를 유지
  3. Teacher Network를 개발하기 위해 새로운 양방향 추론 메커니즘을 통합하여 NSM의 아키텍처를 수정하여 중간 추론 단계에서 보다 신뢰할 수 있는 엔티티 분포를 학습 가능
  4. 이는 이후 Student Network에서 Supervision signal로 사용
 
### 2) Neural State Machine for Multi-hop KBQA - Student Network

<p align="center">
<img width="600" alt="1" src="https://user-images.githubusercontent.com/111734605/209019844-d2d7e641-295f-4721-b589-da131f5dde9d.png">
</p>

#### Instruction Component
1. 위의 그림은 추론 과정에서 어떻게 **자연어 질문**이 주어졌을때, 그것이 연속적인 Instruction vector로 변환되는지 보여준다.
2. Instruction Component의 Input = **query(질문, $$q$$)** + <span style = "color:aqua">**이전 추론 step**</span>**에서의 instruction vector($$i^{k-1}$$)**
  - instruction vector의 초기값은 zero vector이다.
3. query의 단어들을 임베딩 하는데에는 **GloVe 아키텍쳐**를 사용한다.
4. Hidden state를 얻기위해 LSMT 인코더를 사용한다.
  - 조건1) Hidden State = $${h}_{j=1}^l$$, 
  - 조건2) $$h_j \in R^d $$
  - 조건3) $$l$$은 query의 길이이다.
5. 마지막 Hidden state가 question representation으로 간주된다.
  - $$i.e. \; q = h_l, Let i^{(k)} \in R^d$$
  - k번째 추론 스텝의 instruction vector이다.

<p align="center">
<img width="500" alt="1" src="https://user-images.githubusercontent.com/111734605/209880420-bbca64be-78c4-4545-8a7d-5455c74aa49d.png">
</p>

$$i^{(k)}$$는 위의 식과 같다. 이때, $$W^(k), W_{\alpha}, b^{(k)}, b_{\alpha}$$가 Training을 통해서 얻어야 할 Parameter들이다.

- <span style = "font-size:120%">**Parameter**</span>  
  1. $$W^(k)$$: k번째 Weight Matrix, $$W^(k) \in R^{d \times 2d}$$ 이다.
  2. $$W_{\alpha}$$, $$W_{\alpha} \in R^{d \times d}$$ 이다. 
  3. $$b^{(k)}$$, $$b_{\alpha}$$ bias로 둘다 d차원 벡터이다.

Main 아이디어는 <span style= "color:aqua">다른 Time Step에서 Instruction Vector를 학습할 때 **query의 특정 부분에 주의(attention)를 기울이는 것**이다. 이러한 과정에서 query representation도 동적으로 업데이트하여 이전 Instruction Vector의 정보를 통합</span>할 수 있다. 특정 query에 attention한다는 것은 결구 weighted 처리를 한 것이다.

n 번째 추론 step 이후에 우리는 Instruction Vector의 리스트($$[i^{(k)}]^n_{k=1}$$)를 얻을 수 있다.

#### Reasoning Component
위 과정 이후에 얻은 $$i^{(k)}$$를 이용하여 reasoning component의 guild signal로써 활용 가능하다. reasoning component의 Input에는 **현재 step의 instruction vector**를 포함한
다. 그리고 **이전 step에서 얻은 entity들의 분포와 임베딩 값**들 역시 포함한다.

reasoning component의 출력(Output)은 **entity 분포인 $$p^{(k)}$$를 포함**한다. 그리고 **entity 임베딩인 $$e^{k}$$역시 포함**한다. Entity 임베딩의 초기값은 아래 식과 같다.

<p align="center">
<img width="300" alt="1" src="https://user-images.githubusercontent.com/111734605/209881929-1649fcca-005f-4b0e-9ab7-51dd45922df2.png">
</p>

$$W_T \in R^{d \times d}$$ 이고, $$W_T$$가 학습을 통해 얻어야 하는 parameter이다. 기존의 연구들과는 다르게 이 논문에서느 Encoding entity들에 관한 정보를 유감없이 사용한다. 
multi-hop KBQA 문제에서는 reasoning path가 답변 엔티티로의 semantic한 정보를 반영해줄 multiple relation을 만들어 낸다. 그리고, 이 인코딩 엔티티를 이용하는 것은 학습과정에서
노이즈 엔티티들의 영향력을 줄이는데도 기여한다. 그리고 이미 알고 있는 context의 relation에 대한 보이지 않는(학습되지 않은) 엔티티에 관해서도 쉽게 이용할 수 있다는 장점이 있다.

$$<e^{\prime}, r, e>$$ 가 주어졌을때, match vector는 다음 식을 만족한다.

<p align="center">
<img width="300" alt="1" src="https://user-images.githubusercontent.com/111734605/209882578-723b3267-ba74-42bb-884c-9aecaca6c6fb.png">
</p>

$$W_R \in R^{d \times d}$$의 식을 만족하고, $$W_R$$이 우리가 학습을 통해 얻어야 하는 parameter이다. 게다가, **인접한 triple의 Maching message를 집계(aggregate)할 수 있고**,
그리고 **마지막 추론 스텝(reasoning step)에서 얼마나 많은 atttention을 받는지에 따라 weight(가중치)를 부여**할 수 있다. 

<p align="center">
<img width="300" alt="1" src="https://user-images.githubusercontent.com/111734605/209882879-ef0078ce-0e79-4fea-8105-63125945f61e.png">
</p>

이 때, $$p_{e^{\prime}}^{(k-1)}$$은 마지막 추론 스텝에서 엔티티 $$e^{\prime}$$에 할당된 확률이다. 이러한 representation은 KB에서 엔티티와 연관된 관계 의미론(relation semantics)을 캡처할 수 있다. 그런 다음, 우리는 다음과 같이 엔티티 임베딩을 업데이트한다.


<p align="center">
<img width="300" alt="1" src="https://user-images.githubusercontent.com/111734605/209883126-05eef5fa-4d49-47d9-93e3-fbbec06b515f.png">
</p>

여기서 FEN은 Feed Forward Layer이다. FEN은 input으로 이전 임베딩 값인 $$e^{(k-1)}$$과 relation-aggregated 임베딩인 $$\tilde{e}^{(k)}$$ 를 받는다. 
- relation path
- matching degree wit the question

일련의 과정을 거치면 위의 두 가지가 노드 임베딩으로 인코딩된다. k-step에서 중간 엔티티(Intermediate Entity)들의 확률 분포는 다음과 같다
- $$p^{(k)}$$는 엔티티 분포이다.
- $$E^{(k)}$$는 업데이트된 임베딩 행렬이다.

<p align="center">
<img width="300" alt="1" src="https://user-images.githubusercontent.com/111734605/209883742-3e238fd8-a97f-4be0-9b4b-321874f9472b.png">
</p>

#### Discussion
- 논문에서는 Two-fold NSM을 사용했다. 
  1. Core Idea는 <span style = "color:aqua">**Intermediate Entity distribution**을 teacher network로 부터 student network를 위한 **supervision signal**로써 받아 이용</span>하는 것이다.  
  2. NSM은 Special GNN처럼 사용되었다. 이는 Knowledge graph에 대해 매우 좋은 추론 능력을 보여주는 아키텍쳐이다.

- NSM은 기존에 visual reasoning, 즉 시각적 추론을 위해 만들어진 아키텍쳐이다. 이를 논문에서는 Multi-hop KBQA 문제를 위해 두 가지로 적용하였다.
  1. 엔티티와 관련된 관계의 임베딩을 집계하여 노드 임베딩을 초기화한다.   
    - 우리의 초기화 방법은 중요한 관계형 의미론(relation semantics)에 초점을 맞추어 노이즈가 많은 엔티티의 영향을 줄일 수 있다. 또한, 알려진 관계를 가진 새로운 엔티티 또는 보이지 않는 엔티티로 일반화하는 것은 쉬우며, 이는 특히 증분 훈련(Incremental Training)에 중요하다.  
     <p align="center">  
     <img width="300" alt="1" src="https://user-images.githubusercontent.com/111734605/209881929-1649fcca-005f-4b0e-9ab7-51dd45922df2.png">
     </p>  
  2. 이전 임베딩 값과 relation-aggregated 임베딩값을 통합하여 엔티티 임베딩을 업데이트 할 수 있다.    
     <p align="center">
     <img width="300" alt="1" src="https://user-images.githubusercontent.com/111734605/209883126-05eef5fa-4d49-47d9-93e3-fbbec06b515f.png">
     </p>

### 3) The Teacher Network

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/209020057-0f122ef9-6f03-4f37-8989-5da5611bb7b0.png">
</p>

