---
title: (논문 리뷰)Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals 

categories: 
  - PaperReview
  
tags:
  - [KBQA]
  
toc: true
toc_sticky: true

date: 2022-12-22
last_modified_at: 2022-12-22 
---

## 1. 논문을 들어가기 앞서 알면 좋은 Basic Knowledge
- [Graph의 개념](https://meaningful96.github.io/datastructure/2-Graph/)
- [Cross Entropy, Jensen-Sharnnon Divergence](https://drive.google.com/file/d/18qhdvC_2B9LG7paPdAONARqj3DWxxa8h/view?usp=sharing)
- Knowledge Based Learning
- Reward Shaping
- Action Dropout
- [BFS, DFS](https://meaningful96.github.io/datastructure/2-BFSDFS/)
- [Bidirectional Search in Graph](https://meaningful96.github.io/datastructure/3-Bidirectionalsearch/)
- GNN
- Various Types of Supervision in Machine Learning
- [End-to-end deep neural network](https://meaningful96.github.io/deeplearning/1-ETE/)
- NSM(Neural State Machine)

<span style = "font-size:120%">**Graph**</span>

<p align="center">
<img width="500" alt="1" src="https://user-images.githubusercontent.com/111734605/208984702-642c1b33-0940-4469-a731-91dca6bfdad8.png">
</p>
```
그래프는 연결할 객체를 나타내는 정점(Vertex, Node)와 객체를 연결하는 간선(Edge)의 집합으로 구성된다.
그래프 G를 다음과 같이 정의한다.
```
<center>$$G = G(V,E) $$</center>  

여기서 V는 정점의 집합(Vertex Set)이고, E는 간선들의 집합(Edge Set)이다.

**용어 정리**
- **노드(node)**: 정점(vertice)라고도 불리며, 일반적으로 노드에는 데이터가 저장됨
- **간선(edge)**: 링크, arcs라고도 불리며, 노드간의 관계를 나타냄
- **인접 정점(adjacent vertex)**: 간선에 의해 연결된 정점.
- **단순 경로(simple-path)**: 경로 중 반복되는 정점이 없는것, 같은 간선을 자나가지 않는 경로
- **차수(degree)**: 무방향 그래프에서 하나의 정점에 인접한 정점의 수. 위 그래프에서 A의 차수는 3이다.
- **진출차수(out-degree)/진입차수(in-degree)**: 방향그래프에서 사용되는 용어
  - 진출 차수 는 한 노드에서 외부로 향하는 간선의 수,
  - 진입차수 는 외부 노드에서 들어오는 간선의 수

**그래프의 특징**
- 그래프는 <span style = "color:aqua">**네트워크 모델**</span> 즉, 객체와 이에 대한 관계를 나타내는 유연한 방식으로 이해할 수 있다.   
- 그래프의 순회는 DFS(깊이 우선 탐색), BFS(너비 우선 탐색)으로 할 수 있다.  
- 그래프에는 루트 노드, 부모-자식의 개념은 존재하지 않는다.
- 트리는 그래프의 한 종류이다.

<span style = "font-size:120%">**Cross Entropy**</span>

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/209002976-5b2ac8df-418f-498f-8950-cbd269693985.png">
</p>

이 때, KL divergence의 문제점은 symmetric하지 않기 때문에, 유사도를 이야기할 때 **거리**라고 표현하지 않는다.  
이 거리 개념 <span style = "color:aqua">Distance Metric으로 쓸 수 있는 방법</span>으로 나온 것이 **Jensen-Shannon Divergence**이다.

<center><span style="font-size:120%"> $$JSD(P,Q) = \frac{1}{2} D(P||M) + \frac{1}{2} D(Q||M)$$ </span></center>  
<center><span style="font-size:120%"> $$where \,M = \frac{1}{2} (P+Q)$$ </span></center>  

수식에서 보여지듯이, P와 Q의 평균값을 뜻하는 M과 KL-divergence를 함으로써 Symmetric해지는 성질을 확인 할 수 있다.

<center><span style="font-size:120%"> $$JSD(P,Q) = JSD(Q,P)$$ </span></center>  
이를 통해 <span style = "color:aqua">**두 확률 분포 사이의 거리(Distance)**를 유사도 척도로 활용</span>할 수 있다.

<span style = "font-size:120%">**Knowledge Based Learning**</span>  
의사 결정을 지원하기 위해 인간 전문가의 지식을 포착하는 것을 목표로 하는 인공지능(AI)의 한 형태이다. 지식 기반 시스템의 예로는 전문가 시스템이 있는데, 이는 인간의 전문 
지식에 대한 의존 때문에 소위 말하는 것이다.

문제 해결 방법을 알려주는 지식 기반 시스템의 전형적인 아키텍처는 지식 기반과 추론 엔진을 포함한다.
첫 번째 "지식 베이스"의 경우 세계에 관한 사실을 표현한다. 
두 번째 "추론 엔진"의 경우 새로운 지식을 추론할 수 있게 한다.

전문가 시스템: 보통은 전문 지식이 필요한 것으로 간주되는 복잡한 작업에 대해 인간 전문가를 돕거나 대체할 목적으로 시스템이 지원을 시도하는 태스크의 종류를 가리킨다.
지식 기반 시스템: 절차적 코드가 아닌, 분명하게 지식을 표현하는 시스템의 구조를 가리킨다.

<span style = "font-size:120%">**Reward Shaping**</span>  
Reward shaping is an efficient way to incorporate domain knowledge into a reinforcement learning agent.
보상 형성은 도메인 지식을 강화 학습 에이전트에 통합하는 효율적인 방법이다.

In order to enrich the reward function, we develop a novel reward shaping approach to provide informative reward signal for the reinforcement learning agent.
보상 기능을 풍부하게 하기 위해 우리는 강화 학습 에이전트에 유익한 보상 신호를 제공하는 새로운 보상 형성 접근 방식을 개발한다.

## 2. Abstract
Multi-hop Knowledge Base Question Answering (KBQA) Problem의 목표는 지식 기반의 Question의 entity에서 여러 hop(홉)만큼 떨어져 있는 answer entity를 찾는 것이다.  

```Major Challenge: Lack of Supervision signals at intermediate steps.```

이 문제점 때문에, mulit-hop KBQA 알고리즘은 마지막 final answer로부터만 feedback 을 받을 수 있다는 것이고, 이는 학습에 **비효율적이고 불안정**하게 만든다.

**Suggested Solution**
- Novel teacher-student approach for the multi-hop KBQA task
- Student network는 query(질의)에 관한 정확한 답을 찾는 것을 목표로한다.
- <span style = "color:aqua">Teatch network</span>는 동시에 중간 단계의(Intermediate) student network의 추론 능력을 향상시키기 위해 supervision signal을 학습한다.
- Major novelty는 teacher network에 있다.
- Bidirectional reasoning을 통해 그 효율을 증대시킨다.

### Keyword
**Knowledge Base Question Answering**, **Teacher-student Network**, **Intermediate Supervision Signals**

## 3. Introduction

<p align="center">
<img width="600" alt="1" src="https://user-images.githubusercontent.com/111734605/209012402-dc7d7449-e253-439a-8b5e-e6ea6b919b6f.png">
</p>

최근에, End-to-end deep neural network(종단간 심층 신경망)은 Multi-hop KBQA 문제에 대해서 paramter를 자동으로 학습하기에 각광받고 있다.

Multi-hop KBQA라고 불리는 **멀티홉 추론 절차를 필요로 하는 복잡한 문제를 해결하는 것**에 대한 관심이 증가하고 있다. 최종 답변 외에도, 멀티홉 KBQA 알고리즘이 
**답변 엔티티로 이어지는 합리적인 관계 경로를 식별**할 수 있는 것도 중요하다. 경우에 따라서 정답이 올바르게 발견된 경우에도 그 경로는 거짓일 수 있다.  
```In some cases, even if the answer was correctly found, the relation path might be spurious. ```  

- Ex) Figure 1 pic
  1. 문제: In some cases, even if the answer was correctly found, the relation path might be spurious. 
  2. 정답: 빨간색 경로
  3. 오답: 파란색 경로, 회색 경로
 
➜ 그것은 주로 <span style = "color:aqua">**중간 추론 단계(Intermediate reasoning steps)에서 supervision signals가 부족**</span>하기 때문이다.

- Multi-hop KBQA task의 경우 훈련 데이터는 일반적으로 이상적인 대신 ⟨ $$question, answer$$ ⟩ 의 형태이다.
- 따라서 멀티홉 추론 알고리듬은 이러한 데이터 세트를 사용하여 최종 답변에서만 피드백을 받을 수 있다.

이러한 문제점들을 해결하기 위해서 다양한 연구에서 다양한 방법이 제시되었지만, 여전히 중간 단계에서 효과적인 supervision signal이 부족했다. 따라서 본 논문에서는
다음과 같은 방향을 잡고 연구를 진행하였다.

- 메인 모델은 쿼리에 대한 올바른 답을 찾는 것을 목표로 하고, 보조 모델은 메인 모델의 추론 능력을 향상시키기 위해 중간 감독 신호를 학습하려고 한다.
- 구체적으로, 보조 모델은 중간 단계의 어떤 엔티티가 질문과 더 관련이 있는지를 추론하며, 이러한 엔티티는 중간 감독 신호로 간주된다.
  1. 이 아이디어는 attractive 하지만, training을 위한 레이블이 지정된 데이터가 없기 때문에 효과적인 보조 모델을 배우는 것은 어렵다.
  2. Key idea from `양방향 탐색(Bidirectional Search)`
  3. Topic Entity(Query Entity) ➜ Answer Entity : <span style = "color:aqua">전진 추론</span>
  4. Answering Entity ➜ Topic Entity : <span style = "color:aqua">후진 추론</span>

### Idea
- Student Network: NSM(Neural State Machine)을 적용
  - 학생 네트워크는 교사 네트워크에서 학습된 중간 엔티티 분포에 따라 자체를 개선할 수 있다.

## 4. Mechanism
### 1) Overview
- Multi-hop KBQA 과제 자체에 집중하는 학생 네트워크를 훈련한다 
- 다른 교사 네트워크는 학생 네트워크를 개선하기 위한 중간 추론 단계에서 Supervision signal(즉, 우리의 과제에서 추론된 엔티티 분포)를 제공하도록 훈련한다.
  1. Knoledge Base를 그래프로 간주하여 Multi-hop KBQA 작업에 적용
  2. Multi-hop 추론 과정에서 엔티티에 대해 점진적으로 학습된 엔티티 분포를 유지
  3. Teacher Network를 개발하기 위해 새로운 양방향 추론 메커니즘을 통합하여 NSM의 아키텍처를 수정하여 중간 추론 단계에서 보다 신뢰할 수 있는 엔티티 분포를 학습 가능
  4. 이는 이후 Student Network에서 Supervision signal로 사용
 
### 2) Neural State Machine for Multi-hop KBQA - Student Network

<p align="center">
<img width="600" alt="1" src="https://user-images.githubusercontent.com/111734605/209019844-d2d7e641-295f-4721-b589-da131f5dde9d.png">
</p>

### 3) The Teacher Network

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/209020057-0f122ef9-6f03-4f37-8989-5da5611bb7b0.png">
</p>

