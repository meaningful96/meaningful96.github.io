---
title: (논문 리뷰)Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals 

categories: 
  - PaperReview
  
tags:
  - [KBQA]
  
toc: true
toc_sticky: true

date: 2022-12-22
last_modified_at: 2022-12-22 
---

## 1. 논문을 들어가기 앞서 알면 좋은 Basic Knowledge
- [Graph의 개념](https://meaningful96.github.io/datastructure/2-Graph/)
- [Cross Entropy, Jensen-Sharnnon Divergence](https://drive.google.com/file/d/18qhdvC_2B9LG7paPdAONARqj3DWxxa8h/view?usp=sharing)
- Knowledge Based Learning
- Reward Shaping
- Action Dropout
- [BFS, DFS](https://meaningful96.github.io/datastructure/2-BFSDFS/)
- [Bidirectional Search in Graph](https://meaningful96.github.io/datastructure/3-Bidirectionalsearch/)
- GNN

### 1) Graph

<p align="center">
<img width="500" alt="1" src="https://user-images.githubusercontent.com/111734605/208984702-642c1b33-0940-4469-a731-91dca6bfdad8.png">
</p>

- 그래프는 연결할 객체를 나타내는 정점(Vertex, Node)와 객체를 연결하는 간선(Edge)의 집합으로 구성된다.
- 그래프 G를 다음과 같이 정의한다.
$$G = G(V,E) $$  
여기서 V는 정점의 집합(Vertex Set)이고, E는 간선들의 집합(Edge Set)이다.

### 1) 용어 정리
- **노드(node)**: 정점(vertice)라고도 불리며, 일반적으로 노드에는 데이터가 저장됨
- **간선(edge)**: 링크, arcs라고도 불리며, 노드간의 관계를 나타냄
- **인접 정점(adjacent vertex)**: 간선에 의해 연결된 정점.
- **단순 경로(simple-path)**: 경로 중 반복되는 정점이 없는것, 같은 간선을 자나가지 않는 경로
- **차수(degree)**: 무방향 그래프에서 하나의 정점에 인접한 정점의 수. 위 그래프에서 A의 차수는 3이다.
- **진출차수(out-degree)/진입차수(in-degree)**: 방향그래프에서 사용되는 용어
  - 진출 차수 는 한 노드에서 외부로 향하는 간선의 수,
  - 진입차수 는 외부 노드에서 들어오는 간선의 수

### 2) 그래프의 특징
- 그래프는 <span style = "color:aqua">**네트워크 모델**</span> 즉, 객체와 이에 대한 관계를 나타내는 유연한 방식으로 이해할 수 있다.   
- 그래프의 순회는 DFS(깊이 우선 탐색), BFS(너비 우선 탐색)으로 할 수 있다.  
- 그래프에는 루트 노드, 부모-자식의 개념은 존재하지 않는다.
- 트리는 그래프의 한 종류이다.

### 3) Cross Entropy

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/209002976-5b2ac8df-418f-498f-8950-cbd269693985.png">
</p>

이 때, KL divergence의 문제점은 symmetric하지 않기 때문에, 유사도를 이야기할 때 **거리**라고 표현하지 않는다.  
이 거리 개념 <span style = "color:aqua">Distance Metric으로 쓸 수 있는 방법</span>으로 나온 것이 **Jensen-Shannon Divergence**이다.

<center><span style="font-size:120%"> $$JSD(P,Q) = \frac{1}{2} D(P||M) + \frac{1}{2} D(Q||M)$$ </span></center>


