---
title: "[논문리뷰]Relation-Aware Language-Graph Transformer for Question Answering"

categories: 
  - GR
  
toc: true
toc_sticky: true

date: 2024-03-14
last_modified_at: 2024-03-14
---

Authors: *Jinyoung Park, Hyeong Kyu Choi, Juyeon Ko, Hyeonjin Park, Ji-Hoon Kim, Jisu Jeong, Kyungmin Kim, Hyunwoo J. Kim*  
Paper: *[Relation-Aware Language-Graph Transformer for Question Answering](https://arxiv.org/abs/2212.00975) in AAAI 2023*.    

# Problem Statement

<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Deep_Learning/assets/111734605/ecae1066-36e2-4aa9-9253-de12734ec39f">
</p>

<span style = "font-size:110%"><b>1. 기존 GNN 기반 모델들의 한계</b></span>  
Question-Answering(QA)을 위한 기존의 GNN 기반의 모듈은 트리플(Triple)로 이루어진 Knowledge Graph(KG)의 풍부한 정보를 제대로 활용하지 못했다. GNN은 기본적으로 노드의 임베딩을 학습한다. 다시 말해, 노드의 정보만을 학습하며 두 노드 사이의 연결 유무만을 학습하게 된다. 하지만, KG에는 많은 릴레이션에 자연어 정보가 포함되어 있고, 그 종류가 매우 많다. 따라서 GNN을 통한 KG학습에는 한계가 존재한다.

<span style = "font-size:110%"><b>2. Langauge Model(LM)과 Knowledge Graph(KG) 사이 매우 적은 정보만을 교환</b></span>  
기존 모델들 중 LM과 KG 사이 매우 적은 정보 교환만 이루어졌다. 예를 들어, LM모델을 학습하고 추론 시에만 KG를 처리하여 학습된 LM에 통합시키려 하였다. 이후 연구에서는 학습 단계에서 KG와 LM을 합치려는 시도가 있었으며, 이는 special token node나 cross-attention을 통해 이루어졌다. 하지만, 이런 접근 방식은 GNN을 modality-specific하게 하며, KG모듈과 LM모듈 간의 정보 교환이 연산을 진행하는 **fusion부분에서만 이루어지기에** 여전히 제한적으로 일어난다는 한계가 있다.

<br/>

# Related Work

<span style="font-size:110%"><b>1. Knowledge Graph Question-Answering (KGQA)</b></span>    
KG에서 경로 상에 존재하는 정보를 취합하여 하나의 질문(question)에 대한 정답(answering)을 찾아내는 문제로, Knowledge Base Question-Answering(KBQA)로도 불린다. 초기에는 GNN만을 사용한 연구가 대부분이었다. GNN은 기본적으로 message passing과 aggregation을 통해 이웃 노드(엔티티)의 정보를 취합하여 구조 정보를 학습한다. 이후 Knowledge Graph Completion(KGC)분야에도 LM 모델을 활용한 연구가 진행되면서 LM과 KG를 모두 활용하는 multi-modal형태의 연구가 진행되었다.

<p align="center">
  <img width="600" alt="1" src="https://github.com/meaningful96/Deep_Learning/assets/111734605/0d11c9ea-72f3-4b5a-be9e-8f58aef562a3">
  <center><figcaption>ref: Improving Multi-hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals</figcaption></center>
</p>

위의 그림은 KGQA의 예시이다. 질문으로 "Q) *What types are the film starred by actors in the nine lives of fritz the cat?*" 주어졌을 때, 정답을 올바르게 찾아가는 경로는 빨간색이다. 하지만 Question-answering이 어려운 대표적인 이유 중 하나가 바로 정답을 맞추더라도 올바른 경로로 가지 않는 경우가 발생하기 때문이다. 그림에서 파란색 경로를 보면, 질문과는 거리가 먼 추론을 하지만 정답인 *Comedy*를 맞춘 것을 확인할 수 있다. 이러한 이유 때문에 <span style="color:gold">**Hallucination**</span>이 발생하는 것이다. Hallucination이란 예를 들면, "아인슈타인이 중력을 발견한 연도가 언제야?" 라고 자연어 모델에게 질문하였을 때, 잘못된 질문임에도 불구하고 "아인슈타인은 중력을 1925년에 발견하고 논문을 발표했어."와 같이 잘못된 답변을 그럴듯하게 생성해내는 문제이다. 이러한 이유로, QA를 올바르게 할 수 있도록 모델을 학습하는 것이 중요하다.

<span style="font-size:110%"><b>2. Question-Answering for Graphs</b></span>    
QA task의 목표는 주어진 질문의 context를 자연어와 구조화된 관계 정보로 이해하는 것에 초점을 맞춘다. SapBERT와 ConceptNet등이 이 연구에 해당한다.

<p align="center">
<img width="500" alt="1" src="https://github.com/meaningful96/Deep_Learning/assets/111734605/ba5ceeb7-3c3a-439a-97f1-fc6425e3cd05">
</p>

Multiple-Choice Question-Answering (MCQA)는 question의 $$q$$의 단어 엔티티와 선택한 답변 $$a \in C$$ 엔티티를 Concatenation하여 시퀀스 $$X$$로 정의하고 이를 입력으로 넣는다. 그리고 사전 학습된 자연어 모델 $$\mathcal{g_{LM}}$$이 입력 시퀀스 $$X$$를 받아 출력된 값이 바로 Context Token $$\mathcal{H_{LM}}$$이 된다. 

<br/>

# Method

<br/>

# Experiments & Results

<br/>

# Contribution
