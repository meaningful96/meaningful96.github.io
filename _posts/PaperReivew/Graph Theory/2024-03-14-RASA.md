---
title: "[논문리뷰]Relation-Aware Language-Graph Transformer for Question Answering"

categories: 
  - GR
  
toc: true
toc_sticky: true

date: 2024-03-14
last_modified_at: 2024-03-14
---

Authors: *Jinyoung Park, Hyeong Kyu Choi, Juyeon Ko, Hyeonjin Park, Ji-Hoon Kim, Jisu Jeong, Kyungmin Kim, Hyunwoo J. Kim*  
Paper: *[Relation-Aware Language-Graph Transformer for Question Answering](https://arxiv.org/abs/2212.00975) in AAAI 2023*.    

# Problem Statement

<p align="center">
<img width="1000" alt="1" src="hhttps://github.com/meaningful96/Model_Experiment/assets/111734605/ea4f11ee-e96e-4386-91eb-6607a92c323d">
</p>


<span style = "font-size:110%"><b>1. 기존 GNN 기반 모델들의 한계</b></span>  
Question-Answering(QA)을 위한 기존의 GNN 기반의 모듈은 트리플(Triple)로 이루어진 Knowledge Graph(KG)의 풍부한 정보를 제대로 활용하지 못했다. GNN은 기본적으로 노드의 임베딩을 학습한다. 다시 말해, 노드의 정보만을 학습하며 두 노드 사이의 연결 유무만을 학습하게 된다. 하지만, KG에는 많은 릴레이션에 자연어 정보가 포함되어 있고, 그 종류가 매우 많다. 따라서 GNN을 통한 KG학습에는 한계가 존재한다.

<span style = "font-size:110%"><b>2. Langauge Model(LM)과 Knowledge Graph(KG) 사이 매우 적은 정보만을 교환</b></span>  
기존 모델들 중 LM과 KG 사이 매우 적은 정보 교환만 이루어졌다. 예를 들어, LM모델을 학습하고 추론 시에만 KG를 처리하여 학습된 LM에 통합시키려 하였다. 이후 연구에서는 학습 단계에서 KG와 LM을 합치려는 시도가 있었으며, 이는 special token node나 cross-attention을 통해 이루어졌다. 하지만, 이런 접근 방식은 GNN을 modality-specific하게 하며, KG모듈과 LM모듈 간의 정보 교환이 연산을 진행하는 **fusion부분에서만 이루어지기에** 여전히 제한적으로 일어난다는 한계가 있다.

<br/>

# Related Work

<span style="font-size:110%"><b>1. Knowledge Graph Question-Answering (KGQA)</b></span>  
KG에서 경로 상에 존재하는 정보를 취합하여 하나의 질문(question)에 대한 정답(answering)을 찾아내는 문제로, Knowledge Base Question-Answering(KBQA)로도 불린다. 초기에는 GNN만을 사용한 연구가 대부분이었다. GNN은 기본적으로 message passing과 aggregation을 통해 이웃 노드(엔티티)의 정보를 취합하여 구조 정보를 학습한다. 이후 Knowledge Graph Completion(KGC)분야에도 LM 모델을 활용한 연구가 진행되면서 LM과 KG를 모두 활용하는 multi-modal형태의 연구가 진행되었다.

<p align="center">
<img width="500" alt="2" src="https://github.com/meaningful96/Model_Experiment/assets/111734605/7a7cbc17-9952-489f-8f5a-e8fee76967cd">
</p>

위의 그림은 KGQA의 과정을 잘 보여준다.


<br/>

# Method

<br/>

# Experiments & Results

<br/>

# Contribution
