---
title: Position-aware Graph Neural Network

categories: 
  - PaperReview
  
tags:
  - [GNN,Graph]
  
toc: true
toc_sticky: true

date: 2023-01-11
last_modified_at: 2023-01-11
---
## 1. Problem Set  
### 1) Limitation of Existing GNN Architecture  
Fail to capture the position(location) of the node within the broader context of the graph structure  
즉, Graph에서 노드들의 위치를 구분하지 못한다.

### 2) Limitation of One-hot Encoding
Models trained with one-hot encodings cannot generalize to unseen graphs, and arbitrarily deep GNNs still cannot distinguish structurally isomorphic nodes
One-hot encoding으로 모델을 학습시키면 Unseen Grpah에 대해서 일반화하지 못한다. 즉, Graph의 Isomorphic(Symmetric) node를 구별하지 못한다.

<p align="center">
<img width="600" alt="1" src="https://user-images.githubusercontent.com/111734605/210997783-963e93e9-d72f-4244-95ec-3ef2732d73ec.png">
</p>

## 2. Related Work
[GNN]()
[GCN]()
[GAN]()
[GIN]()
[GraphSAGE]()

<span style = "font-size: 80%">- 추후 업로드후 링크 업데이트 예정</span>
  
## 3. Method
### 1) Node Embedding
- <span style = "color:aqua">Vector Representation</span> of nodes in graph

즉, 그래프에 있는 노드 정보들을 벡터로 표현하는 것을 **노드 임베딩(Node Embedding)**이라고 한다.
노드 임베딩을 하는 방법으로는 크게 세 가지 방법이 있다.
- Node Embedding
  - Graph Neural Networks(GNNs)
  - Matrix-factorization
  - Random-walk-based(DeepWalk, node2vec,...)

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/211763565-27c4a8b7-875b-4f6d-8d9a-699ed32b4a55.png">
</p>

위의 그림은 **node2vec** 아키텍쳐의 노드 임베딩을 시각화 한 것이다. node2vec 아키텍쳐는 자연어 처리(NLP)에서 많이 사용되는 모델이다. 간단히 설명하면 어떤 그래프가 주어졌을 때, Random-walk를 통해 graph smapling을 하고 만들어지 노드 페어(Node pair, 노드 쌍)를 **Word2Vec** 알고리즘을 적용해 임베딩 공간(Embedding space)를 표현합니다. 하지만 이런 Random-walk base method의 경우 [Transductive Setting]()을 가지고 있고 이런경우 노드의 정보를 제대로 사용하지 못합니다. <span style = "color:aqua">**GNN의 경우 애초에 Node feature 정보가 들어갈 수 있는데**</span>, Random-walk의 경우 Node property를 넣지 못한는 단점이 있습니다.

### 2) Structure-aware & Position-aware
- **Structure-aware** 
  - 어떤 노드 $$v_i$$가 주어졌을 때, k-hop까지  $$N_1~N_q$$까지 표현을 하는 어떤 함수 $$g$$
  - 이 g를 이용한 것이 **Structure-aware Embedding**이다.
  - GNN의 경우 Structure-aware이다.

<p align="center">
<img width="940" alt="image" src="https://user-images.githubusercontent.com/111734605/211779048-42527ef0-5483-4cb5-bdbf-1841bbc34c6f.png">
</p>

- **Position-aware**
  - 논문에서 Random-walk 아키텍쳐의 임베딩 방법을 Position-ware Embedding이라고 한다.
  - 여기서 $$g$$함수는 어떤 노드 $$v_i, v_j$$의 최단거리(Shortest Path, $$d_{sp}$$)와 같아지게 하는 함수
  - 이러한 임베딩 방법을 **Position-aware Embedding**이라고 한다.

<p align="center">
<img width="940" alt="image" src="https://user-images.githubusercontent.com/111734605/211779327-b7eb9030-22ff-46f3-8df7-727877c1f8c0.png">
</p>

일반적으로 두 Structure-aware Embedding은 Position-Aware Embedding가 아니다.

<span style = "font-size:120%">**Proposition**</span>    
There exists a mapping function $$g$$ that <span style = "color:aqua">**maps structure-aware embedding to position-aware embeddings**</span>, if and only if no pair of nodes have isomorphic local $$q$$-hop neighborhood graphs

논문에서 제안하는 것은 '만약에 어떤 노드 페어든, **Isomorphic한 특성을 따르지 않는다면** 이 Structure-aware embedding을 Position-aware embedding으로 mappong할 수 있는 함수 $$g$$가 있다.' 이다.

### 3) Limitation of Existing GNN

<p align="center">
<img width="400" alt="image" src="https://user-images.githubusercontent.com/111734605/211781946-3ff20c42-30f4-49d9-8715-dde4656be39d.png">
</p>

- <span style = "color:aqua">**Can't capture position(location) of node within a graph**</span>
- GNN can't classify $$v_1$$ and $$v_2$$ because of **isomorphic network neighborhoods**

Graph Neural Network(GNN)은 <span style = "color:aqua">Structure-aware embedding</span> 방식을 채택하고, 이는 어떤 그래프가 주어졌을때
노드들의 정확한 위치를 Detect하지 못한다. 그래서 Vertex $$v_1$$과 $$v_2$$를 **Isomorphic Characteristic** 떄문에 구분하지 못한다.

이를 타래의 그림처럼 rooted 된 subtree형태로 바꿔 표현하면 되면 사실상  $$v_1$$의 subtree와 $$v_2$$의 subtree가 같은 구조이므로 $$v_1$$과 $$v_2$$ 노드를 같은 노드로 판별하게 된다.

이러한 특성이 문제가 되는 이유는 분자 구조 예측이나 Social-Network 문제를 풀 때 문제가 된다. 두 문제의 경우
모두 Node들의 위치가 중요하다.

### 4) Position-aware의 핵심

<p align = "center">
<img width="900" alt="image" src="https://user-images.githubusercontent.com/111734605/211786167-c9f55a38-7b8f-473b-b3e8-c0cb9e4fbcc0.png">
</p>

이러한 한계점으로 논문에서는 **Position-aware Embedding**을 제안한다. 전체적인 process는 위의 그림과 같다.

여기서 Focus해야 할 것은 두 가지이다. 첫번째로 <span style = "color:aqua">**Anchor-set Selection**</span>이다. Anchor-set은 간단히 말하면 노드의 위치 정보를 계산하기 위해 기준점이 되는 노드 셋을 Sampling
하는 것이다.

그리고 두 번째는 역시 <span style = "color:aqua">**Position-aware Node Embedding**</span>이다. 주어진 노드의 거리를 계산해서 정보를 반영하는 임베딩이다.

- Anchor-set Selcetion
- Position-aware Node Embedding

### 5) Anchor-Set Selection

Rely on **Bourgain Theorem** when selecting achor-sets in P-GNNs
  - Existance of a low distortion embedding
  
  - $$O(log^2n)$$ Anchor-set
  - Anchor-set size: Exponentially distributed

  - <span style = "color:aqua">Size of Anchor-set</span>
    - Small set: Enough provide **positional information**, but hit ratio is small
    - Large set: High **sample efficiency**, but little information on position  

논문에서는 **볼겐 정리(Bourgain's Theorem)**에 근거하야 Anchor-set Selection을 제안하였다. 이 정리에 의하면 <span style = "color:aqua">**$$(logn)^2$$**만큼의 Sampling set을 추출</span>하면 왜곡(Distortion)이 가장 적어지며, 그렇기에 Embedding을 했을때 가장 **유의미**하다.

이렇게 추출된 anchor-set들의 Size는 다양하다. 다양하게 추출해야하는 이뉴는 Small set과 Large set들이 각각 장단점을 가지고 있고, 다양한 크기의 set을 추출해서 서로의 장단점을
보완해주기 위함이다. 

**Small set**으로 sampling하면 좀 더 <span style = "color:aqua">Specific한 subgraph를 표현하기에 그 만큼 Position을 표현하기에 유용</span>하지만, <span style = "color:gold">자칫 기준점으로부터 거리가 너무 멀어질 수 있다.</span>

**Large set**의 경우는 <span style = "color:aqua">노드간의 계산을 할 수</span>있으나 <span stlye = "color:gold">노드의 Position을 설명하는 파워는 줄어든다.</span> 따라서, Position과 Set의 크기는 Trade-off 관계에 있다.




## 4. Contribution
