---
title: Position-aware Graph Neural Network

categories: 
  - PaperReview
  
tags:
  - [GNN,Graph]
  
toc: true
toc_sticky: true

date: 2023-01-11
last_modified_at: 2023-01-11
---
## 1. Problem Set  
### 1) Limitation of Existing GNN Architecture  
Fail to capture the position(location) of the node within the broader context of the graph structure  
즉, Graph에서 노드들의 위치를 구분하지 못한다.

### 2) Limitation of One-hot Encoding
Models trained with one-hot encodings cannot generalize to unseen graphs, and arbitrarily deep GNNs still cannot distinguish structurally isomorphic nodes
One-hot encoding으로 모델을 학습시키면 Unseen Grpah에 대해서 일반화하지 못한다. 즉, Graph의 Isomorphic(Symmetric) node를 구별하지 못한다.

<p align="center">
<img width="600" alt="1" src="https://user-images.githubusercontent.com/111734605/210997783-963e93e9-d72f-4244-95ec-3ef2732d73ec.png">
</p>

## 2. Related Work
[GNN]()
[GCN]()
[GAN]()
[GIN]()
[GraphSAGE]()

<span style = "font-size: 80%">- 추후 업로드후 링크 업데이트 예정</span>
  
## 3. Method
### 1) Node Embedding
- <span style = "color:aqua">Vector Representation</span> of nodes in graph

즉, 그래프에 있는 노드 정보들을 벡터로 표현하는 것을 **노드 임베딩(Node Embedding)**이라고 한다.
노드 임베딩을 하는 방법으로는 크게 세 가지 방법이 있다.
- Node Embedding
  - Graph Neural Networks(GNNs)
  - Matrix-factorization
  - Random-walk-based(DeepWalk, node2vec,...)

<p align="center">
<img width="800" alt="1" src="https://user-images.githubusercontent.com/111734605/211763565-27c4a8b7-875b-4f6d-8d9a-699ed32b4a55.png">
</p>

위의 그림은 **node2vec** 아키텍쳐의 노드 임베딩을 시각화 한 것이다. node2vec 아키텍쳐는 자연어 처리(NLP)에서 많이 사용되는 모델이다. 간단히 설명하면 어떤 그래프가 주어졌을 때, Random-walk를 통해 graph smapling을 하고 만들어지 노드 페어(Node pair, 노드 쌍)를 **Word2Vec** 알고리즘을 적용해 임베딩 공간(Embedding space)를 표현합니다. 하지만 이런 Random-walk base method의 경우 [Transductive Setting]()을 가지고 있고 이런경우 노드의 정보를 제대로 사용하지 못합니다. <span style = "color:aqua">**GNN의 경우 애초에 Node feature 정보가 들어갈 수 있는데**</span>, Random-walk의 경우 Node property를 넣지 못한는 단점이 있습니다.

### 2) Structure-aware & Position-aware
- **Structure-aware** 
  - 어떤 노드 $$v_i$$가 주어졌을 때, k-hop까지  $$N_1~N_q$$까지 표현을 하는 어떤 함수 $$g$$
  - 이 g를 이용한 것이 **Structure-aware Embedding**이다.
  - GNN의 경우 Structure-aware이다.

<p align="center">
<img width="940" alt="image" src="https://user-images.githubusercontent.com/111734605/211779048-42527ef0-5483-4cb5-bdbf-1841bbc34c6f.png">
</p>

- **Position-aware**
  - 논문에서 Random-walk 아키텍쳐의 임베딩 방법을 Position-ware Embedding이라고 한다.
  - 여기서 $$g$$함수는 어떤 노드 $$v_i, v_j$$의 최단거리(Shortest Path, $$d_{sp}$$)와 같아지게 하는 함수
  - 이러한 임베딩 방법을 **Position-aware Embedding**이라고 한다.

<p align="center">
<img width="940" alt="image" src="https://user-images.githubusercontent.com/111734605/211779327-b7eb9030-22ff-46f3-8df7-727877c1f8c0.png">
</p>

일반적으로 두 Structure-aware Embedding은 Position-Aware Embedding가 아니다.

<span style = "font-size:120%">**Proposition**</span>    
There exists a mapping function $$g$$ that <span style = "color:aqua">**maps structure-aware embedding to position-aware embeddings**</span>, if and only if no pair of nodes have isomorphic local $$q$$-hop neighborhood graphs

논문에서 제안하는 것은 '만약에 어떤 노드 페어든, **Isomorphic한 특성을 따르지 않는다면** 이 Structure-aware embedding을 Position-aware embedding으로 mappong할 수 있는 함수 $$g$$가 있다.' 이다.

### 3) Limitation of GNN

<p align="center">
<img width="300" alt="image" src="https://user-images.githubusercontent.com/111734605/211781946-3ff20c42-30f4-49d9-8715-dde4656be39d.png">
</p>

## 4. Contribution
