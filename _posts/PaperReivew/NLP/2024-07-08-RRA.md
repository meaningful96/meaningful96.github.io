---
title: "[논문리뷰]Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-07-08
last_modified_at: 2024-07-08
---

*Wu, Y., Hu, N., Bi, S., Qi, G., Ren, J., Xie, A., & Song, W.* (2023, September 20). **Retrieve-Rewrite-Answer: A KG-to-Text enhanced LLMS framework for knowledge Graph question answering**. arXiv.org. [https://arxiv.org/abs/2309.11206](https://arxiv.org/abs/2309.11206)

# Problem Statment
<span style="font-size:110%">**1. LLM은 여전히 long-tail knowledge등의 모든 지식을 저장하는 것이 불가능하다**.</span>  
LLM은 여전히 long-tail knowledge등의 모든 지식을 저장하는 것이 불가능하기 때문에 specialized knowledge를 다루는 Knowledge-Intensive Task에서 낮은 성능을 보인다. 이는 **Hallucination**과 **Factual Inaccuracy**로 이어진다. 

<span style="font-size:110%">**2. 많은 양의 자원을 요구함**.</span>  
LLM을 지속적으로 pre-training하는 연구들은 방대한 양의 corpora를 학습한다. 하지만, 이는 **매우 많은 양의 text data, 컴퓨팅 자원, 학습 시간을 요구**한다는 단점이 있다.

<span style="font-size:110%">**3. 프롬프트 엔지니어링은 지식 표현의 중요성을 간과한다**.</span>
3.	일부 LLM 연구들은 지식을 보다 직접적인 방식으로 풍부하게 하기 위해, 질문과 관련된 사실적 정보를 질문 앞에 추가하여 지식이 보강된 프롬프트를 구성한다. 예를 들어 프롬프트 엔지니어링이 이에 해당한다. 이는 성능측면에서 성공적이고 cost-effective하다. 하지만, 이 방식은 **지식의 표현(knowledge representation)의 중요성을 간과**한다. (e.g., 단순 정보 추가로 인한 맥락과 관계성 부족, 효율적 활용의 한계)

<br/>
<br/>

# Related Work
<span style="font-size:110%">**1.	KG-Augmented LLM for KGQA**</span>  
- 사전에 정의된 템플릿을 통해 Triple과 Question의 textual representation을 knowledge-augmented prompt로 변환한다. 이렇게 변환된 프롬프트를 QA를 위한 LLM에 입력시켜 정답을 생성한다.
- 이 논문은 이러한 지식 표현 형식이 KGQA(Knowledge Graph Question Answering) 작업에서 LLM의 성능에 미치는 영향을 고려하지 않았다고 지적하고 있다. 즉, 지식을 어떤 형식으로 표현하여 LLM에 제공하느냐에 따라 성능이 달라질 수 있는데, 이전 연구들은 이 점을 충분히 고려하지 않았다는 것이다.

<span style="font-size:110%">**2. KG-to-Text**</span>  
- GNN 기반 접근법
  - GNN기반의 접근법은 subgraph의 구조적 정보를 효율적으로 인코딩할 수 있다. 이를 위해 더 복잡한 인코더를 설계하는 방향으로 연구가 진행중이다. 하지만, GNN은 locality정보만을 처리할 수 있고, 그래프의 global한 정보를 추출하지는 못한다.
  - 이를 해결하고자 Transformer기반의 아키텍쳐를 사용하여 인코더를 설계하는 연구들이 진행중이다.

- PLMs 기반 접근법
  - KG-to-Text를 end-to-end generation task로 모델링한다. 이 연구들은 모델 아키텍처를 수정하고 구조적 정보를 추출하는 능력을 향상시키기 위한 pre-training tasks을 도입하는 것을 포함한다.

<br/>
<br/>

# Method
## 0. Preliminary

<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/c9c887e7-599c-4f1a-89e1-9ed46f66120a">
</p>

모델 설명에 앞서 Knowledge를 표현하는 두 가지 형식에 대해 알아야 한다. KG에 존재하는 Knowledge를 **트리플의 형식**이 직관적으로 보이게 표현한 것이 바로 'Triple-form Text'이다. 반면, 문맥적으로 일반적인 텍스트 형태로 지식을 표현한 것을 'Free-form Text'라 한다.

- Triple-form Text
  - Ex) (Korea, capital, Seoul), (China, capital, Beijing)
  - Ex) (Leonardo Da Vinch, painted, Monarisa)

- Free-form Text
  - Ex) Korea's capital is Seoul, China's capital is Beijing
  - Ex) Leonardo Da Vinch painted Monarisa

다음으로 알아야 할 개념은, **Retrive-then-Answer(RA)**와  **Retrieve-Rewrite-Answer(RRA)**이다. 선행 연구들은 보통 RA방식을 채택하며, 본 논문에서 제안한 방식이 RRA이다. RA와 RRA의 가장 큰 차이는 **Rewrite 모듈**이다. Retrieve-than-Answer은 입력으로 들어온 질문을 KG에 검색해서 트리플 형식인 Triple-form Text형식으로 반환받는다. 이를 바로 zero-short으로 QA 모델에 입력해 정답을 추론한다. 반면, Retrieve-Rewrite-Answer은 <span style="color:lime">**트리플 형식의 자연어 표현을 Free-form Text형식으로 변환한 후 모델에 입력**</span>시킨다.

## 1. Model Architecture
### 1) Retrieve Module
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/0c3a0f7b-117a-45e7-8cd0-f359bc8a6e3a">
</p>

Retrieve-Rewrite-Answer은 이름에서와 같이 1) Retrieve Module, 2) Rewrite Module, 3) Answer Module 이 세 개의 모듈로 구성되어있다. 먼저 **Retrieve Module**은 말 그대로 입력으로 들어온 question에 대해서 유용한 정보를 찾기위해 KG에서 검색을 하는 과정이다. Retrieval은 **Hop prediction**, **Relation path prediction**, **Triple sampling**의 세 과정을 포함한다. 이를 통해 유용한 reasoning path를 찾아내게 된다. 

<span style="font-size:105%">**Hop Prediction**</span>  
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/cebc438a-4fed-4356-948e-d4be6fb16259">
</p>

Hop prediction은 <span style="color:gold">**질문에 필요한 relation path의 길이를 예측하는 과정**</span>이다. 다음은 hop prediction을 하는 과정을 수식으로 나타낸 것이다.

<center>$$
\begin{align}
(1) & \quad q_v = PLM(q) \\
\\(2) & \quad D'_h = [d'_{h1}, d'_{h2}, ..., d'_{hH}] = Linear(q_v) \\
\\(3) & \quad d'_{hc} = P(h_c | q_v), \quad c = 1, 2, ..., H \\
\\(4) & \quad h = \arg\max_{h_c} d'_{hc}, \quad c = 1, 2, ..., H \\
\\(5) & \quad D_h = [d_{h1}, d_{h2}, ..., d_{hH}] \\
\\(6) & \quad d_{hc} = 
\begin{cases}
1, & h_c = h_{\text{gold}} \\
0, & h_c \neq h_{\text{gold}}
\end{cases} \\
\\(7) & \quad L_{CE} = -D_h \log D'_h = - \sum_{c=1}^{H} d_{hc} \log d'_{hc}
\end{align}
$$</center>

1. 식(1) $$q_v = \text{PLM}(q)$$: 질문 $$q$$를 벡터 표현 $$q_v$$로 인코딩한다. 
2. 식(2) $$D'_h = [d'_{h1}, d'_{h2}, \ldots, d'_{hH}] = \text{Linear}(q_v)$$: 질문 벡터 $$q_v$$를 선형 분류 계층을 통해 각 홉 수에 대한 확률 분포 $$D'_h$$를 계산한다.
3. 식(3) $$d'_{hc} = P(h_c \vert q_v), \quad c = 1, 2, \ldots, H$$: 각 홉 수 $$h_c$$에 대한 확률 $$d'_{hc}$$를 계산한다.
4. 식(4) $$h = \arg\max_{h_c} d'_{hc}, \quad c = 1, 2, \ldots, H$$: 가장 높은 확률을 가진 홉 수 $$h$$를 선택한다. 
5. 식(5) $$D_h = [d_{h1}, d_{h2}, \ldots, d_{hH}]$$: 정답 홉 수에 대한 원핫 벡터 $$D_h$$를 생성한다. 
6. 식(6) $$d_{hc} =  \begin{cases} 1, & h_c = h_{\text{gold}} \\ 0, & h_c \neq h_{\text{gold}} \end{cases}$$: $$h_{\text{gold}}$$가 정답 홉 수일 때, 해당 홉 수에 대한 확률을 1로 설정하고, 나머지는 0으로 설정한다. 
7. 식(7) $$L_{CE} = -D_h \log D'_h = - \sum_{c=1}^{H} d_{hc} \log d'_{hc}$$: 교차 엔트로피 손실 $$L_{CE}$$를 계산한다.

정리하자면, Retrieval의 가장 첫번째 단계인 hop prediction은 주어진 질문에 대해 몇 개의 홉(Multi level)이 필요한지를 예측하기 위한 과정이다. 이 과정은 질문을 벡터로 인코딩하고, 이를 통해 각 홉 수에 대한 확률 분포를 계산한 후, 가장 높은 확률을 가진 홉 수를 선택한다. 이를 통해 모델은 복잡한 다중 홉 질문에 대해 적절한 관계 경로를 예측할 수 있다.


<span style="font-size:105%">**Relation Path Prediction**</span>    
Relation Path Prediction은 <span style="color:gold">**예측된 hop수에 따라 각 단계별 relation을 순차적으로 예측하고, 최종적으로 reasoning path에 대한 relation path를 구하는 과정**</span>이다. 이 과정은 전반적으로 hop prediction하고 유사하다.

<center>$$
\begin{align}
(1) & \quad q_v = PLM(q) \\
\\(2) & \quad D'_{r,1} = [d'_{r1}, d'_{r2}, ..., d'_{rR}] = Linear(q_v) \\
\\(3) & \quad d'_{rc} = P(r_c | q_v), \quad c = 1, 2, ..., R \\
\\(4) & \quad p_{t-1,i} = r_{i,1} | r_{i,2} | ... | r_{i,t-1}, \quad i = 1, 2, ..., K_{t-1} \\
\\(5) & \quad Q_t = q | r_{i,1} | r_{i,2} | ... | r_{i,t-1} \\
\\(6) & \quad Q_{t,v} = PLM(Q_t) \\
\\(7) & \quad D'_{r,t} = [d'_{r1}, d'_{r2}, ..., d'_{rR}] = Linear(Q_{t,v}) \\
\\(8) & \quad d'_{rc} = P(r_c | Q_{t,v}), \quad c = 1, 2, ..., R \\
(9) & \quad Score(p_{t,i}) = Score(r_{i,1} | r_{i,2} | ... | r_{i,t}) = \prod_{l=1}^{t} d'_{r_{i,l}}, \quad i = 1, 2, ..., K^h
\end{align}
$$</center>

1. 식(1) $$q_v = \text{PLM}(q)$$: 질문 $$q$$를 벡터 표현 $$q_v$$로 인코딩한다. 
2. 식(2) $$D'_{r,1} = [d'_{r1}, d'_{r2}, \ldots, d'_{rR}] = \text{Linear}(q_v)$$: 질문 벡터 $$q_v$$를 선형 분류 계층을 통해 첫 번째 홉의 관계 확률 분포 $$D'_{r,1}$$를 계산한다. 
3. 식(3) $$d'_{rc} = P(r_c \vert q_v), \quad c = 1, 2, \ldots, R$$: 각 관계 $$r_c$$에 대한 확률 $$d'_{rc}$$를 계산한다. 
4. 식(4) $$p_{t-1,i} = r_{i,1} \vert r_{i,2} \vert \ldots \vert r_{i,t-1}, \quad i = 1, 2, \ldots, K_{t-1}$$: 이전 홉까지의 관계 경로 $$p_{t-1,i}$$를 나타낸다. 
5. 식(5) $$Q_t = q \vert r_{i,1} \vert r_{i,2} \vert \ldots \vert r_{i,t-1}$$: 질문과 이전 관계 경로를 연결하여 새로운 입력 시퀀스 $$Q_t$$를 만든다. 
6. 식(6) $$Q_{t,v} = \text{PLM}(Q_t)$$: 입력 시퀀스 $$Q_t$$를 벡터 표현 $$Q_{t,v}$$로 인코딩한다. 
7. 식(7) $$D'_{r,t} = [d'_{r1}, d'_{r2}, \ldots, d'_{rR}] = \text{Linear}(Q_{t,v})$$: $$Q_{t,v}$$를 선형 분류 계층을 통해 다음 홉의 관계 확률 분포 $$D'_{r,t}$$를 계산한다. 
8. 식(8) $$d'_{rc} = P(r_c \vert Q_{t,v}), \quad c = 1, 2, \ldots, R$$: 각 관계 $$r_c$$에 대한 확률 $$d'_{rc}$$를 계산한다. 
9. 식(9) $$Score(p_{t,i}) = Score(r_{i,1} \vert r_{i,2} \vert \ldots \vert r_{i,t}) = \prod_{l=1}^{t} d'_{r_{i,l}}, \quad i = 1, 2, \ldots, K^h$$: 관계 경로 $$p_{t,i}$$의 점수는 경로에 있는 모든 관계의 확률의 곱으로 계산된다.


<br/>
<br/>

# Experiments

<br/>
<br/>

# Limitations and Contributions
