---
title: "[논문리뷰]D2LLM:Decomposed and Distilled Large Language Models for Semantic Search"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2025-09-11
last_modified_at: 2025-09-11
---

*Zihan Liao, Hang Yu, Jianguo Li, Jun Wang, and Wei Zhang*. 2024. [D2LLM:Decomposed and Distilled Large Language Models for Semantic Search](https://aclanthology.org/2024.acl-long.791/). In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Lun-Wei Ku, Andre Martins, and Vivek Srikumar(Eds.). Association for Computational Linguistics, Bangkok, Thailand, 14798–14814.https://doi.org/10.18653/v1/2024.acl-long.791

# Problem Statement

**[BERT Style Bi-Encoder]:** 쿼리와 문서에 대해 독립적으로 벡터를 생성하여 효율성이 뛰어나지만, 미묘한 의미 차이를 포착하지 못해 정확도가 떨어진다. 또한, 방대한 양의 데이터에 대한 복잡한 다단계 학습 과정이 필요하다는 한계가 존재한다.

**[GPT Style Cross-Encoder]:**  쿼리와 문단을 하나의 입력으로 결합하여 처리함으로써 정확도가 높다. 특히, 방대한 양의 지식을 사전 학습하여 도메인별 사전 학습이 필요 없고, 새로운 도메인에도 강건한 zero-shot 학습 능력을 보인다. 하지만, 문서의 벡터를 미리 계산할 수 없어 새로운 쿼리-문서 쌍마다 계산을 다시 수행해야하므로 실시간 처리에는 비효율적이다.

<br/>
<br/>

# Methodology
## Overview
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.11%5DD2LLM/figure1.png?raw=true">
</p>

**D2LLM**은 Cross-Encoder의 강점인 정확도와 Bi-Encoder의 효율성을 결합한 시맨틱 검색 모델이다. 먼저 **LLM 기반의 Cross-Encoder를 교사 모델**로 설정한다. 교사 모델은 쿼리와 문서를 하나의 입력으로 결합하고, 특별히 설계된 프롬프트(symmetric, asymmetric)를 활용하여 정교한 의미적 관계를 파악한다. 그런 다음, 효율성을 극대화하기 위해 교사 모델을 **Bi-Encoder**와 **Interaction Emulation Module (IEM)**을 포함하는 **학생 모델(Student Model)**로 분해한다. Bi-Encoder는 **PMA(Pooling by Multihead Attention)**를 사용하여 쿼리와 문단에 대한 개별 벡터 임베딩을 효율적으로 생성한다. 이와 동시에, IEM은 이 두 임베딩을 결합하여 교사 모델의 복잡한 상호 작용 방식을 모방한다. 

학생 모델은 **지식 증류(Knowledge Distillation)** 과정을 통해 학습된다. 이 과정에는 교사 모델의 점수를 활용하여 관련 샘플에 가중치를 부여하는 **Contrastive Imitation**, 긍정 및 부정 샘플 간의 미묘한 순위 차이를 맞추는 **Rank Imitation**, 그리고 교사 모델의 임베딩 관계 패턴을 모방하는 **Feature Imitation**이 있다. 이처럼 D2LLM은 교사 모델의 지식을 흡수하며 효율성과 정확성 사이의 균형을 효과적으로 달성한다.

## Teacher Model (LLM)
<p align="center">
<img width="400" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.11%5DD2LLM/figure6.png?raw=true">
</p>

- **Input**: Query-Passage Pair ($$\mathbf{X}_i, \mathbf{X}_j$$) + Prompt($$\mathbf{P}$$)
- **Output**: 분류 토큰 임베딩 $$y_{ij}^{\mathcal{T}}$$

먼저 LLM의 zero-shot 학습 능력을 활용하기 위해, 프롬프트 엔지니어링을 적용해 query-passage 쌍을 분석하도록 LLM을 유도하는 특정 프롬프트를 설계한다.  이 프롬프트 $$\mathbf P \in (\mathbf P^{\text{sym}},\mathbf P^{\text{asym}})$$는 대칭(symmetric)과 비대칭(asymmetric) 검색을 위한 두 가지 프롬프트로 구성된다.

- **대칭 검색(Symmetric Search)**
    - **정의**: Query와 Passage가 **동일한 역할/형태**를 가지며, 상호 교환이 가능할 때
    - **예시**:
        - "What are the symptoms of the flu?" ↔ "What are the flu symptoms?"
        - 두 문장은 서로 같은 의미를 담고 있으며, 단순히 **문장 유사도 측정**(semantic similarity)이 목적임
    - **특징**: Query와 Passage가 모두 질문(question) 혹은 짧은 진술문(statement)일 수 있음
    - **Task 예시**: NLI(Natural Language Inference), STS(Semantic Textual Similarity)
    
- **Asymmetric Search**
    - **정의**: Query와 Passage가 **서로 다른 역할**을 가지며, 교환 불가능할 때
    - **예시**:
        - Query: "What are the symptoms of the flu?"
        - Passage: "The flu typically causes fever, cough, sore throat, runny nose, muscle aches, and fatigue."
        - Query는 **질문**, Passage는 **답변/설명 문서**로 역할이 다름
    - **특징**: Query는 짧고 정보 요청 중심, Passage는 길고 정보 제공 중심
    - **Task 예시**: 정보 검색(IR), QA Retrieval
 
LLM에 쿼리-문서 쌍과 프롬프트를 입력시키고, 프롬프트의 마지막 토큰의 hidden state embedding을  classification token embedding으로 사용한다.

<center>$$y_{ij}^{\mathcal{T}} = \text{LLM}(\mathbf{X}_i, \mathbf{X}_j, \mathbf{P})$$</center>

이 마지막 토큰의 히든 스테이트 임베딩 $$y_{ij}^{\mathcal T}$$가 분류 토큰으로 기능하여 쿼리-문서 쌍이 관련 있는지 여부를 표시하며, 프롬프트는 검색 유형(대칭, 비대칭)에 맞도록 적응을 돕는다.

“yes” 혹은 “no”의 확률을 계산하기 위해 LLM의 마지막 레이어의 projection weight matrix $$W^{\mathcal T} \in \mathbb R^{\vert V \vert \times d}$$를 이용한다. 이 가중치 행렬은 모든 vocabulary집합에 대한 임베딩 행렬로, 타겟으로 하는 것은 “yes”, “no” 두 개이기 때문에 실제로 사용되는 것은 $$W^{\mathcal T}[yes, no] \in \mathbb R^{2 \times d}$$ 이다.

## Student Model
<p align="center">
<img width="500" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.11%5DD2LLM/figure7.png?raw=true">
</p>

<br/>
<br/>

# Experiments



<br/>
<br/>
