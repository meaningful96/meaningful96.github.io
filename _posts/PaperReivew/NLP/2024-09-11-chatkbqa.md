---
title: "[논문리뷰]ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-09-16
last_modified_at: 2024-09-16
---

# Problem Statement

<p align="center">
<img width="500" alt="1" src="https://github.com/user-attachments/assets/c4901691-6aee-48cd-b386-5848840efbfb">
</p>

<span style="font-size:110%">C1. 낮은 검색 정확도</span>  
- 자연어 형태의 질문의 경우 Knowledge Base에 있는 형태와 다름.
- 종종 엔티티나 릴레이션이 잘못 검색되거나, 검색하지 못하는 경우가 발생.
- Ex) “한국의 수도는 어디인가?”
  - In KB, ‘수도’ = m2476, ‘서울’ = m748


<span style="font-size:110%">C2. 잘못된 검색 결과는 의미 분석을 혼란 시킴.</span>  
- C1에서와 같이 검색 결과가 자연어가 아닌 엔티티 ID가 섞여 같이 LLM에 입력되면 의미상 혼란이 발생할 수 있음.
- Ex) 질문: “한국의 수도는 어디인가?”, KB 검색 결과: (한국, ~이다, m2476), (m2476, 포함되다, m748)
  - LLM ← “한국의 수도는 어디인가? (한국, ~이다, m2476), (m2476, 포함되다, m748)”
  - 답변: 경주

<span style="font-size:110%">C3. “검색(Retrieve)”, “변환(Transform)”, “생성(Generation)”의 반복 구조로 모델의 복잡성 증가</span>  
- 기존의 KBQA에서 RAG를 사용하는 모델들은 대부분 “Retrieve-then-Generation” 기반
- LLM이 1)입력으로 들어오는 질문을 해석, 2)Database에 검색, 3)검색된 엔티티와 릴레이션을 자연어로 변환, 4)LLM에 입력, 5)정답 생성

<br/>
<br/>

# Method

## 논리적 형식(Logical Form)
<p align="center">
<img width="800" alt="1" src="https://github.com/user-attachments/assets/95348a6d-720b-424b-8fc1-34a9ca319272">
</p>

논리적 형식(Logical Form)은 복잡한 자연어 질문을 지식 베이스에서 실행할 수 있는 형식으로 변환한 것이다. 그래프 쿼리(Graph Query)는 지식 베이스 상에서 조건을 만족하는 경로를 탐색하는 질의다. 위 사진에서는 고혈압과 심부전에 적합하면서 신부전에 금기사항이 아닌 약물들을 찾아, 그 중 상호 상승 효과가 있는 약물을 탐색하는 과정이 그래프 형태로 표현된 것이다.

그래프 쿼리에서 AND와 NOT 연산자는 질의에서 여러 관계를 동시에 만족시키거나 배제하는 역할을 한다. 예를 들어, Hypertension과 Heart Failure에 모두 적합한 약물을 찾아야 하므로 이 둘 사이에는 AND 연산이 사용되고, Kidney Failure에 금기사항인 약물을 제외하기 위해 NOT 연산이 사용된다.

## Model Architecture
<p align="center">
<img width="800" alt="1" src="https://github.com/user-attachments/assets/687d9aa5-0e44-4136-b006-f09dbbcafb02">
</p>



<br/>
<br/>

# Experiments and Results



<br/>
<br/>

# Limitations and Contributions



<br/>
<br/>

# Reference
\[1\] *Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, Guanting Dong, Meina Song, Wei Lin, Yifan Zhu, and Luu Anh Tuan*. 2024. [**Chatkbqa: A generate-then retrieve framework for knowledge base question answering with fine-tuned large language models**](https://arxiv.org/abs/2310.08975).  

