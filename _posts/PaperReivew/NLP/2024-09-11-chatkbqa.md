---
title: "[논문리뷰]ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-09-16
last_modified_at: 2024-09-16
---

# Problem Statement

<p align="center">
<img width="500" alt="1" src="https://github.com/user-attachments/assets/c4901691-6aee-48cd-b386-5848840efbfb">
</p>

<span style="font-size:110%">C1. 낮은 검색 정확도</span>  
- 자연어 형태의 질문의 경우 Knowledge Base에 있는 형태와 다름.
- 종종 엔티티나 릴레이션이 잘못 검색되거나, 검색하지 못하는 경우가 발생.
- Ex) “한국의 수도는 어디인가?”
  - In KB, ‘수도’ = m2476, ‘서울’ = m748


<span style="font-size:110%">C2. 잘못된 검색 결과는 의미 분석을 혼란 시킴.</span>  
- C1에서와 같이 검색 결과가 자연어가 아닌 엔티티 ID가 섞여 같이 LLM에 입력되면 의미상 혼란이 발생할 수 있음.
- Ex) 질문: “한국의 수도는 어디인가?”, KB 검색 결과: (한국, ~이다, m2476), (m2476, 포함되다, m748)
  - LLM ← “한국의 수도는 어디인가? (한국, ~이다, m2476), (m2476, 포함되다, m748)”
  - 답변: 경주

<span style="font-size:110%">C3. “검색(Retrieve)”, “변환(Transform)”, “생성(Generation)”의 반복 구조로 모델의 복잡성 증가</span>  
- 기존의 KBQA에서 RAG를 사용하는 모델들은 대부분 “Retrieve-then-Generation” 기반
- LLM이 1)입력으로 들어오는 질문을 해석, 2)Database에 검색, 3)검색된 엔티티와 릴레이션을 자연어로 변환, 4)LLM에 입력, 5)정답 생성

<br/>
<br/>

# Method

## 논리적 형식(Logical Form)
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/95348a6d-720b-424b-8fc1-34a9ca319272">
</p>

논리적 형식(Logical Form)은 복잡한 자연어 질문을 지식 베이스에서 실행할 수 있는 형식으로 변환한 것이다. 그래프 쿼리(Graph Query)는 지식 베이스 상에서 조건을 만족하는 경로를 탐색하는 질의다. 위 사진에서는 고혈압과 심부전에 적합하면서 신부전에 금기사항이 아닌 약물들을 찾아, 그 중 상호 상승 효과가 있는 약물을 탐색하는 과정이 그래프 형태로 표현된 것이다.

그래프 쿼리에서 AND와 NOT 연산자는 질의에서 여러 관계를 동시에 만족시키거나 배제하는 역할을 한다. 예를 들어, Hypertension과 Heart Failure에 모두 적합한 약물을 찾아야 하므로 이 둘 사이에는 AND 연산이 사용되고, Kidney Failure에 금기사항인 약물을 제외하기 위해 NOT 연산이 사용된다.

지식 베이스(Knowledge Base, KB)는 RDF(Resource Description Framework) 그래프의 한 종류로, **지식을 (주체, 술어, 객체) 형태의 트리플로 저장**한다. KB는 $$\mathcal{K} = (s, r, o)$$로 표현한다. 논리적 형식 <span style="color:red">**자연어 질문을 구조화된 표현**</span>으로 나타낸 것이다. S-표현식(S-expression)에 기반해 트리플을 표현한다. S표현식이란 리스트와 기호로 이루어진 단순한 형태의 표현 방식이다.

- **One-hop 쿼리** = triple = (s, r, o)
  - (s, r, ?) = (**JOIN** (R r), S)
  - (?, r, o) = (**JOIN** r o)
  - E1과 E2의 **interaction** = (**AND** E1 E2)
  - E1을 **counting** = (**COUNT** E1)

이외에도 논문에서는 여러 가지 기호를 사용하여 정의한다. ChatKBQA는 주어진 질문에 대한 정답을 찾기 위해 지식 베이스를 검색하고, 그 과정에서 SPARQL을 사용하게된다. 입력으로 들어온 자연어 질문(query)과 KB를 각각 $$\mathcal{Q}$$, $$\mathcal{K}$$라 할 때, 먼저 ChatKBQA는 논리적 형식으로 바꾸는 작업을 한다. 논리적 형식을 $$F$$라 할 때, 자연어 질문을 바꿔주는 Semantic parsing 함수를 $$\text{Sp}(Q)$$라고 하면$$F = \text{Sp}(Q)$$로 표현할 수 있다. 이를 다시 SPARQL 쿼리 $$q$$로 나타내기 위해 고정된 변환 함수를 이용하고 이 과정을 $$q = \text{Convert}(F)$$로 표현할 수 있다. 이후 최종 정답 집합 $$A$$를 $$A = \text{Execute}(q \vert \mathcal{K})$$로 표현할 수 있다.

<center>$$\mathcal{Q} \rightarrow \text{Logical Form } F = \text{Sp}(Q) \rightarrow \text{SPARQL query } q = \text{Convert}(F) \rightarrow A = \text{Execute}(q \vert \mathcal{K}) $$</center>


## Model Architecture
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/687d9aa5-0e44-4136-b006-f09dbbcafb02">
</p>




<br/>
<br/>

# Experiments and Results



<br/>
<br/>

# Limitations and Contributions



<br/>
<br/>

# Reference
\[1\] *Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, Guanting Dong, Meina Song, Wei Lin, Yifan Zhu, and Luu Anh Tuan*. 2024. [**Chatkbqa: A generate-then retrieve framework for knowledge base question answering with fine-tuned large language models**](https://arxiv.org/abs/2310.08975).  

