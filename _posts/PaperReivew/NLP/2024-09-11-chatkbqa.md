---
title: "[논문리뷰]ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-09-16
last_modified_at: 2024-09-16
---

# Problem Statement
<span style="font-size:110%">C1. 낮은 검색 정확도</span>  
- 자연어 형태의 질문의 경우 Knowledge Base에 있는 형태와 다름.
- 종종 엔티티나 릴레이션이 잘못 검색되거나, 검색하지 못하는 경우가 발생.
- Ex) “한국의 수도는 어디인가?”
  - In KB, ‘수도’ = m2476, ‘서울’ = m748


<span style="font-size:110%">C2. 잘못된 검색 결과는 의미 분석을 혼란 시킴.</span>  
- C1에서와 같이 검색 결과가 자연어가 아닌 엔티티 ID가 섞여 같이 LLM에 입력되면 의미상 혼란이 발생할 수 있음.
- Ex) 질문: “한국의 수도는 어디인가?”, KB 검색 결과: (한국, ~이다, m2476), (m2476, 포함되다, m748)
  - LLM ← “한국의 수도는 어디인가? (한국, ~이다, m2476), (m2476, 포함되다, m748)”
  - 답변: 경주

<span style="font-size:110%">C3. “검색(Retrieve)”, “변환(Transform)”, “생성(Generation)”의 반복 구조로 모델의 복잡성 증가</span>  
- 기존의 KBQA에서 RAG를 사용하는 모델들은 대부분 “Retrieve-then-Generation” 기반
- LLM이 1)입력으로 들어오는 질문을 해석, 2)Database에 검색, 3)검색된 엔티티와 릴레이션을 자연어로 변환, 4)LLM에 입력, 5)정답 생성

<br/>
<br/>

# Method

## 논리적 형식(Logical Form)
<p align="center">
<img width="500" alt="1" src="https://github.com/user-attachments/assets/b2b379bf-70af-4f01-90c8-d05bff0bafad">
</p>

논리적 형식(Logical Form)은 복잡한 자연어 질문을 지식 베이스에서 실행할 수 있는 형식으로 변환한 것이다. 그래프 쿼리(Graph Query)는 지식 베이스 상에서 조건을 만족하는 경로를 탐색하는 질의다. 위 사진에서는 고혈압과 심부전에 적합하면서 신부전에 금기사항이 아닌 약물들을 찾아, 그 중 상호 상승 효과가 있는 약물을 탐색하는 과정이 그래프 형태로 표현된 것이다.

그래프 쿼리에서 AND와 NOT 연산자는 질의에서 여러 관계를 동시에 만족시키거나 배제하는 역할을 한다. 예를 들어, Hypertension과 Heart Failure에 모두 적합한 약물을 찾아야 하므로 이 둘 사이에는 AND 연산이 사용되고, Kidney Failure에 금기사항인 약물을 제외하기 위해 NOT 연산이 사용된다.

지식 베이스(Knowledge Base, KB)는 RDF(Resource Description Framework) 그래프의 한 종류로, **지식을 (주체, 술어, 객체) 형태의 트리플로 저장**한다. KB는 $$\mathcal{K} = (s, r, o)$$로 표현한다. 논리적 형식 <span style="color:red">**자연어 질문을 구조화된 표현**</span>으로 나타낸 것이다. S-표현식(S-expression)에 기반해 트리플을 표현한다. S표현식이란 리스트와 기호로 이루어진 단순한 형태의 표현 방식이다.

- **One-hop 쿼리** = triple = (s, r, o)
  - (s, r, ?) = (**JOIN** (R r), S)
  - (?, r, o) = (**JOIN** r o)
  - E1과 E2의 interaction = (**AND** E1 E2)
  - E1을 counting = (**COUNT** E1)

이외에도 논문에서는 여러 가지 기호를 사용하여 정의한다. ChatKBQA는 주어진 질문에 대한 정답을 찾기 위해 지식 베이스를 검색하고, 그 과정에서 SPARQL을 사용하게된다. 입력으로 들어온 자연어 질문(query)과 KB를 각각 $$\mathcal{Q}$$, $$\mathcal{K}$$라 할 때, 먼저 ChatKBQA는 논리적 형식으로 바꾸는 작업을 한다. 논리적 형식을 $$F$$라 할 때, 자연어 질문을 바꿔주는 Semantic parsing 함수를 $$\text{Sp}(Q)$$라고 하면$$F = \text{Sp}(Q)$$로 표의

<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/555596d2-a399-487c-93d4-63f0a680820a">
</p>

이전 연구들에서는 주로 지식 베이스를 활용한 QA 문제를 풀 때 **Retrieve-then-Generate** 형식을 취했다. 즉, 주어진 질문과 관련된 토픽 엔티티(Topic entity)를 기반으로 KB에 검색하고, 토픽 엔티티를 기반으로 정답 엔티티로 가능 추론 경로(reasoning path)를 추출하고, 이 추론 경로를 LLM에 넣어주어 정답을 생성하는 방식이다. 예를 들어 RoG나 GNN-RAG같은 모델이 이에 해당한다.

혹은 입력으로 들어온 질문에 대해 먼저 KB에서 관련된 엔티티와 릴레이션을 검색하고 이를 기반으로 의미 분석(Semantic parsing)을 통해 논리적 형식을 생성하는 방법을 따른다. 이러한 방식은 ChatKBQA와 정반대 방식이며, 검색된 엔티티나 릴레이션이 부정확한 경우 이후 논리적 형식이 잘못될 수 있다는 치명적인 단점이 존재한다. 따라서, 중간 단계에서 한 번 잘못 검색되면 최종 답변에 부정적인 영향을 주게된다. 

반면 ChatKBQA는 <span style="color:red">**Generate-then-Retrieve**</span> 방식이다. 먼저 <spans tyle="color:red">**논리적 형식(Logical form)을 생성**하고, 이를 **SPARQL 쿼리**로 변환 후 **KB에 검색**</span>하는 방식이다. 논리적 형식을 먼저 생성하기 때문에, 잘못된 검색 결과가 논리 구조에 영향을 주지 않으며, 따라서 검색의 오류를 줄여 더 정확한 결과를 도출할 수 있게 된다.

## Model Architecture
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/40ab3411-2715-4fef-8954-66ddec0474b0">
</p>

ChatKBQA는 크게 네 단계에 걸쳐 정답을 생성하게 된다. 가장 먼저 논리적 형식을 생성하기 위해 **1)LLM을 fine-tuning**한다. 그리고 학습된 LLM을 사용해 질문에 대한 논리적 형식을 생성하고 **2)Beam search**를 통해 가장 좋은 논리적 형식을 생성하게 된다. 최종적으로 생성된 논리적 형식은 자연어만을 포함하기 때문에, 이를 **3)엔티티의 ID와 릴레이션 ID로 변환**하는 과정을 거치고, 변환된 논리적 형식을 고정된 함수에 넣어 **4)SPARQL 쿼리**로 변환한다. 그리고 변환된 쿼리를 통해 KB에 검색하고 정답을 찾게된다.

### 1) Fine-tuning LLM
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/ee6f0d60-fd69-4210-95e4-68c69296af35">
</p>

ChatKBQA이 LLM을 학습하는 처음이자 마지막인 단계이다. LLM이 입력으로 들어오는 자연어 질문 쿼리에 대해 논리적 형식(Logical form)을 출력할 수 있도록 Fine-tuning하는 단계이자, 이는 곧 Instruction tuning과도 동일하다. 다시 말해, LLM이 입력으로 들어온 질문에 대해 <span style="color:red">**Instruction 형태로 결과를 출력하도록 학습을 유도**</span>한다. LLM은 Llama2-7B와 Llama2-13B를 사용하였다.

예를 들어, 입력으로 "*What ios the name of Justin bieber's brother?*"라는 질문이 들어왔을 때 LLM이 출력하는 논리적 형식은 다음과 같다.

```bash
"( AND ( JOIN [ people , person , gender ] [ Male ] ), 
 	     ( JOIN ( R [ people , sibling relationship , sibling ]),
       ( JOIN ( R [ people , person , siblings ] ) [ Justin Bieber])"
```

<br/>

### 2) Beam Search using Fine-tuned LLM
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/2ec9772d-d15e-4eb0-83af-bd82c69f44dc">
</p>
다음으로 학습된 LLM을 논리적 형식을 만드는 과정이다. LLM은 fine-tuning을 통해 의미 분석(semantic parsing)을 위해 자연어 질문을 논리적 형식으로 변환하는 지식을 습득하였다. 저자들은 학습 중 등장하지 않은 test set의 질문들에 대해 미리 정답이 되는 논리적 형식을 만들고, LLM이 출력한 논리적 형식과 비교하였다. 그 결과, LLM은 63%의 정확도로 정확하게 논리적 형식을 생성해내었다. 

논문에서는 좀 더 높은 정확성을 위해 Beam Search를 통한 논리적 형식 생성 방식을 제안한다. 또한 후보 논리적 형식에서 채워지지않은 엔티티와 릴레이션의 자리를 \[\]로 대체한 논리적 형식의 스켈레톤 구조를 통해 더 정확한 논리적 형식을 생성해 내도록 하였다. 예를 들어, LLM이 `( JOIN ( R [ people , person , siblings ] ) [ Justin Bieber])` S-표현식에서 릴레이션의 정보를 찾지 못했다면 다음과 같이 모델이 출력한다. 참고로 (**JOIN** (R r), S)은 헤드와 릴레이션(=주체와 술어)이 주어진 상태를 의미한다.

```bash
# (s, r, ?) = (**JOIN** (R r), S)

"( AND ( JOIN [ people , person , gender ] [ Male ] ), 
 	     ( JOIN ( R [ people , sibling relationship , sibling ]),
       ( JOIN ( R []) [ Justin Bieber])"
```



<br/>

### 3) Transform and Retrieve
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/ced0f146-d3c6-4bb6-8f84-6db89b155274">
</p>


<br/>

### 4) SPARQL Query
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/d528bb81-5cbf-4da3-8a8f-f769ddb3a78e">
</p>


<br/>


<br/>
<br/>

# Experiments and Results



<br/>
<br/>

# Limitations and Contributions



<br/>
<br/>

# Reference
\[1\] *Haoran Luo, Haihong E, Zichen Tang, Shiyao Peng, Yikai Guo, Wentai Zhang, Chenghao Ma, Guanting Dong, Meina Song, Wei Lin, Yifan Zhu, and Luu Anh Tuan*. 2024. [**Chatkbqa: A generate-then retrieve framework for knowledge base question answering with fine-tuned large language models**](https://arxiv.org/abs/2310.08975).  

