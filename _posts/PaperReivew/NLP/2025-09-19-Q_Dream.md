---
title: "[논문리뷰]Optimizing Question Semantic Space for Dynamic Retrieval-Augmented Multi-hop Question Answering (ACL, 2025)"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2025-09-19
last_modified_at: 2025-09-19
---

*Linhao Ye, Lang Yu, Zhikai Lei, Qin Chen, Jie Zhou, and Liang He*. 2025. [**Optimizing Question Semantic Space for Dynamic Retrieval-Augmented Multi-hop Question Answering**](https://aclanthology.org/2025.acl-long.871/). In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Wanxiang Che, Joyce Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar (Eds.). Association for Computational Linguistics, Vienna, Austria, 17814–17824. https://doi.org/10.18653/v1/2025.acl-long.871

# Problem Statement
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.19%5DQ-dream/q_dream_figure1.png?raw=true">
</p>

**[Semantic Mismatching]** 기존 RAG 프레임워크에서 가장 치명적인 문제 중 하나는 질문과 passage 간의 의미 공간 불일치(semantic proximity gap)이다. 질문과 실제로 도움이 되는 passage 사이의 내재된 <span style="color:gold">**의미 패턴이 다름에도 불구하고, 동일한 임베딩 인코더를 공유하기 때문에 겉보기에 유사한 문서가 더 높은 점수를 받아 검색**</span>되는 경우가 많다. 예를 들어, “20℃에서 얼음이 녹는가?”라는 질문에 대해 얼음의 운동 특성을 다룬 비관련 문서가 높은 유사도로 선택되고, 실제로는 녹는점이 0℃임을 설명하는 핵심 문서는 무시되는 사례가 발생한다. 이 문제는 Multi-hop QA에서 더욱 심각해지며, 모델이 잘못된 증거를 바탕으로 잘못된 추론을 하게 만든다.
- Q-DREAM은 이 문제를 해결하기 위해 **질문 의미 공간을 클러스터별 전용 retrieval 공간으로 최적화**하여, 질문 유형에 따라 **도움이 되는 passage와 질문을 강하게 정렬**하는 방법을 제안한다.

**[Subquestion Dependency 문제]** Multi-hop QA는 본질적으로 원 질문을 여러 subquestion으로 나누어 단계적 추론을 수행해야 한다. 하지만 많은 경우 <span style="color:gold">******subquestion들이 서로 의존성**</span>을 가지며, 선행 질문의 답변을 알아야만 후속 질문을 완전하게 구성할 수 있다. 기존 방식은 이 의존성을 무시하거나 단순한 분해에 그쳐, 불완전한 subquestion을 그대로 검색기에 입력한다. 그 결과, retrieval 품질이 떨어지고 중요한 증거를 놓치게 된다.
- Q-DREAM은 이를 위해 **subquestion Dependency Optimizer (SDOM)**모듈을 도입하여, 의존성을 가진 subquestion을 선행 질문의 답변과 결합해 맥락적으로 완전한 질문으로 재구성한다.

**[High Computational Cost 문제]** 최근 IRCoT와 같은 기법은 retrieval과 reasoning을 반복적으로 상호작용시키며 multi-hop QA 성능을 개선해왔다. 하지만 이러한 방식은 매 단계마다 retriever와 generator를 교차로 호출해야 하므로 <span style="color:gold">**모델 호출 횟수가 기하급수적으로 증가**</span>.하고, <span style="color:gold">**추론 속도와 비용**</span>이 크게 증가한다. 실제로 IRCoT는 높은 정확도를 달성했지만, 실시간 서비스나 대규모 QA 시스템에는 비효율적이라는 한계가 있다.
- Q-DREAM은 세 모듈을 통해 **독립적이고 병렬적인 retrieval**을 가능하게 하여, **추론 과정에서 반복 호출을 줄이고 효율성을 높이는 설계**를 제안한다.

**[Long-tail Knowledge Retrieval 한계]** Multi-hop QA에서는 빈도가 낮거나 드문 엔티티와 사실(Long-tail Knowledge)이 자주 등장한다. 그러나 기존 RAG는 이러한 지식을 효과적으로 회수하지 못한다. 이는 임베딩 공간이 고빈도 패턴에 편향되어 학습되기 때문에, 희귀 패턴은 검색 성능이 크게 떨어지는 것이다. 본 논문은 이 문제를 직접적으로 해결하지는 않지만, 향후 과제로 제시하며 연구의 한계를 명시한다.

<br/>
<br/>

# Methodology
## Overview
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.19%5DQ-dream/q_dream_figure2.png?raw=true">
</p>

Q-DREAM은 Question Decomposition Module (QDM), Subquestion Dependency Optimizer Module (SDOM), Dynamic Passage Retrieval Module (DPRM) 세 모듈로 구성된 프레임워크이다. 각 모듈은 독립적으로 동작하면서도, 전체 파이프라인에서는 상호 보완적으로 연결되어 multi-hop QA의 정확성과 효율을 동시에 달성한다.

## Question Decomposition Module (QDM)
- **입력**: Original question $$Q_{ori}$$
- **출력**: 세분화된 subquestion 집합 $$Q_{sub} =\{ q_1, \cdots, q_n \}$$

QDM은 복잡한 multi-hop 질문을 여러 개의 단순하고 세분화된 subquestion으로 분해하는 모듈이다. 이를 통해 retrieval이 보다 fine-grained 수준에서 수행될 수 있으며, reasoning 과정 또한 단계적으로 구조화된다. QDM은 생성 모델 $$M_{QDM}$$을 사용해 입력 질문 $$Q_{ori}$$로부터 subquestion 집합 $$Q_{sub}$$을  만들어낸다. 

<center>$$\max_{M_{QDM}} \log P(Q_{sub} \mid Q_{ori}; M_{QDM})$$</center>

학습은 최대우도(maximum likelihood) lossㄹ르 사용한다. 특히 QDM은 단순한 분해에 그치지 않고, <span style="color:gold">**의존성을 가진 subquestion에 대해 마커 #number#**</span>를 부여한다. 이 마커는 이후 SDOM 단계에서 어떤 subquestion이 선행 질문의 답변을 필요로 하는지 식별하는 기준이 된다. 따라서 QDM은 dependency-aware decomposition을 수행한다는 점에서 기존 단순 decomposition 방식보다 한층 정교하다.

## Subquestion Dependency Optimizer Module (SDOM)
- **입력**: 불완전한 의존성 subquestion $$q_i$$, 선행 subquestion $$q_j$$, passage $$p_{q_j}$$
- **출력**: 재구성된 완전한 subquestion $$q_i^{'}$$

<center>$$\max_{M_{SDOM}} \log P(q_i^{'} \mid q_j, p_{q_j}, q_i; M_{SDOM})$$</center>

SDOM의 training objective는 위와 같다. 즉, 선행 subquestion과 그와 관련된 문서(=passage), 그리고 불완전한 subquestion을 바탕으로 맥락적으로 완전한 질문을 생성한다. Figure 2에서 예시처럼, “Who is the child of the director from #1#?”는 $$q_i$$ 의 답이 “Anjan Choudhury”일 때, SDOM이 이를 반영해 “Who is the child of Anjan Choudhury?”로 재구성한다.

## Dynamic Passage Retrieval Moduel (DPRM)
DPRM은 질문–passage 간 semantic mismatching 문제를 해결하기 위해, subquestion을 embedding 후 k-means로 클러스터링하여 각 cluster $$C_i$$별 전용 LoRA 블록 $$M_{DPRM}^{C_i}$$을 학습한다.

<center>$$\max_{M_{DPRM}^{C_i}} \mathbb{E}_{(q, p) \in C_i} \log \Big( \frac{E_q \cdot E_p}{\vert \vert E_q \vert \vert \vert \vert E_p \vert \vert} \Big)$$</center>

Training objective는 위와 같다. 여기서 $$E_p, E_q$$는 $$M_{DPRM}^{C_i}$$의 마지막 레이어의 hidden state에서 추출한 임베딩이다.  

<center>$$p_{q_i^*} = \arg\max_{p_v \in P} f(E_{q_i^*}, E_{p_v})$$</center>

추론시에는 각 subquestion $$q_i^{*}$$에 대응되는 클러스터에 매핑하고, 후보 passage 집합 $$P = \{ p_1, \cdots, p_m \}$$에서 cosine similarity 기반으로 최적 passage를 선택한다. 

<center>$$A_{\text{ori}} = \arg\max_{A_{\text{ori}}} P\big(A_{\text{ori}} \mid Q_{\text{ori}}, Q'_{\text{sub}}, P_{Q'_{\text{sub}}}; M \big)$$</center>

마지막으로, 모든 의존성이 보정된 $$Q_{sub}^{'}$$와 그에 대응하는 passage 집합 $$P_{Q_{sub}^{'}}$$를 answer generation 모델 $$M$$에 입력하여 최종 답변을 생성한다.

## Inference Pseudo Code
<p align="center">
<img width="500" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.19%5DQ-dream/q_dream_figure3.png?raw=true">
</p>

<br/>
<br/>

# Experiments
## Main Results
<p align="center">
<img width="800" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.19%5DQ-dream/q_dream_figure4.png?raw=true">
</p>

논문은 **In-domain (2WikiMQA)**와 **Out-of-domain (HotpotQA, IIRC)** 실험을 통해 Q-DREAM의 성능을 평가하였다.
- **In-domain (2WikiMQA)**:
    - Q-DREAM(ChatGPT)의 성능은 EM/F1 = **48.6 / 62.1**로, 기존 IRCoT(36.6/51.4), SURE(32.7/46.5) 등 주요 baseline을 크게 능가하였다.
    - 특히 **F1 기준으로 IRCoT 대비 +10.7**의 향상을 달성하였다. 이는 DPRM과 SDOM이 함께 작동해 retrieval 품질을 크게 개선한 결과이다.
- **Out-of-domain (HotpotQA, IIRC)**:
    - HotpotQA에서 Q-DREAM(ChatGPT)는 F1 **+17.5** 향상(SURE 대비)을 기록하였고, IIRC 데이터셋에서도 기존 방법보다 높은 정확도를 보였다.
    - 이는 Q-DREAM이 단순히 훈련 도메인에서만 강한 것이 아니라, **일반화 능력**을 보유함을 입증한다.
- **소규모 모델 기반 결과**:
    - Llama2-7B와 같은 소규모 모델에서도 Q-DREAM은 InstructRAG, ChatQA2보다 우수한 성능을 기록하였다.
    - 즉, Q-DREAM은 특정 대형 모델(ChatGPT)에 한정된 방법론이 아니라 **모델 불가지론적(Model-agnostic)** 프레임워크임을 실험적으로 보여준다.
 
## Ablation Study
<p align="center">
<img width="300" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.19%5DQ-dream/q_dream_figure5.png?raw=true">
</p>

- **DPRM 제거**: 성능이 EM/F1 **48.6/62.1 → 42.3/56.5**로 급감하였다. semantic mismatching 문제 해결에 DPRM이 핵심적 역할을 한다는 것을 보여준다.
- **SDOM + DPRM 동시 제거**: 성능이 EM/F1 **48.6/62.1 → 27.3/38.1**로 가장 크게 감소하였다. 이는 두 모듈이 상호 보완적으로 작동하며 전체 성능을 좌우한다는 점을 입증한다.
- **QDM 제거**: Q-DREAM의 구조상 불가능하므로, 실험에서는 수행되지 않았다. 대신 QDM은 baseline들과 비교해 항상 필수적 모듈로 간주되었다.

결과적으로, -DPRM에서 - (SDOM, DPRM)으로 실험을 바꿀때 성능 감소가 가장 심하므로, <span style="color:gold">**SDOM의 성능 gain이 가장 크다**</span>.

## Inference Efficiency
<p align="center">
<img width="800" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.19%5DQ-dream/q_dream_figure6.png?raw=true">
</p>

- IRCoT는 평균 **25.6초**가 걸리지만, Q-DREAM은 **4.2초**로 약 **6배 빠른 추론**을 달성하였다.
- 이는 Q-DREAM이 retrieval과 reasoning을 반복적으로 상호작용시키지 않고, **모듈화된 일회성 파이프라인**으로 수행되기 때문이다.
- 성능과 효율성을 동시에 달성했음을 보여주며, 실시간 QA 응용에서의 실용 가능성을 입증한다.

<br/>
<br/>

# Conclusion
**Contribution**  
- In-domain과 Out-of-domain 벤치마크에서 SOTA 성능을 달성했으며, IRCoT 대비 **약 6배 빠른 추론 효율성**을 입증하였다.
- ChatGPT와 Llama2-7B 등 다양한 LLM 백본에서 일관되게 효과를 보이며, 모델에 종속되지 않는 보편적 방법론임을 실험적으로 확인하였다 (Model agnostic).

**Limitations**  
- Multi-hop QA를 중심으로 실험을 진행했기 때문에, 다른 복잡한 reasoning 태스크에 대한 일반화 가능성은 추가적인 검증이 필요하다.
- 제안된 프레임워크는 semantic mismatching과 subquestion dependency 문제는 효과적으로 해결했지만, 여전히 **long-tail knowledge retrieval** 문제는 완전히 해결하지 못했다.
