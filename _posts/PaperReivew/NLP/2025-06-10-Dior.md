---
title: "[논문리뷰]DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation(ACL, 2025)"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2025-06-10
last_modified_at: 2025-06-10
---

*Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, and Jiajie Xu*. “[**DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation**](https://arxiv.org/pdf/2504.10198).” In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics, ACL 2025.

# Problem Statment
<p align="center">
<img width="400" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.06.10%5DDioR/dior1.png?raw=true">
</p>

이 논문은 기존 Dynamic RAG 기법들이 가진 두 가지 주요 한계점을 문제로 삼는다.

- 첫째, **적절한 시점에 retrieval을 실행하는 효과적인 메커니즘 부재**: 기존 방법들은 generation token의 확률 임계치 기반 등 static한 규칙에 의존하여, hallucination이 이미 발생한 후에야 retrieval을 시작하는 문제를 갖는다.
- 둘째, **retrieval된 문서의 품질과 관련성에 대한 충분한 검증 및 최적화 부재**: 한 번에 대량의 문서를 검색하고, 문서 길이와 중복성 문제를 제대로 다루지 못해 LLM의 이해와 추론에 악영향을 미친다.

<br/>
<br/>

# Methodology
## Overview
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.06.10%5DDioR/dior2.png?raw=true">
</p>

DioR는 동적 Retrieval-Augmented Generation(RAG)에서 발생하는 두 가지 핵심 한계, 즉 retrieval 시점 판단의 부정확성과 retrieved 문서의 품질 저하를 해결하기 위해 설계된 프레임워크이다. 모델은 두 개의 주요 모듈로 구성된다. 첫째, Adaptive Cognitive Detection 모듈은 LLM의 응답 자신감(confidence)을 바탕으로 retrieval 시점(timing)을 제어하는 역할을 하며, 사전(Early Detection)과 실시간(Real-time Detection) 분류기로 구성되어 hallucination 발생 가능성을 사전에 예측하거나 생성 중에 감지한다. 둘째, Contextual Retrieval Optimization 모듈은 retrieval 키워드 선정과 문서 선별 과정을 정교화하는 기능을 수행하며, 중요도 기반 키워드 선정(pre-retrieval)과 문서 내용 기반 재검색(post-retrieval)을 통해 정보 밀도와 문서 관련성을 극대화한다. 이 두 모듈은 결합되어 LLM이 보다 정확하고 맥락에 부합하는 응답을 생성하도록 유도하며, 특히 다중 문서 reasoning 및 사실 기반 응답 생성 과제에서 우수한 성능을 달성한다.

## Adaptive Cognitive Detection (적응형 인지 감지)
**Adaptive Cognitive Detection**은 DioR 모델에서 LLM이 언제 외부 지식을 검색해야 할지를 정교하게 판단하는 모듈로, 두 가지 탐지기인 Early Detection과 Real-time Detection으로 구성된다. 이 두 탐지기는 각각 **사전 예측(pre-generation)**과 **실시간 감지(during generation)**라는 상이한 시간 축에서 hallucination 가능성을 평가한다.

### (1) Early Detection
- **입력**: 질문 Q
- **출력**: LLM이 해당 질문에 대해 스스로 답할 수 있는지 여부 (Confident vs. Non-confident)
- **방법**: LLaMA2-7B로 Q에 대한 응답 A 생성 → 정답 R과 비교하여 hallucination 여부 레이블 → IG(Integrated Gradients) Entropy 추출 → RNN 기반 분류기 학습

Early Detection은 LLM이 실제로 텍스트를 생성하기 전에, 질문에 대해 **스스로 정답을 생성할 수 있는지의 여부를 판단**한다. 이를 위해 위키피디아 기반 QA 데이터셋을 구축하고, 각 질문에 대해 LLaMA2-7B 모델이 생성한 답변과 정답 간의 포함 관계(R ⊆ A)를 기준으로 hallucination 여부를 레이블링한다. 그런 다음, **질문에 대한 Integrated Gradients 기반의 Attribution Entropy를 추출하여 모델이 어떤 단어에 집중하고 있는지를 수치화**하고, 이를 입력으로 RNN 기반 분류기를 학습하여 사전 판단이 가능하도록 한다. 이 탐지기를 통해 모델이 낮은 자신감을 가질 것으로 예상되는 입력에 대해 텍스트 생성을 시작하기 전에 retrieval을 트리거할 수 있다.

### (2) Real-time Detection
- **입력**: 생성된 텍스트의 토큰
- **출력**: 특정 token이 hallucination인지 여부
- **방법**: 문장에서 entity를 추출하고 원문과 생성문을 entity-level로 비교 (cosine similarity 기반) → MLP 기반 분류기 학습

Real-time Detection은 **LLM이 생성한 텍스트를 분석하면서, 각 토큰이 사실과 다른 정보를 포함하고 있는지를 실시간으로 판단**한다. 이를 위해, 위키피디아 문서에서 entity를 추출하고, 해당 문서를 잘라낸 후 LLaMA2-7B가 텍스트를 이어 쓰게 하여 새로운 문장을 생성한다. 생성된 문장에서 추출한 entity들과 원문 entity들 간의 cosine similarity를 비교하고, 의미적으로 유사하지 않다면 해당 토큰을 hallucination으로 간주한다. 이 과정으로 학습된 MLP 기반 분류기는 LLM이 출력 중인 토큰이 오류를 포함할 가능성이 있는지를 실시간으로 탐지하여, 해당 시점에서 retrieval을 트리거할 수 있게 한다.

요약하면, Early Detection은 generation 이전의 사전 판단, Real-time Detection은 generation 중의 동적 감지를 담당함으로써, DioR는 retrieval 시점을 미세하게 조절하고 불필요한 검색을 줄이며, hallucination을 사전 및 실시간 단계에서 모두 억제할 수 있도록 설계되어 있다.

<br/>

## Contextual Retrieval Optimization (문맥 기반 검색 최적화)
**Contextual Retrieval Optimization** 모듈은 DioR가 retrieval을 트리거한 이후, **무엇을 검색할지(what to retrieve)**에 대한 품질을 정교화하는 핵심 구성요소이다. 이 모듈은 Pre-Retrieval과 Post-Retrieval 두 단계로 구성되며, 각각 검색 키워드 선정과 문서 선택·가공의 역할을 수행한다.

### Pre-Retrieval
- **입력**: LLM의 전체 생성 텍스트
- **출력**: retrieval keyword 후보들의 우선순위
- **방법**:
  - Attention score, TF-IDF, 위치 점수, 쿼리와의 cosine similarity로 토큰별 중요도 계산
  - 중요도 높은 토큰을 BM25 등으로 검색

Pre-Retrieval은 **retrieval에 사용할 키워드를 보다 정밀하게 선정**하는 단계로, 기존 방식처럼 최근 생성된 문장의 attention만 사용하는 대신, DioR는 생성된 전체 텍스트에 대한 정량적 중요도 평가를 수행한다. 구체적으로, Early Detection과 Real-time Detection에서 추출된 후보 키워드(token)에 대해 다음 네 가지 기준을 조합하여 **중요도 점수 $$I_i$$**를 계산한다:

(1) Multi-head attention score $$A_i$$  
(2) TF-IDF 기반 정보량  
(3) 문장 내 위치 기반 점수 $$P_i = \frac{\text{Pos}(i)}{N}$$  
(4) 쿼리와의 cosine similarity $$S_i$$  

이렇게 얻은 중요도 점수를 기반으로 토큰을 정렬하여 상위 키워드를 선택하고, 이들을 BM25 등의 검색기로 보내어 외부 문서를 가져오게 된다. 이를 통해 검색 쿼리가 더욱 의미 중심적이고, 문맥에 부합한 정보만을 포함하게 된다.

### Post-Retrieval
- **입력**: Pre-retrieval로 얻은 candidate 문서
- **출력**: 최종 선택된 문서 블록
- **방법**:
  - 처음 top-k 중 절반을 선택 → 새롭게 등장한 개념을 바탕으로 쿼리를 확장 → 반복적으로 문서 재검색
  - 각 문서는 의미 단위로 잘게 나누어(문장 분할 및 재조합) LLM에 투입

Post-Retrieval은 초기 검색 이후 검색된 **문서를 어떻게 재정렬하고 가공할 것인지**를 다루는 단계이다. 기존 dynamic RAG는 문서를 한 번에 일괄적으로 검색하고 모두 LLM에 넣었지만, DioR는 이를 개선하여 **단계적 검색(stepwise retrieval)**을 수행한다. 먼저 상위 문서 중 일부(n/2)를 선택하고, 해당 문서에서 새로 등장한 개념이나 키워드를 추출하여 검색 쿼리를 확장하고, 남은 문서들에 대해 재검색을 반복한다. 이후 문서가 너무 길 경우에는 문장을 의미 단위로 나누고(sub-clause segmentation), 논리적으로 연결이 끊기지 않도록 재조합하여 블록화한다. 최종적으로 이 블록들을 LLM의 prompt에 삽입하여, hallucination이 발생한 지점부터 이어서 정확하고 풍부한 응답을 생성하도록 돕는다.

요약하면, Pre-Retrieval은 어떤 키워드로 검색할지 정밀하게 선정하고, Post-Retrieval은 어떤 문서를 어떤 방식으로 사용할지 다단계 최적화하여, DioR가 검색 품질을 극대화하고 LLM의 reasoning 성능을 향상시킬 수 있도록 설계된 구조이다.

<br/>
<br/>

# Experiments
## Main Result1
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.06.10%5DDioR/dior3.png?raw=true">
</p>

DioR는 4개의 대표적인 벤치마크 데이터셋(2WikiMultihopQA, HotpotQA, IIRC, StrategyQA)과 3가지 retrieval 방식(BM25, SGPT, SBERT)을 기반으로 평가되었다. Table 1에서는 기존 방법(Dragin)을 Base로 설정하여 DioR와의 성능 차이를 분석하였고, Table 2에서는 DioR를 다양한 기존 RAG 기법들과 직접 비교하였다.

2WikiMultihopQA에서는 **BM25 기반 EM이 0.214(Base)에서 0.254(DioR)**로 상승하며, F1 점수 역시 0.282에서 0.335로 개선되었다. SGPT와 SBERT 기반에서도 EM 및 F1 점수에서 DioR는 일관된 향상을 보였다. HotpotQA에서도 DioR는 BM25 기준 EM 0.274, F1 0.379로, 각각 Base 대비 0.055, 0.065의 상승을 보였으며, 특히 SBERT 기반 Precision은 0.068의 최대 증가폭을 기록하였다.

IIRC에서는 상대적으로 낮은 baseline 성능에도 불구하고 EM 0.201, F1 0.245로 의미 있는 성능 향상이 있었고, StrategyQA에서는 Base 대비 모든 retrieval 방법에서 Precision과 Recall이 동일하거나 소폭 향상되었다.

## Main Result2
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.06.10%5DDioR/dior4.png?raw=true">
</p>

Table 2에 따르면 DioR는 기존의 대표적인 dynamic RAG 방법들인 SEAKR, RaDIO, Dragin, FLARE 등과 비교하여 모든 데이터셋에서 EM, F1 기준 최고 성능을 기록하였다. 예를 들어, HotpotQA에서 DioR는 EM 0.274, F1 0.379로, RaDIO(EM 0.246, F1 0.351) 및 SEAKR(EM 0.261, F1 0.365)보다 모두 우위였다. 2WikiMultihopQA에서도 EM 0.266, F1 0.335로 SEAKR과 RaDIO를 초과하였다.

이러한 결과는 DioR가 제안한 **retrieval 시점 제어(Adaptive Cognitive Detection)**와 **문서 품질 최적화(Contextual Retrieval Optimization)**가 실제 성능 향상으로 이어졌음을 입증하며, 특히 multi-hop reasoning, long-context QA와 같은 복잡한 질의응답 상황에서 기존 동적 RAG보다 훨씬 더 견고하고 정밀한 응답을 생성함을 시사한다.

## Ablation Study
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.06.10%5DDioR/dior5.png?raw=true">
</p>

Ablation Study는 DioR의 각 구성 요소가 성능에 어떤 기여를 하는지를 정량적으로 검증하기 위해 수행되었으며, Table 3에 결과가 요약되어 있다. 실험은 DioR의 핵심 모듈인 Early Detection (ED), Real-time Detection (RD), Pre-Retrieval (Pre-R), **Post-Retrieval (Post-R)**을 각각 제거한 설정에서 전체 성능 변화량을 분석하는 방식으로 이루어졌다. 이 분석을 통해 DioR의 성능 향상이 단일 요인에 의한 것이 아닌 모듈 간 상호작용과 기능적 분담의 결과임을 실증적으로 확인하였다.

**Real-time Detection 제거(w/o RD)**는 가장 큰 성능 저하를 유발하였다. 예를 들어, HotpotQA에서 F1 점수가 0.379(DioR) → 0.319, IIRC에서는 0.245 → 0.197로 급락하였다. 이는 실시간으로 hallucination을 탐지해 retrieval을 트리거하는 기능이 DioR의 핵심적 기여 요소임을 보여준다.

**Pre-Retrieval 제거(w/o Pre-R)**는 중요도 기반 keyword 선택 없이 단순히 등장 순서대로 검색을 수행하게 되는 실험으로, HotpotQA 기준 EM이 0.274 → 0.237, F1은 0.379 → 0.334로 감소하였다. 이는 문맥 기반 키워드 선정이 검색 정밀도를 높이는 데 기여함을 입증한다.

종합적으로, Ablation Study는 DioR의 각 모듈이 개별적으로도 성능에 긍정적인 영향을 미치며, 특히 Real-time Detection과 <span style="color:gold">**Pre-Retrieval 모듈이 가장 큰 성능 gain을 유도**</span>함을 실험적으로 확인하였다. 이를 통해 DioR의 설계가 성능 향상을 위한 필수 요소들의 조합이라는 점이 설득력 있게 입증된다.

<br/>
<br/>

# Conclusion
이 논문은 기존 동적 Retrieval-Augmented Generation(RAG) 방식이 가진 두 가지 근본적 한계, 즉 retrieval 시점에 대한 정교한 판단 부재와 retrieved 문서 품질 통제의 결여를 해결하기 위해 DioR(Adaptive Cognitive Detection and Contextual Retrieval Optimization)이라는 새로운 프레임워크를 제안하였다. DioR는 LLM의 생성 전후 단계에서 hallucination 발생 가능성을 탐지하는 Early Detection과 Real-time Detection 모듈을 통해 retrieval 시점을 정교하게 제어하며, Pre-Retrieval과 Post-Retrieval 전략을 통해 키워드 선정과 문서 가공의 정밀도를 극대화한다. 실험 결과, DioR는 2WikiMultihopQA, HotpotQA, IIRC, StrategyQA 등 다양한 지식 집약형 QA 데이터셋에서 기존 동적 RAG 기법들을 일관되게 초과하는 성능을 달성함으로써, 사실 기반 reasoning과 hallucination 완화에 효과적인 새로운 표준을 제시하였다.

그럼에도 불구하고 DioR는 여전히 몇 가지 한계를 지닌다. 특히, retrieval된 문서의 총 길이는 줄지 않았기 때문에, 문서 내 개별 정보를 잘게 쪼개고 블록화하더라도 전체 입력 길이가 길어져 LLM의 처리 효율성과 추론 능력에 부담을 줄 수 있다. 또한 수학 문제와 같이 복잡한 reasoning이 필요한 문제에서는 여전히 한 번의 직접적 추론으로는 한계가 있으며, 추후에는 문제를 여러 하위 단계로 분해하는 step-by-step 추론 전략을 통합하는 연구가 필요하다. 이러한 점은 DioR의 강점을 확장하기 위한 미래 연구 방향으로 제시된다.
