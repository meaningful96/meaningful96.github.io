---
title: "[논문리뷰]Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-07-10
last_modified_at: 2024-07-10
---
*Luo, L., Li, Y., Haffari, G., & Pan, S*. (2023, October 2). **Reasoning on graphs: Faithful and interpretable large language model reasoning**. arXiv.org. [https://arxiv.org/abs/2310.01061](https://arxiv.org/abs/2310.01061)

# Problem Statement

<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/04713ed4-f450-4821-89ef-4baffa4bdd55">
</p>

<span style="font-size:110%">**최신 지식의 부족과 환각 문제 (Lack of Up-to-Date Knowledge and Hallucinations)**</span>  
LLM은 복잡한 작업에서 인상적인 추론 능력을 보여주지만, 최신 지식이 부족하고 추론 중에 환각을 경험할 수 있다. 이는 잘못된 추론 과정으로 이어져 성능과 신뢰성을 떨어뜨릴 수 있다.​

<span style="font-size:110%">**구조적 정보의 중요성 간과 (Overlooking the Importance of Structural Information)**</span>  
기존의 KG 기반 LLM 추론 방법은 KG를 사실적 지식 기반으로만 취급하고, 추론을 위한 구조적 정보의 중요성을 간과한다. 이는 KG의 관계 경로가 제공하는 의미론적 연결을 충분히 활용하지 못하게 한다.​

<span style="font-size:110%">**비실행 가능성 문제 (Non-Executable Queries)**</span>  
Semantic Parsing 방법은 논리적 쿼리를 생성하여 KG에서 답변을 얻지만, 생성된 논리적 쿼리가 실행 불가능한 경우가 많아 답변을 얻지 못할 수 있다. 이는 구문 및 의미적 제한 때문에 발생할 수 있다.​

<span style="font-size:110%">**구조적 정보의 부족으로 인한 문제 (Issues Due to Lack of Structural Information)**</span>  
Retrieval-augmented 방법은 KG에서 사실을 검색하여 LLM의 추론 성능을 향상시키지만, 이러한 방법들은 KG를 사실적 지식 기반으로만 취급하고, 추론을 위한 KG의 구조적 정보를 간과한다. 예를 들어, 관계 경로가 중요한 의미론적 연결을 제공할 수 있음에도 불구하고 이를 충분히 활용하지 못한다​.

<br/>
<br/>

# Related Work

<span style="font-size:110%">**LLM Reasoning Prompt**</span>  
- 이 연구는 prompt engineering으로 불리며, **LLM의 fine-tuning 없이 주어진 프롬프트를 통해 모델이 복잡한 추론 작업을 수행하도록 하는 것**이다. 주로 LLM에게 계획을 생성하게 하거나, 추론 단계를 세분화하도록 하여, 일련의 하위 작업으로 나누어 해결하는 방식이다. 이를 통해 최신 지식을 반영하고, 신뢰할 수 있는 추론을 수행할 수 있다. 예를 들어, Chain-of-Thought (CoT), Tree of Thoughts (ToT), Plan-and-Solve, ReACT등이 연구들이 있다.

<span style="font-size:110%">**Knowledge Graph Question Answering(KGQA)**</span>     
- **Embedding-based Methods**
  - 엔티티와 관계를 임베딩 공간에서 모델링하고 특별한 모델 구조를 설계하여 답변을 추론한다. 
  - KV-Mem, EmbedKGQA, NSM, QA-GNN, Greaselm.  

- **Retrieval-augmented Methods**
  - KG에서 관련 사실을 검색하여 추론 성능을 향상시킨다. 초기 연구들은 페이지 랭크(Page Rank)나 랜덤 워크(Random Walk) 알고리즘을 사용하여 서브그래프(subgraph)를 검색한다. 
  - GraftNet, PullNet, SR+NSM, UniKGQA.  

- **Semantic Parsing Methods**
  - 질문을 구조적 쿼리(e.g., SPARQL)로 구문 분석하여 쿼리 엔진이 답변을 얻도록 합니다. 
  - SPARQL, ArcaneQA, RnG-KBQA, DECAF.


<br/>
<br/>

# Method
## Overview

<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/90f79376-433a-4463-836d-187f2af66b56">
</p>

Resoning on Graphs(RoG)는 KG에 근거해 추론 계획은 세우고, LLM을 통해 신뢰할 수 있는 reasoning path를 검색하고 정답을 추론하는 ***planning-retrieval-reasoning*** 프레임워크를 제안한다. RoG는 크게 1)Planning, 2)Retreival-reasoning 두 개의 모듈로 구성된다. 

- **Planning** 모듈
  - 주어진 질문 $$q$$에 대해 신뢰할 수 있는 <span style="color:gold">**관계 경로(relation path)**</span> $$z$$를 생성
 
- **Retreival-reasoning** 모듈
  - Planning 모듈에서 생성된 관계 경로 $$z$$를 사용하여 KG에서 유효한 <span style="color:gold">**추론 경로(reasoning path)**</span> $$w_z$$를 검색하고, 이를 기반으로 답변 $$a$$를 생성

얘를 들어, 입력으로 들어온 질문이 "Who is the child of Alice?"라고 해보자. 이 때, 

## Module 1. Planning Module
**Planning Module**은 말 그대로 추론을 위해 계획을 수립하는 부분이다. 이 몯모듚듈의 핵심은, 주어진 입력에 대해 정답을 찾기 위한 추론 경로를 찾기 전, 일차적으로 **적합한 관계 경로를 찾아내는 것**이다. 처음부터 추론 경로를 찾지 않는 이유는 여러가지가 있다. 첫번째로 정답에 대한 추론 경로는 엔티티의 정보를 포함하기 때문에, 가능한 모든 경로에 대한 임베딩을 계산하는 것은 컴퓨팅 자원을 많이 소모할 수 있다. 또한, 정보가 많아지는 만큼 불필요한 정보도 많아져 노이즈가 발생할 수 있기 때문이다. 이러한 이유로 많은 선행 연구들도 추론 경로를 추출하기 전에 관계 경로를 먼저 찾아낸다.

- **Notations**
  - **Knowledge Graph**: $$\{(e, r, e^{'} \vert e, e^{'} \in \mathcal{E}, r \in \mathcal{R})\}$$
  - **Relation Path(관계 경로)**: $$z = \{r_1, r_2, \cdots, r_l\}$$ ($$r_i$$는 path에서 i번째 relation)
  - **Reasoning Path(추론 경로)**: $$w_z = e_0 \xrightarrow{r_1} e_1 \xrightarrow{r_2} \cdots \xrightarrow{r_l} e_l$$ 

예를 들어, (Alice, marry\_to, Bob), (Bob, father\_of, Charlie) 두 개의 트리플로 이루어진 관계 경로 $$z$$와 추론 경로 $$w_z$$를 다음과 같이 정의할 수 있다.
- 관계 경로: $$z = \text{marry_to} \rightarrow \text{father_of}$$
- 추론 경로: $$w_z = \text{Alice} \xrightarrow{\text{marry_to}} Bob \xrightarrow{\text{father_of}} Charlie$$

RoG는 관계 경로와 추론 경로를 통해 최적화하고자 하는 수식은 다음과 같다. 질문과 KG과 주어졌을때, 정답에 대한 확률을 계산하는 것이며, 정답 엔티티의 확률값이 최대화되도록 하는 것이다.

<p align="center">
<img width="350" alt="1" src="https://github.com/user-attachments/assets/23b99c54-ce2b-4c7a-90dc-83bc00b4d543">
</p>

결론적으로, RoG은 이 확률값을 계산하기 위해 Planning 모듈과 Retrieval-reasoning 모듈에서 각각 따로 계산된 확률을 이용하므로 두 개의 최적화 프레임워크를 가지게 된다. 위의 식은 evidence lower bound(ELBO)를 최대화하는 것으로 식을 변형할 수 있다. ([ELBO](https://en.wikipedia.org/wiki/Evidence_lower_bound))

<p align="center">
<img width="350" alt="1" src="https://github.com/user-attachments/assets/a19eca20-c69f-478d-8858-b528dced440c">
</p>

<br/>
<br/>

# Experiments



<br/>
<br/>

# Limitations and Contributions
