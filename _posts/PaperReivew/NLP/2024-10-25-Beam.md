---
title: "[논문리뷰]End-to-End Beam Retrieval for Multi-Hop Question Answering"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-10-25
last_modified_at: 2024-10-25
---

*Jiahao Zhang, Haiyang Zhang, Dongmei Zhang, Yong Liu, and Shen Huang*. 2024. [End-to-end beam retrieval for multi-hop question answering](https://arxiv.org/abs/2308.08973)

# Problem Statement

</figure>
<p align="center">
<img width="500" alt="1" src="https://github.com/user-attachments/assets/a24e803a-8d9d-4db8-ba58-e4f03862d0d4">
</p>
<center>*Documents들 사이에서 Multi-hop Reasoning을 하는 과정*</center>

**선행 연구들에서 Retriever들이 대부분 2-hop 질문에 초점을 맞췄다**.   
  - 기존의 리트리버는 질문의 복잡도가 비교적 낮은 2-hop 질문에 최적화되어 설계되었고, 그 이상의 복잡한 시나리오에 대해서는 적절한 성능을 내지 못하였다.
  
**멀티-홉 검색 과정에 대한 전반적인 감독(supervision)이 부족하다**.    
  - 기존 연구들은 멀티-홉 질문에 대해 각 홉에 대한 감독을 따로 적용하는 경우가 많아, 전체적인 검색 과정을 하나로 통합하여 감독하지 못하였다. 이로 인해 복잡한 멀티-홉 시나리오에서 성능이 저하되었다.

**첫 번째 홉에서 잘못된 경로를 선택하면, 이후 모든 검색 과정이 실패할 수 있다**.   
  - 기존의 검색 방법들은 첫 번째 단계에서 잘못된 경로가 선택되면, 이후 단계에서 이를 교정하거나 보완할 방법이 없어 전체 검색 프로세스가 실패할 위험이 높았다.

**복잡한 멀티-홉 질문에 적응하기 어렵다**.    
  - 특히 2-hop을 넘어서는 복잡한 시나리오에서는 기존 방법들이 충분히 유연하게 대응하지 못하여, 복잡한 질문에 대한 정확도가 떨어졌다.

# Method
## Model Overview
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/115a1f17-2d04-450b-b4f5-3b50063c6aae">
</p>

Beam Retrieval 모델은 멀티-홉 질의 응답(Multi-hop QA)을 풀기 위한 End-to-End 방식의 Beam search 검색 프레임워크이다. 위의 그림은 Beam Retrieval 모델 아키텍쳐를 보여준다. Beam Retrieval는 크게 **검색(Retrieve)**과 **추론(Inference)** 두 단계로 이루어져있다.

## 검색(Retrieve)
검색 모듈은 문서를 임베딩하기 위한 **인코더**와 다음 문서를 결정하기 위한 **Classification Head**로 구성된다.

<span style="font-size:110%">**Step 1) 1-hop 문서 선택**</span>  
멀티-홉 추론은 주어진 질문 $$Q$$에 대해 후보 패세지(=경로) 집합 $$D=\{p_1, p_2, \dots, p_n \}$$이 주어졌을때, $$k$$개의 홉을 통해 관련성 있는 패세지 체인 $$\hat{p_1}, \hat{p_2}, \dots, \hat{p_n}$$을 찾아내는 것이다. 검색을 위한 첫 번째 단계에서는, 첫 번째 문서를 선택해야한다. 먼저 질문 $$Q$$와 각 패세지 $$p_i \in D$$를 `DeBERTa-v3-large` 입력시킨다. 

**\[1-hop Search\]**  
**첫 번째 홉**에서는 질문 $$Q$$와 후보 패세지 $$p_i$$를 결합한다. 즉, 하나의 질문과 모든 패세지들과의 쌍(pair)을 각각 모델에 입력시켜 임베딩한다. 만약 질문 $$Q$$에 대해 10개의 Document가 있으면, 총 10개의 쌍을 임베딩하는 것이다. 이를 수식으로 나타내면 다음과 같다.

<center>$$[\text{CLS}] + Q + p_i + [\text{SEP}]$$</center>

인코더는 $$[\text{CLS}] + Q + p_i + [\text{SEP}]$$를 입력받아 $$(Q, p_i)$$의 임베딩 $$H^i = [ h_1^i, h_2^i, \dots, h_{L_i}^i ]$$ 형태의 임베딩 벡터를 생성한다. $$L_i$$는 질문과 패세지를 합친 시퀀스의 전체 길이를 나타내며, 다시 말해, 질문과 패세지들의 토큰 수를 의미한다.

이후 질문-패세지에 대한 임베딩은 **Classification Head**에 입력된다. 1-hop 패세지를 결정하는 classifier의 목적은 패세지가 "관련 있음", "관련 없음"과 같이 관련 유무의 정도를 분류하기 위함이다. 이 **classifier1**를 통해 각 후보 <span style="color:gold">**패세지에 대해 관셩성을 나타내는 점수**</span>가 계산되며 해당 스코어는 $$[\text{CLS}]$$ 토큰의 임베딩을 입력받는다. Beam search를 하므로, 스코어에 기반해 top-B개의 문서를 선택하게 된다.

**\[n-hop searrch\]**  
두 번째 홉부터는 이전에 선택된 패세지들과 새로운 후보 패세지를 결합하여 시퀀스를 생성한다. 예를 들어, $$t$$번째 홉에서는 질문 $$Q$$, 이전에 선택된 패세지들 $$\hat{p_1}, \hat{p_2}, \dots,\hat{p_{t-1}}$$, 그리고 새로운 후보 패세지 $$z_t$$를 결합하여 다음과 같은 입력 시퀀스를 구성한다.

<center>$$[\text{CLS}] + Q + \hat{p_1} + \cdots + \hat{p_{t-1}} + z_t + [\text{SEP}]$$</center>

이 결합된 시퀀스는 인코더를 다시 호출하여 임베딩 $$H^t = [ h_1^t, h_2^t, \dots, h_{L_i}^t ]$$을 생성한다. 이후 이전과 동일하게 claissification head를 통해서 관련성의 유무를 스코어로 계산하는데, 1-hop에서 사용된 분류기와는 다른 분류기, **classifier2**를 사용한다. 마찬가지로 Beam search를 진행하기 때문에 top-B개의 패세지를 선택한다.

## 추론(Inference)
Beam Search는 각 홉마다 관련성이 높은 패세지들을 선택하며, 마지막 홉에서는 $$B$$개의 패세지 체인(**최종 가설**)을 유지한다. 예를 들어, 최종적으로 선택된 $$B$$개의 멀티-홉 패세지들은 다음과 같이 표현된다.

<center>$$(p̂^1_1, p̂^2_1, ..., p̂^k_1), (p̂^1_2, p̂^2_2, ..., p̂^k_2), ..., (p̂^1_B, p̂^2_B, ..., p̂^k_B)$$</center>

여기서 각각의 가설은 여러 홉에 걸친 패세지들이 결합된 추론 경로이다. 추론은 크게 두 가지 방법으로 진행된다. 1)Supervised Reader와 2)LLM을 통해 추론을 진행한다. 이 때, 이미 데이터셋에 존재하는 **Supporting fact**를 입력받는 Supervised setting과 입력받지 않는 Unsupervised setting 방식으로 추론을 진행하게 된다.

### 1) Supervised Reader
Supervised Reader는 선택된 패세지들을 하나로 결합하여 질문에 대한 답을 추출하는 역할을 한다. 이때, Reader는 질문 $$Q$$와 선택된 가설을 입력으로 받아 패세지들의 전체적인 문맥을 통해 정답을 추출한다. Supervised Reader로는 **BERT**, **DeBERT**, **FE2H** 등의 모델이 사용되었다. 

### 2) LLM
LLM은 **gpt-3.5-turbo-16k**와 **longchat-13b-16k**을 사용하였으며, few-shot으로 정답을 추론하게 하였다.

# Experiments
## Retrieval Performance
<p align="center">
<img width="400" alt="1" src="https://github.com/user-attachments/assets/6ee6ec4f-1602-423f-87e6-cb564ed38dcb">
</p>

다른 Mulit-hop Retrieval 모델들과 비교했을 때 SOTA를 달성하였다.

## QA Performance
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/09a20de2-5f8b-4d1d-a7cd-76430e230dc6">
</p>

Supervised Setting에서는 다른 모델들과 비교했을 때 SOTA를 달성하였다. 

<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/69e767a0-d907-4abc-9f21-132d78d05ae1">
</p>

하지만, LLM을 사용한 방식이 오히려 일반적인 LM(`DeBERTa-v3-large`)를 사용한 결과보다 모든데이터셋에서 성능이 떨어졌다.

