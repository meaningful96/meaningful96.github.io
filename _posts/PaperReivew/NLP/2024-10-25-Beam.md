---
title: "[논문리뷰]End-to-End Beam Retrieval for Multi-Hop Question Answering"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-10-25
last_modified_at: 2024-10-25
---

*Jiahao Zhang, Haiyang Zhang, Dongmei Zhang, Yong Liu, and Shen Huang*. 2024. [End-to-end beam retrieval for multi-hop question answering](https://arxiv.org/abs/2308.08973)

# Problem Statement

</figure>
<p align="center">
<img width="500" alt="1" src="https://github.com/user-attachments/assets/9eb95d1f-13db-467a-82c0-64cfb7834bd1">
</p>
<center>*Documents들 사이에서 Multi-hop Reasoning을 하는 과정*</center>

**선행 연구들에서 Retriever들이 대부분 2-hop 질문에 초점을 맞췄다**.   
  - 기존의 리트리버는 질문의 복잡도가 비교적 낮은 2-hop 질문에 최적화되어 설계되었고, 그 이상의 복잡한 시나리오에 대해서는 적절한 성능을 내지 못하였다.
  
**멀티-홉 검색 과정에 대한 전반적인 감독(supervision)이 부족하다**.    
  - 기존 연구들은 멀티-홉 질문에 대해 각 홉에 대한 감독을 따로 적용하는 경우가 많아, 전체적인 검색 과정을 하나로 통합하여 감독하지 못하였다. 이로 인해 복잡한 멀티-홉 시나리오에서 성능이 저하되었다.

**첫 번째 홉에서 잘못된 경로를 선택하면, 이후 모든 검색 과정이 실패할 수 있다**.   
  - 기존의 검색 방법들은 첫 번째 단계에서 잘못된 경로가 선택되면, 이후 단계에서 이를 교정하거나 보완할 방법이 없어 전체 검색 프로세스가 실패할 위험이 높았다.

**복잡한 멀티-홉 질문에 적응하기 어렵다**.    
  - 특히 2-hop을 넘어서는 복잡한 시나리오에서는 기존 방법들이 충분히 유연하게 대응하지 못하여, 복잡한 질문에 대한 정확도가 떨어졌다.

# Method
## Model Overview
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/4d1b7bfb-b8d0-4ebc-a6fd-ef5ef99d8007">
</p>

Beam Retrieval 모델은 멀티-홉 질의 응답(Multi-hop QA)을 풀기 위한 End-to-End 방식의 Beam search 검색 프레임워크이다. 위의 그림은 Beam Retrieval 모델 아키텍쳐를 보여준다. Beam Retrieval는 크게 **검색(Retrieve)**과 **추론(Inference)** 두 단계로 이루어져있다.

## 검색(Retrieve)
검색 모듈은 문서를 임베딩하기 위한 **인코더**와 다음 문서를 결정하기 위한 **Classification Head**로 구성된다.

<span style="font-size:110%">**Step 1) 1-hop 문서 선택**</span>  
멀티-홉 추론은 주어진 질문 $$Q$$에 대해 후보 패세지(=경로) 집합 $$D=\{p_1, p_2, \dots, p_n \}$$이 주어졌을때, $$k$$개의 홉을 통해 관련성 있는 패세지 체인 $$\hat{p_1}, \hat{p_2}, \dots, \hat{p_n}$$을 찾아내는 것이다. 검색을 위한 첫 번째 단계에서는, 첫 번째 문서를 선택해야한다. 먼저 질문 $$Q$$와 각 패세지 $$p_i \in D$$를 `DeBERTa-v3-large` 입력시킨다. 

**\[1-hop Search\]**  
**첫 번째 홉**에서는 질문 $$Q$$와 후보 패세지 $$p_i$$를 결합한다. 즉, 하나의 질문과 모든 패세지들과의 쌍(pair)을 각각 모델에 입력시켜 임베딩한다. 만약 질문 $$Q$$에 대해 10개의 Document가 있으면, 총 10개의 쌍을 임베딩하는 것이다. 이를 수식으로 나타내면 다음과 같다.

<center>$$[\text{CLS}] + Q + p_i + [\text{SEP}]$$</center>

인코더는 $$\[\text{CLS}\] + Q + p_i + \[\text{SEP}\]$$를 입력받아 $$(Q, p_i)$$의 임베딩 $$H = [ h_1^i, h_2^i, \dots, h_{L_i}^i ]$$ 형태의 임베딩 벡터를 생성한다. $$L_i$$는 질문과 패세지를 합친 시퀀스의 전체 길이를 나타내며, 다시 말해, 질문과 패세지들의 토큰 수를 의미한다.

이후 질문-패세지에 대한 임베딩은 **Classification Head**에 입력된다. 1-hop 패세지를 결정하는 classifier의 목적은 패세지가 "관련 있음", "관련 없음"과 같이 관련 유무의 정도를 분류하기 위함이다. 이 classifier를 통해 각 후보 <span style="color:red">**패세지에 대해 관셩성을 나타내는 점수**</span>가 계산되며 해당 점수는 $$[\text{CLS}]$$


# Experiments

# Contribution
