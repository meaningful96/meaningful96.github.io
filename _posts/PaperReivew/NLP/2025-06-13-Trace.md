---
title: "[논문리뷰]TRACE: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2025-06-13
last_modified_at: 2025-06-13
---

*Jinyuan Fang, Zaiqiao Meng, and Craig MacDonald*. “[**TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation**](https://aclanthology.org/2024.findings-emnlp.496/).” In Findings of the Association for Computational Linguistics: EMNLP 2024, pages 8472–8494, Miami, Florida, USA.

# Problem Statement
<p align="center">
<img width="600" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.06.13%5DTRACE/Trace1.png?raw=true">
</p>

이 논문은 다중 문서에서 정보를 통합해 복잡한 질문에 답해야 하는 **multi-hop question answering(MHQA)** 문제를 해결함에 있어, 기존 RAG 모델들이 다음과 같은 한계점을 지적한다.
- **irrelevant한 문서를 검색**하여 노이즈를 유입시키고, 이로 인해 추론 성능이 저하됨.
- 특히 단순히 retriever가 가져온 문서를 LLM에 연결(concatenation)하는 기존 방식은, **다중 홉 추론에 필요한 근거(evidence)**를 효과적으로 구성하지 못함.

이를 해결하기 위해 저자들은 **문서들을 Knowledge Graph(KG)로 변환**하고, 이 KG로부터 **논리적으로 연결된 추론 체인(Reasoning Chain)을 구성**하여, 보다 정제된 supporting evidence를 RAG 모델에 제공하는 방법인 **TRACE**를 제안한다.

<br/>
<br/>

# Methodology
## Overview
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.06.13%5DTRACE/Trace2.png?raw=true">
</p>

TRACE는 multi-hop 질문에 대한 정답을 생성하기 위해, 검색된 문서로부터 Knowledge Graph(KG)를 생성하고, 이 KG로부터 논리적으로 연결된 reasoning chain을 autoregressive하게 구성하며, 최종적으로 이 reasoning chain을 기반으로 정답을 생성하는 RAG 프레임워크이다. 전체 확률 모델은 다음과 같이 정의된다:

- $$q$$: 질문
- $$D_q$$: 질문에 대해 검색된 문서 집합
- $$G_q$$: $$D_q$$로부터 생성된 KG
- $$z$$: KG에서 생성된 추론 체인
- $$a$$: 생성된 정답

## KG Generator
- **입력**: 검색된 문서들 (by Original Question, $$D_q$$)
- **출력**: Knowledge Graph
    - Head: 문서의 title
    - Tail: Body (text에서 추출된 entity나 문장)

KG Generator는 검색된 문서 집합 $$D_q$$를 입력으로 받아, 각 문서에서 ⟨head, relation, tail⟩ 형태의 knowledge triple을 추출함으로써 KG $$G_q$$를 생성한다. 이때, 각 문서의 **title을 head entity로 간주**하고, **본문에서 출현하는 tail entity들과의 관계를 추출하여 triple을 구성**한다. KG 생성은 LLM 기반 in-context prompting으로 수행되며, KG generator는 다음 확률식을 따르는 모듈이다:

$$p(G_q \vert D_q)$$

TRACE는 **lost-in-the-middle** 문제를 방지하기 위해, <span style="color:red">**모든 문서 $$d_i \in D_q$$에 대해 triple을 독립적으로 생성**</span>하고, 문서 간 triple 연결은 공통 entity를 통해 암묵적으로 연결한다. 즉, 긴 문서를 하나로 입력하는 방식 대신, 문서 단위로 triple을 추출하고 이를 합쳐 전체 KG를 구성한다:

$$G_q = \bigcup_{i=1}^{N} \text{KG Generator}(d_i)$$

문서가 Wikipedia 기반이기 때문에, title과 본문 간 관계를 추출하기 용이하며, 추출된 triple은 reasoning chain 구성의 후보로 사용된다. 이때의 prompt는 "title과 관련된 tail entity와 그 관계를 문장에서 추출하라"는 방식으로 구성된다.

## Reasoning Chain Constructor
Reasoning Chain Constructor는 KG $G_q$를 기반으로 질문 $q$에 대한 reasoning chain $$z = [z_1, z_2, \dots, z_L]$$을 autoregressive하게 구성한다. 이 모듈은 $$p(z \vert q, G_q)$$의 근사로 작동하며, chain factorization은 다음과 같이 정의된다:

$$
p(z \mid q, G_q) = \prod_{i=1}^{L} p(z_i \mid q, z_{<i}, \hat{G}_i)
$$

여기서 $$\hat{G}_i$$는 i번째 step에서의 후보 triple 집합이다. 이 reasoning chain 생성을 위해 TRACE는 두 개의 핵심 서브모듈을 포함한다:

## Answer Generator


<br/>
<br/>

# Experiments



<br/>
<br/>

# Conclusion
