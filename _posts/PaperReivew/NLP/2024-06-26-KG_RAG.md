---
title: "[논문리뷰]KG-RAG: Bridging the Gap Between Knowledge and Creativity"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-06-26
last_modified_at: 2024-06-26
---

*Sanmartin, D*. (2024, May 20). **KG-RAG: Bridging the gap between knowledge and creativity**. arXiv.org. [https://arxiv.org/abs/2405.12035](https://arxiv.org/abs/2405.12035)

# Problem Statement

## 1. Hallucination
LLMs(대형 언어 모델)는 종종 사실과 일치하지 않는 정보를 생성하는 경향이 있다. 이는 "환각(Hallucination)"이라고 불리며, 모델이 존재하지 않는 사실을 만들어내거나 잘못된 정보를 제공하는 문제이다. 특히 LLMs에서 잘못된 정보를 마치 사실인 것 처럼 생성해내는 경우가 종종 발생하며, 이는 LLMs의 신뢰성을 떨어트린다. 

## 2. Catastrophic forgetting
재앙적 망각(Catastrophic forgetting)은 LLMs가 새로운 정보로 학습될 때 이전에 학습된 지식을 잊어버리는 문제를 말한다. 이는 모델이 지속적으로 새로운 데이터를 학습할 때 기존의 지식을 유지하기 어렵게 만든다. 

## 3. Processing Long-Context
LLMs는 긴 문맥을 처리하는 데 어려움을 겪는다. 긴 대화나 문서에서 중요한 정보를 놓치거나 잃어버리는 경우가 발생한다. 이는 긴 문서나 대화에서 연관된 정보를 유지하고 처리하는 데 한계를 보인다.

<br/>
<br/>

# Related Work

## 1. AI Agent

<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/7f42e197-1b24-4861-aaa9-4f88d4dca87e">
</p>

AI 에이전트는 **지각(Perceptron), 뇌(Brain), 행동(Action)**이라는 세 가지 핵심 구성 요소로 이루어져 있으며, 이들은 감지-계획-행동의 자율적 운영 주기를 통해 상호 작용한다. 이 세가지 구성 요소들을 통해 AI 에이전트의 자율적인 운영 주기인 '감지-계획-행동' 사이클을 구현한다.

- **지각(Perceptron)**은 환경을 감지하고 이해하는 기능을 담당한다. 예를 들어 이지미 인식, 음성 인식, 텍스트 이해 등을 포함하여 에이전트가 외부 지식을 수집하는 전 과정이다.
- **뇌(Brain)**은 의사 결정을 내리고, 계획을 세우며, 에이전트의 지식과 기억을 저장하는 중추 역할을 한다. LLMs을 통합하여 동적 추론과 의사 결정을 수행하고 Knowledge Graph(KG)를 통해 구조화된 지식과 기억을 저장한다. 프롬프트 엔지니어링(Prompt Engineering)과 지식 증강(Knowledge Augmented) 등 LLMs의 추론 능력과 특정 task에 대한 성능을 향상시키는 연구가 활발히 진행되고 있다. 예를 들어, Chain of Thought (CoT), Tree of Thought (ToT), Graph of Thoughts (GoT), ReAct (Reason and Act) 등이 있습니다.
- **행동(Action)**은 의사 결정에 따라 행동을 실행하는 기는을 담당한ㄴ다. 예를 들어, 로봇 제어, 이메일 자동 발송, 챗봇등이 이에 해당한다.

## 2. Retrieval-Augmented Generation(RAG)

RAG(Retrieval-Augmented Generation)는 질의(query)에 대한 결과를 찾기 위해 외부 지식을 활용하는 방법이다. 특히, RAG는 외부 지식을 검색하는 Retrieval 모듈과 생성 모듈(Generator)을 결합하여 Open-Domain QA(ODQA)와 Knowledge Intensive Task(KIT)를 효과적으로 수행할 수 있다. 이 방식의 가장 큰 특징은 특정 작업에 구애받지 않는 Task-agnostic한 접근법을 제공한다는 점이다. RAG는 검색된 정보를 동적으로 주입하여, 모델이 최신 정보와 맥락을 기반으로 정확하고 일관된 응답을 생성할 수 있도록 한다. 이를 통해 다양한 응용 분야에서 높은 정확도와 신뢰성을 유지할 수 있다. 이전 포스터에서 자세하게 확인할 수 있다.([\[논문리뷰\]RAG: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://meaningful96.github.io/nr/rag/))

<br/>
<br/>

# Method

## 1. Preliminaries
### 1) Large Language Models (LLMs)
기존의 언어 모델 학습 패러다임은 사전 학습(pre-training)과 미세 조정(fine-tuning) 두 단계로 구성되어 있었다. 그러나 초거대 언어 모델(LLMs)이 등장하면서 새로운 데이터셋에 대해 매번 미세 조정을 수행하는 데 막대한 자원이 필요하다. 이러한 이유로, 프롬프팅(prompting)에 대한 연구가 주목받고 있으며, 학습 패러다임도 <span style="color:gold">**사전 학습(pre-training), 프롬프팅(prompt), 예측(predict)**</span>이라는 세 단계로 전환되었다. 

<p align="center">
<img width="200" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/972d2e1f-8f99-468e-96c3-42cb19226a18">
</p>

Language Model(LM)의 입력 프롬프트(입력 시퀀스)를 $$x$$라 하고, $$x = (x_1, x_2, \cdots, x_q)$$이며, $$x_i$$는 입력 프롬프트 시퀀스의 $$i$$번째 위치한 토큰이다. LM이 생성해내는 출력 시퀀스는 $$y$$로 정의하며, $$y = (y_1, y_2, \cdots, y_m)$$이다. LM은 위의 식과 같이 보통 $$P(y \vert x)$$의 조건부 확률을 최적화 하는 것으로 학습을 진행하게 된다. 이 때, $$P(y_i \vert y_{<i}, x})$$는 입력 프롬프트 $$x$$와 생성된 $$i-1$$번째 출력 토큰들을 고려한 $$i$$번째 출력 토큰의 확률이다.

### 2) Knowledge Graph Question Answering(KGQA)
지식 그래프(Knowledge Graph)는 트리플로 구선된 Knowledge의 집합이며, 트리플은 엔티티(Entity)와 릴레이션(Relation)으로 구성된다. 즉, $$G = (E, R)$$로 표현할 수 있다. 트리플은 $$(e, r, e^{'})$$ 혹은 $$(h, r, t)$$로 표현 가능하다.

<p align="center">
<img width="200" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/e4763fef-8938-449f-bb2a-cb1d00e8edb7">
</p>

본문에서는 위와 같이 KG를 정의한다.


<br/>
<br/>

# Experiments



<br/>
<br/>


# Contribution

<br/>
<br/>

# Reference
