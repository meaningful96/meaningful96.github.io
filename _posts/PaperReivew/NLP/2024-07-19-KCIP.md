---
title: "[논문리뷰]A Knowledge-Injected Curriculum Pretraining Framework for Question Answering"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-07-19
last_modified_at: 2024-07-19
---

*Lin, X., Su, T., Huang, Z., Xue, S., Liu, H., & Chen, E*. (2024). **A Knowledge-Injected Curriculum Pretraining Framework for Question Answering**. WWW 2024, [https://arxiv.org/abs/2403.09712](https://arxiv.org/abs/2403.09712)

# Problem Statement
<span style="font-size:110%">**Knowledge Base Question Answering(KBQA)**</span>  
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/21178b20-d772-4f9f-99e4-1ff769c1f653">
</p>

**Knowledge Base Question Answering(KGQA)**는 지식 베이스(knowledge base)를 활용하여 자연어 질문에 답변하는 기술이다. Knowledge Graph(KG)는 개체와 개체 간의 관계를 구조화된 형태로 표현한 데이터베이스로, 다양한 정보가 체계적으로 정리되어 있습니다. KGQA는 이러한 구조화된 데이터를 이용해 사용자의 질문에 정확하고 효율적으로 답변할 수 있습니다.

예를 들어, "What is the period of the author of *Off on a Comet*?"이라는 질문을 입력으로 받았다. 그리고 주어진 KG에는 "*Off on a Comet*" 이라는 엔티티가 있고, "author"이라는 릴레이션으로 "Jules Verne"가 연결되어있다.

- Triple 1: (*Off on a Comet*, author, Jules Verne)
- Triple 2: (Jules Verne, period, 1828-1905)

이처럼, 두 개의 트리플을 순차적으로 연결하면 질문에 대한 정답(1828-1905)을 찾을 수 있다. 위의 예시는 다시 말해 <span style="color:gold">**2-hop 추론(reasoning)**</span> 문제가 되는 것이다. 

<br/>

<span style="font-size:110%">**Existing Several Nontrivial Technical Challenges of KBQA**</span>  
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/7b3629f5-cae5-4873-90cf-06da9367db68">
</p>

기존의 KBQA 연구들은 환각(hallucination) 등 여러 가지 고질적인 문제들을 해결하려 한다. 그러나 이러한 문제들은 여전히 지속되고 있으며, 논문에서는 최근 KBQA 연구들에서 중요한 세 가지 문제점을 지적한다.

- **문제 1. 문장 생성 방법의 다양성**
  - 현재 사전 학습된 생성형 언어 모델을 사용하여 문장을 생성하는 방법이 많이 사용된다. 이는 정해진 템플릿을 입력으로 받아 QA(질문-응답) 쌍을 생성하는 방식이다. 예를 들어, CoT, GoT, ToT(Tree-of-Thought)등 여러 prompt engineering 연구들이 있다.
  - 그러나 이러한 방법은 종종 KG에서 제공하는 고품질의 메타데이터를 충분히 활용하지 못하는 단점이 있다. 즉, KG에 있는 풍부한 정보를 효과적으로 반영하지 못하여 결과적으로 생성된 문장의 품질이 떨어질 수 있다.

- **문제 2. 생성된 문장의 자연스러움 문제**
  - 사전 학습된 언어 모델이 생성하는 문장은 종종 부자연스럽거나 왜곡된 형태를 띨 수 있다.
  - 이는 자연스러운 문장을 보장하기 위한 복잡한 조정 과정이 필요하다는 것을 의미한다. 다양한 문장 구조와 맥락을 모델이 제대로 학습하지 못하면 부자연스러운 결과문이 나올 수 있다.

- **문제 3. 복잡한 추론 능력의 부족 문제**
  - 언어 모델이 종종 ‘환각, hallucination’을 겪게 된다. 이는 모델이 실제로 존재하지 않는 정보를 생성하거나, 잘못된 추론을 통해 잘못된 정보를 제공하는 현상이다.
  - 또한, 최신 지식의 부족으로 인해 최신 정보나 사실을 반영하지 못하는 경우가 많다.
  -  다중 홉 추론(Multi-hop reasoning)을 수행하는 데 어려움을 겪는다. 이는 복잡한 질의에 대한 정확한 응답을 제공하는 데 제한이 될 수 있다.

본 논문에서는 Knowledge Injective(KI), Knowledge Adaptive(KA), Curriculum Reasoning(CR) 모듈을 도입하여 이 세가지 문제를 해결하고자 한다.

<br/>
<br/>

# Methods
## Model Architecture
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/a65699fc-930b-4f49-9e39-4d9a46adeb14">
</p>

논문에서는 **Knowledge-Injected Curriculum Pretraining(KICP)** 프레임워크를 소개한다. KICP는 사전 학습된 언어 모델을 위한 종합적인 지식 학습과 복잡한 추론 능력을 목표로 하는 일반적인 프레임워크로, <span style="color:gold">**지식 주입(KI)**</span>, <span style="color:gold">**지식 적응(KA)**</span>, <span style="color:gold">**커리큘럼 추론(CR)**</span>의 세 가지 주요 구성 요소로 이루어져 있다. 

**KI**는 KG에서 지식을 추출하여 문장으로 변환하고, **KA**는 원래의 언어 모델을 고정시켜 자연어 이해 능력을 유지하면서 생성된 코퍼스에서 지식을 학습한다. 마지막으로, **CR**은 인간의 추론 패턴을 따라 여러 난이도의 추론이 요구되는 코퍼스를 구성하고, 쉬운 것에서 어려운 것 순으로 언어 모델을 훈련시켜 모델 학습을 촉진한다.

## Module 1. Knowledge Injection (KI)
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/d05564f0-5295-40a6-bed6-15d5faa2dd91">
</p>

KI 모듈은 다양한 지식 그래프(KG) <span style="color:gold">**트리플을 문장으로 변환하는 과정을 일반화하고, 고품질 KG의 메타데이터를 효과적으로 활용**</span>할 수 있도록 설계되었다. 이를 통해 사전 학습된 생성 모델과 freeze된 템플릿의 한계를 극복할 수 있다.

- KI모듈은 세 가지 단계를 거쳐서 KG의 트리플을 언어모델에 입력시킬 수 있는 형태로 가공한다. 첫 번째로 **Text characterization**이다. KG에 존재하는 트리플의 엔티티와 릴레이션은 보통 id로 매핑이 되어있다. 이는 자연어로써 아무 의미없는 정보이기 때문에, KI 모듈은 text characterziation을 통해 언어 모델이 학습하기 용이하게 맵핑된 아이디를 다시 의미있는 자연어, entity name으로 변환시킨다. 

- 두번째로, triple format의 자연어를 <span style="color:gold">**일반적인 문장에 해당하는 free form sentence형태**</span>로 바꾼다. 

- 마지막으로 완성된 문장에서 <span style="color:gold">**특정 단어를 마스킹**</span>한다. 모델이 이를 예측하도록 하여 주어진 문맥에서 누락된 정보를 예측하는 능력을 학습할 수 있다. 


## Module 2. Knowledge Adaptation (KA)
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/ffc3d5ac-fb45-4c1f-a854-e3c521bb38c1">
</p>

KI에 의해 생성된 코퍼스는 문장들이 **문법을 엄격히 따르지 않을 수 있어(특히 간단한 τ의 경우) 자연스러운 코퍼스(corpus)와 다르다**. 또한, 코퍼스의 다양성도 제한적이다. LM을 이 코퍼스로 사전 학습시키면 자연어 이해(Natural Language Understanding, NLU) 능력이 저하되고, 자연스러운 텍스트에서의 성능이 떨어질 수 있다. 더 나아가, 제안된 일반 프레임워크에서는 문장 생성 기술이 임의적이므로, 기존 연구처럼 특정 생성 기술에 기반한 방법을 사용할 수 없다. 따라서, KA(Knowledge Adaptation)에서는 지식 사전 학습 동안 LM의 NLU능력을 유지하는 것을 목표로 한다. 

KI 모듈로 생성된 문장들을 불완전한 문법으로 이루어진 문장일 가능성이 있기 때문에, 그대로 LM에 미세 조정(fine-tuning)하게 되면, 언어 모델의 문맥적 의미를 학습하는 자연어 이해(NLU) 능력이 저하될 수 있다. 이 NLU 능력을 보존하기 위해 <span style="color:gold">**어댑터(adapter)**</span>를 도입해 모든 레이어의 출력값을 어댑터가 학습하도록 한다. 

중요한 것은 어댑터의 레이어 수가 freeze된 LM의 레이어 수와 동일하며, 히든 크기만 LM의 절반이라는 점이다. 최종 출력 차원은 LM과 동일하다. 어댑터의 i번째 레이어는 freeze된 LM의 i번째 레이어와 동일한 구조를 가지며, 이전 어댑터의 히든 표현과 freeze된 LM의 출력 벡터를 결합하여 입력받는다. freeze된 LM이 6개의 레이어로 구성되어 있으면, 어댑터 역시 6개의 레이어로 구성되지만, 마지막 레이어를 제외한 중간 레이어의 히든 크기는 LM의 절반이 된다.

## Module 3. Curriculum Reasoning (CR)
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/e5c4f92f-bc27-4c45-8b8a-7f056d1f7fd7">
</p>

복잡한 추론 능력을 향상시키기 위해 Knowledge Injection(KI)에서 생성된 코퍼스를 사용하는데, 이 코퍼스는 문법을 엄격하게 따르지 않을 수 있으며 다양성이 제한적이다. 이러한 코퍼스로 언어 모델을 사전 학습하면 자연어 텍스트에 대한 자연어 이해(NLU) 능력이 저하될 수 있다. 이를 위해 KA모듈에서 어댑터를 적용해 일반화된 자연어 정보를 학습하도록 하였다.

이를 바탕으로 모델의 <span style="color:gold">**복잡한 추론 능력**</span> 향상시키기 위해 세 단계로 구성된 Curriculum Reasoning(CR) 모듈을 제안한다. 세 단계는 각각 1)일반적인 트리플의 정보를 학습하는 Knowledge Learning 단계, 2)Multi-hop path에 존재하는 트리플을 한 번에 학습하는 CoT learning 단계, 그리고 3)모델이 실제 QA task에서 암기된 지식을 사용하여 추론하도록 사전 학습을 진행하는 Composition Learning 단계이다. 세 단계에 걸쳐 **freeze된 LM과 adapter의 파라미터들을 최종적으로 미세 조정**한다.

**Lesson 1: Knowledge Learning**  
KICP 프레임워크의 첫 번째 단계는 Knowledge Learning이다. 이 단계에서는 지식을 효과적으로 학습하기 위해 KI 모듈을 사용하여 K개의 트리플을 추출하고 이를 바탕으로 언어 모델을 학습시킨다. 이를 통해 KG의 지식을 암기하도록 한다.

**Lesson 2: Chain-of-Thought (CoT) Learning**    
두 번째 단계는 CoT Learning으로, 기본적인 KG의 knowledge fact를 학습한 후, KI를 통해 특정 추론 패턴과 관련 지식을 조합하여 코퍼스를 구성하고 학습시킨다. 엔티티 등 동일한 요소를 최종 구성과 추론 단계에서 모두 마스킹하여 정보 누출을 방지한다. 복잡한 추론이 필요한 충분한 양의 코퍼스를 모든 KG에서 수집하는 것은 어렵기 때문에, 우리는 KG를 기반으로 코퍼스를 구축한다. 사람들은 종종 특정 패턴(예: 다중 홉 추론)을 따라 복잡한 추론을 수행하며, 이는 참여하는 삼중항에 제약을 가한다(예: 연쇄형 삼중항). 따라서 이러한 패턴을 따르며 코퍼스를 구축한다.

**Lesson 3: Composition Learning**  
세 번째 단계인 Composition Learning에서는 모델이 실제 QA task에서 암기된 지식을 사용하여 추론하도록 사전 학습을 진행한다. 여기서는 관련 추론 없이 최종 구성만을 제공하여 코퍼스를 구성하며, 무작위로 샘플링된 삼중항을 사용하여 동적으로 생성된 코퍼스를 활용한다.

<br/>
<br/>

# Experiments



<br/>
<br/>

# Limitations and Contributions



<br/>
<br/>
