---
title: "[논문리뷰]A Knowledge-Injected Curriculum Pretraining Framework for Question Answering"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-07-19
last_modified_at: 2024-07-19
---

*Lin, X., Su, T., Huang, Z., Xue, S., Liu, H., & Chen, E*. (2024). **A Knowledge-Injected Curriculum Pretraining Framework for Question Answering**. WWW 2024, [https://arxiv.org/abs/2403.09712](https://arxiv.org/abs/2403.09712)

# Problem Statement
<span style="font-size:110%">**Knowledge Base Question Answering(KBQA)**</span>  
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/21178b20-d772-4f9f-99e4-1ff769c1f653">
</p>

**Knowledge Base Question Answering(KGQA)**는 지식 베이스(knowledge base)를 활용하여 자연어 질문에 답변하는 기술이다. Knowledge Graph(KG)는 개체와 개체 간의 관계를 구조화된 형태로 표현한 데이터베이스로, 다양한 정보가 체계적으로 정리되어 있습니다. KGQA는 이러한 구조화된 데이터를 이용해 사용자의 질문에 정확하고 효율적으로 답변할 수 있습니다.

예를 들어, "What is the period of the author of *Off on a Comet*?"이라는 질문을 입력으로 받았다. 그리고 주어진 KG에는 "*Off on a Comet*" 이라는 엔티티가 있고, "author"이라는 릴레이션으로 "Jules Verne"가 연결되어있다.

- Triple 1: (*Off on a Comet*, author, Jules Verne)
- Triple 2: (Jules Verne, period, 1828-1905)

이처럼, 두 개의 트리플을 순차적으로 연결하면 질문에 대한 정답(1828-1905)을 찾을 수 있다. 위의 예시는 다시 말해 <span style="color:gold">**2-hop 추론(reasoning)**</span> 문제가 되는 것이다. 

<br/>

<span style="font-size:110%">**Existing Several Nontrivial Technical Challenges of KBQA**</span>  
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/7b3629f5-cae5-4873-90cf-06da9367db68">
</p>

기존의 KBQA 연구들은 환각(hallucination) 등 여러 가지 고질적인 문제들을 해결하려 한다. 그러나 이러한 문제들은 여전히 지속되고 있으며, 논문에서는 최근 KBQA 연구들에서 중요한 세 가지 문제점을 지적한다.

- **문제 1. 문장 생성 방법의 다양성**
  - 현재 사전 학습된 생성형 언어 모델을 사용하여 문장을 생성하는 방법이 많이 사용된다. 이는 정해진 템플릿을 입력으로 받아 QA(질문-응답) 쌍을 생성하는 방식이다. 예를 들어, CoT, GoT, ToT(Tree-of-Thought)등 여러 prompt engineering 연구들이 있다.
  - 그러나 이러한 방법은 종종 KG에서 제공하는 고품질의 메타데이터를 충분히 활용하지 못하는 단점이 있다. 즉, KG에 있는 풍부한 정보를 효과적으로 반영하지 못하여 결과적으로 생성된 문장의 품질이 떨어질 수 있다.

- **문제 2. 생성된 문장의 자연스러움 문제**
  - 사전 학습된 언어 모델이 생성하는 문장은 종종 부자연스럽거나 왜곡된 형태를 띨 수 있다.
  - 이는 자연스러운 문장을 보장하기 위한 복잡한 조정 과정이 필요하다는 것을 의미한다. 다양한 문장 구조와 맥락을 모델이 제대로 학습하지 못하면 부자연스러운 결과문이 나올 수 있다.

- **문제 3. 복잡한 추론 능력의 부족 문제**
  - 언어 모델이 종종 ‘환각, hallucination’을 겪게 된다. 이는 모델이 실제로 존재하지 않는 정보를 생성하거나, 잘못된 추론을 통해 잘못된 정보를 제공하는 현상이다.
  - 또한, 최신 지식의 부족으로 인해 최신 정보나 사실을 반영하지 못하는 경우가 많다.
  -  다중 홉 추론(Multi-hop reasoning)을 수행하는 데 어려움을 겪는다. 이는 복잡한 질의에 대한 정확한 응답을 제공하는 데 제한이 될 수 있다.

본 논문에서는 Knowledge Injective(KI), Knowledge Adaptive(KA), Curriculum Reasoning(CR) 모듈을 도입하여 이 세가지 문제를 해결하고자 한다.

<br/>
<br/>

# Methods
## Model Architecture
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/a65699fc-930b-4f49-9e39-4d9a46adeb14">
</p>

논문에서는 **Knowledge-Injected Curriculum Pretraining(KICP)** 프레임워크를 소개한다. KICP는 사전 학습된 언어 모델을 위한 종합적인 지식 학습과 복잡한 추론 능력을 목표로 하는 일반적인 프레임워크로, <span style="color:gold">**지식 주입(KI)**</span>, <span style="color:gold">**지식 적응(KA)**</span>, <span style="color:gold">**커리큘럼 추론(CR)**</span>의 세 가지 주요 구성 요소로 이루어져 있다. 

**KI**는 KG에서 지식을 추출하여 문장으로 변환하고, **KA**는 원래의 언어 모델을 고정시켜 자연어 이해 능력을 유지하면서 생성된 코퍼스에서 지식을 학습한다. 마지막으로, **CR**은 인간의 추론 패턴을 따라 여러 난이도의 추론이 요구되는 코퍼스를 구성하고, 쉬운 것에서 어려운 것 순으로 언어 모델을 훈련시켜 모델 학습을 촉진한다.

## Module 1. Knowledge Injection (KI)
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/d05564f0-5295-40a6-bed6-15d5faa2dd91">
</p>

KI 모듈은 다양한 지식 그래프(KG) <span style="color:gold">**트리플을 문장으로 변환하는 과정을 일반화하고, 고품질 KG의 메타데이터를 효과적으로 활용**</span>할 수 있도록 설계되었다. 이를 통해 사전 학습된 생성 모델과 고정된 템플릿의 한계를 극복할 수 있다.

- KI모듈은 세 가지 단계를 거쳐서 KG의 트리플을 언어모델에 입력시킬 수 있는 형태로 가공한다. 첫 번째로 **Text characterization**이다. KG에 존재하는 트리플의 엔티티와 릴레이션은 보통 id로 매핑이 되어있다. 이는 자연어로써 아무 의미없는 정보이기 때문에, KI 모듈은 text characterziation을 통해 언어 모델이 학습하기 용이하게 맵핑된 아이디를 다시 의미있는 자연어, entity name으로 변환시킨다. 

- 두번째로, triple format의 자연어를 <span style="color:gold">**일반적인 문장에 해당하는 free form sentence형태로 바꾼**</span>다. 

- 마지막으로 완성된 문장에서 <span style="color:gold">**특정 단어를 마스킹**</span>한다. 모델이 이를 예측하도록 하여 주어진 문맥에서 누락된 정보를 예측하는 능력을 학습할 수 있다. 


## Module 2. Knowledge Adaptation (KA)
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/ffc3d5ac-fb45-4c1f-a854-e3c521bb38c1">
</p>

## Module 3. Curriculum Reasoning (CR)
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/e5c4f92f-bc27-4c45-8b8a-7f056d1f7fd7">
</p>

<br/>
<br/>

# Experiments



<br/>
<br/>

# Limitations and Contributions



<br/>
<br/>
