---
title: "[논문리뷰]A Knowledge-Injected Curriculum Pretraining Framework for Question Answering"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-07-19
last_modified_at: 2024-07-19
---

*Lin, X., Su, T., Huang, Z., Xue, S., Liu, H., & Chen, E*. (2024). **A Knowledge-Injected Curriculum Pretraining Framework for Question Answering**. WWW 2024, [https://arxiv.org/abs/2403.09712](https://arxiv.org/abs/2403.09712)

# Problem Statement
<span style="font-size:110%">**Knowledge Base Question Answering(KBQA)**</span>  
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/21178b20-d772-4f9f-99e4-1ff769c1f653">
</p>

**Knowledge Base Question Answering(KGQA)**는 지식 베이스(knowledge base)를 활용하여 자연어 질문에 답변하는 기술이다. Knowledge Graph(KG)는 개체와 개체 간의 관계를 구조화된 형태로 표현한 데이터베이스로, 다양한 정보가 체계적으로 정리되어 있습니다. KGQA는 이러한 구조화된 데이터를 이용해 사용자의 질문에 정확하고 효율적으로 답변할 수 있습니다.

예를 들어, "What is the period of the author of *Off on a Comet*?"이라는 질문을 입력으로 받았다. 그리고 주어진 KG에는 "*Off on a Comet*" 이라는 엔티티가 있고, "author"이라는 릴레이션으로 "Jules Verne"가 연결되어있다.

- Triple 1: (*Off on a Comet*, author, Jules Verne)
- Triple 2: (Jules Verne, period, 1828-1905)

이처럼, 두 개의 트리플을 순차적으로 연결하면 질문에 대한 정답(1828-1905)을 찾을 수 있다. 위의 예시는 다시 말해 <span style="color:gold">**2-hop 추론(reasoning)**</span> 문제가 되는 것이다. 

<br/>

<span style="font-size:110%">**Existing Several Nontrivial Technical Challenges of KBQA**</span>  
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/7b3629f5-cae5-4873-90cf-06da9367db68">
</p>

기존의 KBQA 연구들은 환각(hallucination) 등 여러 가지 고질적인 문제들을 해결하려 한다. 그러나 이러한 문제들은 여전히 지속되고 있으며, 논문에서는 최근 KBQA 연구들에서 중요한 세 가지 문제점을 지적한다.

- **문제 1. 문장 생성 방법의 다양성**
  - 현재 사전 학습된 생성형 언어 모델을 사용하여 문장을 생성하는 방법이 많이 사용된다. 이는 정해진 템플릿을 입력으로 받아 QA(질문-응답) 쌍을 생성하는 방식이다. 예를 들어, CoT, GoT, ToT(Tree-of-Thought)등 여러 prompt engineering 연구들이 있다.
  - 그러나 이러한 방법은 종종 지식 그래프(KG)에서 제공하는 고품질의 메타데이터를 충분히 활용하지 못하는 단점이 있다. 즉, KG에 있는 풍부한 정보를 효과적으로 반영하지 못하여 결과적으로 생성된 문장의 품질이 떨어질 수 있다.

- **문제 2. 생성된 문장의 자연스러움 문제**
  - 사전 학습된 언어 모델이 생성하는 문장은 종종 부자연스럽거나 왜곡된 형태를 띨 수 있다.
  - 이는 자연스러운 문장을 보장하기 위한 복잡한 조정 과정이 필요하다는 것을 의미한다. 다양한 문장 구조와 맥락을 모델이 제대로 학습하지 못하면 부자연스러운 결과문이 나올 수 있다.

- **문제 3. 복잡한 추론 능력의 부족 문제**
  - 언어 모델이 종종 ‘환각, hallucination’을 겪게 된다. 이는 모델이 실제로 존재하지 않는 정보를 생성하거나, 잘못된 추론을 통해 잘못된 정보를 제공하는 현상이다.
  - 또한, 최신 지식의 부족으로 인해 최신 정보나 사실을 반영하지 못하는 경우가 많다.
  -  다중 홉 추론(Multi-hop reasoning)을 수행하는 데 어려움을 겪는다. 이는 복잡한 질의에 대한 정확한 응답을 제공하는 데 제한이 될 수 있다.

본 논문에서는 Knowledge Injective(KI), Knowledge Adaptive(KA), Curriculum Reasoning(CR) 모듈을 도입하여 이 세가지 문제를 해결하고자 한다.

<br/>
<br/>

# Methods
## Model Architecture
<p align="center">
<img width="1000" alt="1" src="https://github.com/user-attachments/assets/a65699fc-930b-4f49-9e39-4d9a46adeb14">
</p>



<br/>
<br/>

# Experiments



<br/>
<br/>

# Limitations and Contributions



<br/>
<br/>
