---
title: "[논문리뷰]RAG: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"

categories: 
  - NR

  
toc: true
toc_sticky: true

date: 2024-06-25
last_modified_at: 2024-06-25
---

*Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W., Rocktäschel, T., Riedel, S.*, & Kiela, D. (2020, May 22). **Retrieval-Augmented Generation for Knowledge-Intensive NLP tasks**. arXiv.org. https://arxiv.org/abs/2005.11401

# Problem Statement
## 1. 정보의 한계성
기존의 언어 모델은 주로 training set에서 학습한 정보에 근거하여 답변을 생성한다. 이는 모델이 <span style="color">학습한 데이터 범위 내의 정보만 제공할 수 있다는 한계를 가진다. 즉, 모델이 학습하지 않은 최신 데이터나 특수한 Knowledge에 대해서는 답변을 제공하기 어렵다

## 2. Hallucination 
Hallucination이란 문제가 질문(Query)에 대한 오답을 마치 정답처럼 생성해내는 것을 말한다. LLM에서는 특히 이 Hallucination 문제가 매우 중요한 한계로 작용하고 있다. 모델이 학습한 데이터셋의 크기가 작거나 vocabulary 사이즈가 너무 작은 경우, 혹은 overfitting이 되었거나 데이터의 qulity가 낮은 경우 발생한다.

Retrieval-Augmented Generation(RAG)는 이러한 문제점을 해결하기 위해 <span style="color:gold">검색 기반의 접근</span>을 하며 <span style="color:gold">생성 모델과의 통합</span>을 통해 해결하고자 하였다.

<br/>
<br/>

# Related Work
## 1. Open Domain Question Answering(ODQA)
Open Domain Question Answering은 보통 Open Domain QA 혹은 ODQA로 불린다. 이 task는 매우 넓은 범위의 주제에 대해 질문(query)에 답할 수 있는 모델을 설계하는 것을 목표로 한다. 이러한 질문은 특정 도메인에 국한되지 않으며, 시스템은 인터넷이나 데이터베이스와 같은 넓은 범위의 지식에서 답변을 검색한다.

<p align="center">
<img width="800" alt="1" src="https://github.com/meaningful96/Blogging/assets/111734605/e9ff7c5f-e5c2-49f3-9afa-580bb7781d9b">
</p>

쉽게 말해, 입력으로 들어온 query에 대해 Wikidata와 같은 외부 데이터베이스에서 관련된 문서(passage)를 search하고, query와 관련된 case를 여러 개 가지고와 모델이 이를 통해 가장 정합한 case를 고르고 답변을 추론하는 것이다. (즉, 모델이 Input sequence와 함께 외부 데이터의 문서를 같이 이용해서 추론을 한다.) 또한 답변(answer)는 "바나나, 사과, 수박"과 같이 연속된 여러 개의 토큰으로 출력이 가능하다. 외부 데이터의 문서를 검색하기 때문에 <span style="color:gold">답변이 외부 데이터베이스나 질문에 존재가 가능</span>하다. 

- Example
  1. 질문(Query): "브라질의 수도는 어디인가요?"
    - 답변(Answer): "브라질리아"
    - 이 때 모델은 브라질의 지리적, 정치적 정보를 검색하여 "브라질리아"를 답변한다.
  2. 질문(Query): "양조의 과정은 어떤 것이 있나요?"
    - 답변(Answer): "제맥아, 제분, 담금, 끓임, 발효, 숙성, 여과, 포장"
    - Wikidata에서 "양조가 이루어지는 데에는 제맥아, 제분, 담금, 끓임, 발효, 숙성, 여과, 포장 등의몇 가지 과정을 거친다"를 검색하여 답변을 추론한다.

## 2. Knowledge Intensive Task(KIT)
Knowledge Intensive Task는 특정 지식이 요구되는 작업을 지칭한다. 이런 작업들은 단순한 정보 검색을 넘어서, 복잡한 추론, 문맥 이해, 전문 지식을 필요로 한다. 특히 사실 확인(fact checking)문제가 대표적인 예이다. ODQA와 달리 KIT는 더 복잡한 추론과 전문 지식을 필요로 하며, 답변을 생성하기 위해 여러 출처의 정보를 통합하고 유추하는 과정이 필요할 수 있다. 따라서 <span style="color:gold">질문(query)이나 검색된 외부 데이터(passage)에 정답 토큰이 직접적으로 존재하지 않을 수 있다</span>.

- Example (Fact Checking)
  1. 질문(Query): "한국의 수도는 강원도 태백이다." 
    - 답변(Answer): "거짓"
    - Wikidata에 검색된 passage: 대한민국의 수도는 서울특별시이며 한강이 도시를 관통한다.

이처럼 질문과 검색된 외부데이터(passage)어디에도 거짓이라는 토큰이 존재하지 않음에도 불구하고 모델이 "거짓"을 답변으로 추론할 수 있다.

<br/>
<br/>

# Method

<br/>
<br/>

# Experiments

<br/>
<br/>

# Contribution

<br/>
<br/>

# Reference
Paper: [RAG: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)      
Video: [고려대학교 산업경영공학부 DSBA](https://www.youtube.com/watch?v=gtOdvAQk6YU)

