---
title: "[논문리뷰]Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2025-09-05
last_modified_at: 2025-09-05
---
*Bowen Jin, Jinsung Yoon, Jiawei Han, and Sercan O. Arik*. 2025. [Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG](https://arxiv.org/abs/2410.05983). In Proceedings of the International Conference on Learning Representations (ICLR 2025). International Conference on Learning Representations.

# Problem Statement
<p align="center">
<img width="500" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/Paper_Review/%5B2025.09.02%5DLongContext/figure2.png?raw=true">
</p><span style="font-size:80%">[Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172)</span>


<span style="font-size:110%">**Lost-in-the-middle**</span>  
**Lost-in-the-middle**이란 추론 과정에서 LLM에 long-context가 입력되었을 때 LLM이 입력 시퀀스 중간에 위치한 정보는 제대로 활용하지 못하고, 시퀀스 <span style="color:red">**앞과 뒤에 위치한 정보만 잘 활용**</span>하는 현상이다. 위의 그림에서 retrieval로 검색된


<br/>
<br/>

# Chanllenges of Long Context LLMs in RAG


<br/>
<br/>

# Methodology


<br/>
<br/>

# Conclusion
