---
title: "[논문리뷰]Making Long-Context Language Models Better Multi-Hop Reasoners (ACL, 2024)"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2026-01-18
last_modified_at: 2026-01-18
---

*Yanyang Li, Shuo Liang, Michael Lyu, and Liwei Wang*. 2024. [Making Long-Context Language Models Better Multi-Hop Reasoners](https://aclanthology.org/2024.acl-long.135/). In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Lun-Wei Ku, Andre Martins, and Vivek Srikumar (Eds.). Association for Computational Linguistics, Bangkok, Thailand, 2462–2475. https://doi.org/10.18653/v1/2024.acl-long.135

# 1. Problem Statement
이 논문은 Long-Context Language Models (LC-LMs)가 긴 문맥을 처리하는 데 능숙하지만, multi-hop reasoning에서는 여전히 성능이 저하된다는 문제를 다루고 있다. 특히 **긴 문맥으로 인해 노이즈가 많은 상황에서 관련 정보만을 추출하고 논리적으로 연결하는 능력이 부족함**을 지적한다. 저자들은 이러한 한계를 해결하기 위해 Reasoning with Attribution(RwA)라는 새로운 추론 패러다임을 제안한다. 이 방법은 LMs가 reasoning 과정에서 각 주장(assertain)에 대해 출처를 명시적으로 연결(**citation / quote**)하도록 강제함으로써, 보다 근거 기반의 multi-hop reasonin을 수행하도록 한다.

<br/>
<br/>

# 2. Limitations of Existing Works
- **[노이즈 있는 문맥에서의 비효율적 정보 탐색]**: 기존 long-context LMs는 긴 입력 내에서 **질문과 관련 없는 정보에 쉽게 주의를 빼앗김**(Lost in the Middle 현상)으로 인해, 핵심 정보 추출에 실패하는 경향이 있다. 이는 multi-hop reasoning에서 각각의 중간 추론 단계가 필요한 경우 특히 심각한 문제를 야기한다.
- **[문맥 내 지식의 비효율적 통합]**: LM이 문맥 내에서 필요한 근거를 가져오더라도, **이를 논리적으로 연결하여 정당한 reasoning chain을 구성하는 능력**이 부족하다. 즉, retrieval은 가능하나 integration이 어렵다. 특히 소형 모델에서 이 현상이 두드러진다.
- **[Attribution 부재]**: 기존 CoT(Chain-of-Thought) 기반 reasoning은 reasoning 과정을 보여주지만, **각 reasoning step이 어떤 문맥에 근거하는지를 명시하지 않음**으로 인해 reasoning의 신뢰성과 일관성이 떨어진다.

<br/>
<br/>

# 3. Methodology
## 3.1. Reasoning with Attribution (RWA)
<p align="center">
<img width="400" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/PaperReview(2026)/%5B2026.01.18%5DAttrLoRA/figure1.png?raw=true">
</p>

이 논문에서 제안한 핵심 방법론은 **Reasoning with Attribution (RwA)**이다. 기존 CoT 방식을 확장하여 reasoning의 각 단계가 문맥의 특정 부분에 연결되도록 설계한다. 이 방식은 reasoning을 두 단계로 나누는 효과를 가진다.

1. **관련 문맥의 위치를 찾기 (Retrieval localization)**
2. **해당 근거를 기반으로 추론 수행 (Reasoning grounding)**

RwA에는 두 가지 변형이 존재한다. 
- **CoC (Chain-of-Citation)**: reasoning 단계별로 인용 문서 ID를 명시
    - models are prompted to reference citations corresponding to each step of the reasining chain
- **CoQ (Chain-of-Quote)**: reasoning 단계별로 인용 문서에서 실제 인용문을 포함
    - CoQ goes further by requiring models to include direct quotations from the cited material for each reasoning step
 
<p align="center">
<img width="400" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/PaperReview(2026)/%5B2026.01.18%5DAttrLoRA/figure2.png?raw=true">
</p>

Table 2는 CoC와 CoQ에 대한 사전 실험 결과이다. sLLM에 학습을 하기 전, 이 방법이 CoT 대비 얼마나 성능 증가가 되는지 확인하기 위해 API기반의 모델들로 실험을 진행하였다. 입력으로 5-shot 예시를 주었으며, 실험 결과 모든 데이터셋에서 전반적으로 CoT대비 성능이 증가한 것을 볼 수 있다. 특히, CoC방식이 가장 큰 성능 향상을 보여주었다.

## 3.2. Dataset Curation
<p align="center">
<img width="400" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/PaperReview(2026)/%5B2026.01.18%5DAttrLoRA/figure3.png?raw=true">
</p>

MuSiQue 데이터셋을 기반으로 **ChatGPT를 이용해 attribution이 포함된 reasoning chain(CoQ)을 자동 생성**한 후, 이를 필터링하여 *MuSiQue-Attribute*라는 학습용 데이터셋을 구축하여 사용한다.

생성 단계에서 5가지 유형 (Incorrect Answer, Non-Existent Attirubution, Incorrect Citation, Repreated Citation, Extreme Quotes)을 자동 필터링하였으며, 최종적으로 1,358개의 고품질 예시를 확보하였다.
- 2-hop: 82.2% / 3-hop: 14.1% / 4-hop: 3.8%

## 3.3 Learning Frameworks
<p align="center">
<img width="400" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/PaperReview(2026)/%5B2026.01.18%5DAttrLoRA/figure4.png?raw=true">
</p>

학습은 비교적 간단하다. 일반적인 instruction tuning방식이며, LLM이 <span style="color:gold">**reasoning 시 citation을 생성하는 CoC chain을 직접 출력**</span>하도록 학습한다. 이 때, 앞서 만든 MuSiQue기반의 고품질 데이터셋을 **Learning to Attribute(LA)**라고 한다.

- Multi-Task Learning 구조: LA 외에도 reasoning 능력을 강화하기 위해 세 가지 보조 과제를 함께 학습
    - **AP (Answer Prediction)**: reasoning 없이 직접 답을 생성
    - **CG (CoT Generation)**: reasoning chain을 먼저 생성 후 답 도출
    - **QI (Quotes Identification)**: reasoning에 필요한 인용문만 식별

학습 시에는 모델이 특정 문서 위치나 문서 수에 민감해지는 편향을 방지하기 위해 두 가지를 방법을 적용한다

- Distractor Sampling: 무작위로 irrelevant document추가 → 노이즈 강건성 향상
- Document Shuffling: 문서 순서를 무작위로 변경 → 위치 편향 제거거

# 4. Experiments
## 4.1. Experiment Setup

**Dataset:**  
- **학습:** MuSiQue-Attributes
- **추론:** [Zero-Shot] HotpotQA, 2WikiMultihopQA / [Trained] MuSiQue

**Models:**  
- Vicuna-7B / LongLoRA-7B

## 4.2. Main Results
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/PaperReview(2026)/%5B2026.01.18%5DAttrLoRA/figure5.png?raw=true">
</p>

- **AO**  : 모델이 정답만 추론
- **CoT**: Chain-of-Thought
- **CoC**: Chain-of-Citation

CoC prompting은 CoT 대비 **평균 EM + 1~3 point 향상** 효과를 보여주었다. 특히 Claude-instant에서 CoT로 성능이 하락하던 경우도 CoC로 완화되었다. ChatGPT 기준 MuSiQue dataset에서 CoC: 37.0 EM, CoT: 36.2 EM 으로 개선되었다.

특히, Vicuna-7B를 기반으로 LoRA fine-tuning을 적용한 AttrLoRA는 기존 7B 모델 대비 **평균 20 포인트 이상 향상** 보였으며, MuSiQue dataset에서는 ChatGPT 및 Claude-instant를 초과하는 성능을 달성했다.

## 4.3. AttrLoRA (Zero-Shot Example)
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/PaperReview(2026)/%5B2026.01.18%5DAttrLoRA/figure6.png?raw=true">
</p>

또한 Figure 2(page 6)에서 노이즈 비율(0–100%)을 증가시킨 실험 결과, 다른 모델이 30 포인트 이상 하락하는 반면 AttrLoRA는 약 10 포인트 만 감소해 **강한 노이즈 강건성**을 보였다.

## 4.4. Ablation Study
<p align="center">
<img width="400" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/PaperReview(2026)/%5B2026.01.18%5DAttrLoRA/figure7.png?raw=true">
</p>

- **Multi-Task Learning:** LA + QI 조합이 가장 안정적이며, 단순 CoT 학습(C G)은 오히려 성능 감소 유발.
- **Data Augmentation:** MuSiQue 및 HotpotQA에서 성능 상승, 2Wiki처럼 단순한 질문 구조에서는 효과 미미.
- **Fine-tuning Data Scaling (Figure 4):** 데이터의 20%만 사용해도 85% 성능 달성 → 데이터 효율성 우수.

## 4.5. Case Study
<p align="center">
<img width="1000" alt="1" src="https://github.com/meaningful96/Blogging/blob/main/PaperReview(2026)/%5B2026.01.18%5DAttrLoRA/figure8.png?raw=true">
</p>

<br/>
<br/>

# 5. Conclusion
**Limitations**  
- **[제한된 Attribution 형식]**: 본 연구의 Reasoning with Attributions 방법은 citation(문서 참조)과 **quotation(직접 인용)** 두 형태에만 국한되어 있으며, 웹 링크(URL), 문서 요약(anchor text), 혹은 외부 지식베이스 연결 등 다른 attribution 표현 방식은 고려되지 않았다. 이는 다양한 근거 표현 방식으로의 확장 가능성을 제한한다.
- **[모델 구조적 확장의 부재]**: 제안된 접근법은 모델 아키텍처 수정 없이 training 전략에만 의존한다. 따라서 attribution reasoning에 특화된 구조(예: citation-aware attention layer나 retrieval gating mechanism)를 포함하는 전용 모델 설계 여지가 남아 있다.
- **[Retrieval 의존성 한계]**: 현재 방법은 데이터셋 작성자가 제공한 고정된 context를 입력으로 사용한다. 즉, 실시간 검색 기반의 retrieval-augmented generation(RAG) 환경에서는 직접적인 검증이 이루어지지 않았으며, retrieval 통합형 모델과의 결합 성능은 향후 연구가 필요하다.

**Contribution**  
- **Reasoning with Attributions 패러다임** 제안 → LM의 multi-hop reasoning 성능 및 robustness 동시 향상.
- **MuSiQue-Attribute** 데이터셋 제공 → multi-hop reasoning 및 attribution 연구 기반 확장.
- **Multi-task Learning + Data Augmentation 전략** 도입 → 소형 LM의 추론 정확도 대폭 향상.
- **AttrLoRA 모델** → 7B 규모에서도 ChatGPT 급의 multi-hop 성능 달성 및 노이즈 강건성 검증.
