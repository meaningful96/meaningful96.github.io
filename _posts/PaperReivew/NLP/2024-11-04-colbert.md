---
title: "[논문리뷰]ColBERT & ColBERT-v2"

categories: 
  - NR
  
toc: true
toc_sticky: true

date: 2024-11-04
last_modified_at: 2024-11-04
---

# Background
## 역색인(Inverted Index) 검색 엔진
후보 문서들을 검색하는 일도 중요하지만, 최종적으로 사용자에게 보여지는 **문서를 고르는 Ranking작없도 중요**하다. HotpotQA, MuSiQue, 2WikiMultiHopQA와 같은 데이터셋들은 이미 후보 문서들은 정해져있기 때문에, Ranking 작업이 필수이다.

전통적인 ranking방법으로는 **BM25**를 많이 사용하고 있다. BM25는 TF-IDF와 비슷하지만, 문서의 길이를 고려한 랭킹함수이다. 어떤 텀에 대하여 해당 텀이 **어떤 문에서 얼마나 많이 등장**하였는지(많이 등장할수록 값이 커짐)와, **얼마나 많은 문서에 등장**했는지(많은 문서에 등장할수록 값이 작아짐)를 고려한다. BM25는 역색인 검색 엔진에서 미리 계산해 저장할 수 있기 때문에 많은 문서를 다루고 성능이 중요한 검색엔지에서 많이 사용된다.

**역색인(Inverted Index)** 검색 엔진은 문서 검색 시스템에서 효율적으로 데이터를 검색하기 위해 사용되는 방식 중 하나이다. 일반적인 색인이 문서와 그 안에 포함된 단어의 위치를 기록하는 방식이라면, 역색인은 각 단어에 대해 그 단어가 포함된 모든 문서를 기록하는 방식이다. 이를 통해 사용자가 특정 단어를 검색할 때 해당 단어가 포함된 문서를 빠르게 찾아낼 수 있다.

역색인에서는 **키(key)**가 단어가 되고, **값(value)**은 그 단어가 등장한 문서 리스트 또는 문서 내에서의 위치 정보가 됩니다. 예를 들어, 다음과 같은 세 문서가 있다고 가정해 보겠습니다.

- 문서 1: "고양이는 귀엽다."
- 문서 2: "강아지는 충성스럽다."
- 문서 3: "고양이와 강아지는 친구다."

<p align="center">
<img width="420" alt="1" src="https://github.com/user-attachments/assets/ad7fcc6d-201f-4b71-be82-11db266ec6e5">
</p>

역색인 검색 엔진을 이용하여 "고양이"라는 단어를 검색할 경우, 역색인은 즉시 문서 1과 문서 3을 반환할 수 있다. 대표적인 역색인 검색 엔진에는 엘라스틱서치(Elasticsearch), 아파치 루씬(Apache Lucene), 그리고 솔라(Solr) 등이 있다.

## BERT를 활용한 Neural Ranking
<p align="center">
<img width="420" alt="1" src="https://github.com/user-attachments/assets/fcd90ebd-3be1-471f-8bde-5a2053e88f9e">
</p>

1. BERT에게 **$$\text{[CLS] Query [SEP] Document [SEP]}$$** 형식으로 시퀀스를 입력시킨다. 이때 input data로 $$\text{[CLS]}$$와 $$\text{[SEP]}$$ 토큰을 반드시 포함해야 한다.
2. 모든 BERT 레이어에 대해 실행한다.
3. 마지막 $$\text{[CLS]}$$ 토큰의 출력 임베딩에서 score를 추출한다.


# Reference
\[1\] Blog: [\[논문 리뷰\]ColBERT, ColBERTv2](https://pangyoalto.com/colbertv1-2-review/)  
\[2\] Github: [ColBERT](https://github.com/stanford-futuredata/ColBERT)  
