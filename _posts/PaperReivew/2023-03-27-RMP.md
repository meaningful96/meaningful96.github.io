---
title: "[논문리뷰]Relational Message Passing for Knowledge Graph Completion"

categories: 
  - PaperReview
  
tags:
  - [KG Completion]
  
toc: true
toc_sticky: true

published: true

date: 2023-03-27
last_modified_at: 2023-03-27
---

Wang, H. (2020, February 17). Relational Message Passing for *Knowledge Graph Completion. arXiv.2002.06757*    
[Relational Message Passing for Knowledge Graph Completion]("https://arxiv.org/pdf/2002.06757.pdf")  

# Problem Statement

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/230568984-7b90f5d6-62df-4644-9170-dc5bb53ae12e.png">
</p>

<span style = "font-size:120%">**Incompleteness and noisy**</span>    
Knowledge Graph는 head와 relation, tail로 이루어진 트리플(Triple, <$$h,r,t$$>)형태로 정보를 표현한다. Knowledge Graph는 보통의 Homogeneous Graph와는 다르게 엔티티(Entity, Node)나 릴레이션(Relation, Edge)이 여러 가지 타입을 가지는 Heterogeneous Graph이며 엔티티와 릴레이션의 수가 매우 많은 Large-Scale Graph이다. 이러한 일련의 이유로, <span style = "color:aqua">1)**KG는 불완전(Incomplete)할 수 있으며 noisy**</span>할 수 있다. 이는 다시 말해서, 노드 또는 엔티티의 수가 많다 보니 그래프 전반적으로 **missing link**가 많고, 그에 따라 여러 hop을 거친 path information이 불완전하기에 정보가 noisy하다는 것이다.

<span style = "font-size:120%">**Limitation of existing message passing models**</span>    
두 번째로 <span style = "color:aqua">2)**기존의 존재하는 message passing 모델들은 한계**</span>점으로 Knowledge Graph에 부적합하다는 것이다. 그 모델들은 모두 Input을 Entity의 Embedding vector로 받아 이웃 노드들의 정보를 Aggregation하고 그 메세지 정보로 hidden state를 업데이트 시키는 방식으로 학습이 진행된다. 이럴 경우 노드 수가 많은 Knowledge Graph의 경우 Computational Complexity가 압도적으로 증가하기 때문이다.

따라서, Knowledge Graph에 적당한 Message Passing 방법을 적용시킨 모델이 <span style = "color:gold">**'PathCon'**</span>이다.

<br/>
<br/>

# Related Work

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/230572221-8b097544-7c92-463e-bfea-fd2a8507f3e3.png">
</p>

<span style = "font-size:120%">**Relation Prediction**</span>    
관련된 연구로는 Relation Prediction이 있다. Knowledge Graph Completion task는 쉽게 말하면 head나 tail을 찾는 엔티티 기반의 추론 문제이다. 비슷하게 Relation Prediction은 Triple에서 relation edge를 찾는 것을 목적으로 하는 추론 문제이다. 논문에서는 더 나아가, Relation Prediction을 <u>확률 분포로 주어진 head와 tail에 대한 relation type의 분포를 모델링 하는 것이라고 정의</u>한다.

<span style = "font-size:120%">**Knowledge Graph Completion(KGC)**</span>    
두번째로는 KGC이다. KGC는 위의 노란색 박스에서와 같이, head와 relation의 임베딩이 주어졌을 때 tail임베딩을 찾는 것이 목표이다. Link Prediction과 비슷하다.

<br/>
<br/>

# Method
## 1. Notation

<p align="center">
<img width="1000" alt="1" src="https://user-images.githubusercontent.com/111734605/230575766-8d58579c-9f11-414c-89ef-809a3f87c3b3.png">
</p>

논문에서 나오는 Notation으로는 왼쪽의 표와 같다. 트리플은 <$$h,r,t$$>로 정의된다. $$s^i$$는 Hidden state 임베딩을 의미한다. 이 노테이션을 바탕으로 Relation Prediction의 내용을 보충하자면, Relation Prediction을 다음과 같이 베이즈 정리(Bayes' Theorem)로 나타내면 다음과 같다.

<p align="center">
<img width="400" alt="1" src="https://user-images.githubusercontent.com/111734605/230725747-b3ca7551-ffb1-461e-87eb-3fd13de4baa6.png">
</p>

Relation Prediction은 앞서 말했듯, 헤드와 테일이 주어졌을 때 릴레이션을 찾는 것이다. 그리고 이는 <span style = "color:aqua">**릴레이션의 유형(Relation Type)에 의한 분포를 모델링**</span>하는 것과 같다. 따라서 Posterior의 경우 조건 그대로 <$$h,t$$> 가 주어졌을 때 릴레이션을 찾는 것이므로 조건부 확률(Conditional Probability)의 조건 부에 $$h,t$$가 들어간다. 하지만 , Posterior의 경우 직접적으로 모델링하기 힘들다.

따라서 베이즈 정리를 이용해 Likelihood와 Prior의 곱과 비례한다는 식으로 바꿔 모델링이 가능하다. Likelihood의 경우 조건식과 구하려던 확률식의 위치가 바뀌게 되고 이는 $$p(h,t \vert r)$$으로 표기한다. 이 Likelihood(우도)가 의미하는 것은 특정 가설이나 모델이 참인 경우 특정 데이터 또는 증거 집합을 관찰할 확률을 나타낸다. <span style = "color:aqua">**Likelihood의 의미를 좀 더 쉽게 설명하자면 결국 릴레이션 r에 관한 다른 서브 루프가 없는가를 측정해 확률로서 나타낸 것**</span>이다. 

마지막으로 Prior는 일종의 사전 지식으로 여기서는 $$h(r)$$로 표현된다. 이 때, prior의 수식은 간단하게 전체 릴레이션의 수에 대한 특정 Relation Type의 출현 확률이다. 따라서 (1)식으로 정의된다.

이를 (2)번식과 같이 Decomposition할 수 있다. Decompostion을 함으로써 직접적으로 구해야하는 확률의 무엇인지 정해진다. PathCon모델에서는 엔티티의 정보(Entitiy's Identity)를 고려하지 않고, 엔티티의 <span style = "color:aqua">**Local Relational Subgraph**</span>만을 고려한다. 다시 말해서 엔티티의 Local Relational Subgraph를 $$C(\cdot)$$으로 표현했을 때 $$p\left(C(h) \vert r \right)$$ 와  $$p\left(C(t) \vert r \right)$$로 정의된다.

<p align="center">
<img width="500" alt="1" src="https://user-images.githubusercontent.com/111734605/230727754-31e7953e-ad33-49ef-8669-67edd3ec17a7.png">
</p>

이 그림을 보면, 진한 빨간색이 head와 tail로부터 1-hop만큼 떨어진 릴레이션의 정보를 모으는 것을 시각화 한 것이고, 옅은 빨간색은 2-hop만큼의 릴레이션 정보를 Aggregation하는 것을 시각화 한 것이다. 또한 초록색선이 바로 Relation Path가 된다. Relation Path는 head에서 tail로 릴레이션을 따라서 가는 path를 말한다. 이는 Shortest path일 수도 있고, 몇 hop까지 정보를 aggregation하느냐에 따라 달라질 수 있다.

<br/>
<br/>

# Experiment & Result


<br/>
<br/>

# Contribution
