---
title: "[논문리뷰]SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models "

categories: 
  - PaperReview
  
tags:
  - [KG Completion]
  
toc: true
toc_sticky: true

date: 2023-07-10
last_modified_at: 2023-07-10
---


Wang, L., Zhao, W., Wei, Z., & Jingming, L. (2022). SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models. In *Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*. https://doi.org/10.18653/v1/2022.acl-long.295

# Problem Statement

<span style="font-size:110%"><b>1. Limitation of Graph Embedding</b></span>  
Graph Embedding은 엔티티와 릴레이션을 Text description같은 추가 정보를 사용하지않고 **Triple의 구조 정보**를 저차원 벡터로 mapping하여 그래프를 학습하게된다. Graph Embedding 방식을 채택한 모델들은 TransE, TransR, RotatE등이 있다. Graph Embedding의 문제점은 바로 Graph에 내제된 정보중 오직 <span style="color:gold">**구조 정보(Structural Information)만을 사용해 학습하고, 텍스트 정보(Texture Information)는 사용하지 못한다**<.span>는 점이다. 이로인해 그래프의 특징을 온전하게 반영하지 못한다.

<br/>

<span style="font-size:110%"><b>1. Limitation of Text-Based Method</b></span>    
Text-based Method는 Graph Embedding과 달리 사용가능한 text를 entity representation learning을 위해 통합하는 방식이다. 즉, Text 정보를 이용하여 학습을 진행한다. 직관적으로 추가적인 input정보를 활용할 수 있기 때문에 Graph Embedding방식보다는 좋을 것이라 예측되지만, **실제로는 훨신 긴 Inference time이 소요되고 심지어 성능이 더 뒤쳐지는 결과**를 보였다.

<p align="center">
<img width="400" alt="1" src="https://github.com/meaningful96/DSKUS_Project/assets/111734605/360089fa-b7f3-4a1f-8e19-4a6b7b06401a">
</p>
<center><span style="font-size:80%">Knowledge Graph에 있는 text description</span></center>

저자는 이 Text-based method의 성능 저하 이유를 <span style="color:gold"><b>Inefficiency in contrastive learning</b></span>으로 본다. 즉, 기존의 Contrastive learning은 KGC를 하는데 pre-trainied 모델에 적용하기에 부적합하다는 것이다.

<br/>
<br/>

# Related Work

<br/>
<br/>

# Method

<br/>
<br/>

# Experiment & Result

<br/>
<br/>

# Contribution

# Reference
